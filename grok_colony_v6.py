import os
from datetime import datetime
from ultralytics import YOLO
import gradio as gr
import torch
from PIL import Image, ImageDraw, ImageFilter, ImageEnhance
import numpy as np
import cv2
import pandas as pd
from pathlib import Path
import time
import glob
import json

# AI ê¸°ë°˜ ë¶„í•  ëª¨ë¸ ë¡œë“œ (FastSAM-x ì‚¬ìš©)
model_path = 'weights/FastSAM-x.pt'
model = YOLO(model_path)

# ë””ë°”ì´ìŠ¤ ì„¤ì • (CUDA, MPS, CPU ìˆœìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥)
device = torch.device(
    "cuda" if torch.cuda.is_available() else
    "mps" if torch.backends.mps.is_available() else "cpu"
)

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íˆìŠ¤í† ë¦¬ ê´€ë¦¬ í´ë˜ìŠ¤
class ImagePreprocessHistory:
    def __init__(self):
        self.original_image = None
        self.current_image = None
        self.history = []
        self.current_index = -1

    def set_original(self, image):
        if image is None:
            return None
        if not isinstance(image, Image.Image):
            image = Image.fromarray(np.array(image))
        self.original_image = image
        self.current_image = image
        self.history = [image]
        self.current_index = 0
        return image

    def add_state(self, image):
        if image is None:
            return None
        if not isinstance(image, Image.Image):
            image = Image.fromarray(np.array(image))
        self.history = self.history[:self.current_index + 1]
        self.history.append(image)
        self.current_index = len(self.history) - 1
        self.current_image = image
        return image

    def reset(self):
        if self.original_image is not None:
            self.current_image = self.original_image
            self.current_index = 0
            return self.original_image
        return None

    def undo(self):
        if self.current_index > 0:
            self.current_index -= 1
            self.current_image = self.history[self.current_index]
            return self.current_image
        return self.current_image

image_history = ImagePreprocessHistory()

# Colony ì¹´ìš´í„° í´ë˜ìŠ¤ (ìë™/ìˆ˜ë™ êµ¬ë¶„ ë° ê²°ê³¼ ì´ë¯¸ì§€ì— í†µí•© ìˆ«ì í‘œì‹œ)
class ColonyCounter:
    def __init__(self):
        self.manual_points = []  # ìˆ˜ë™ í¬ì¸íŠ¸
        self.auto_points = []    # ìë™ í¬ì¸íŠ¸
        self.current_image = None
        self.auto_detected_count = 0
        self.remove_mode = False
        self.original_image = None
        self.removed_points = []  # ì‚­ì œëœ í¬ì¸íŠ¸ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
        self.scale_factor = 1.0   # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§• ìŠ¤ì¼€ì¼ íŒ©í„° ì¶”ê°€
        self.base_image = None    # í¬ì¸íŠ¸ í‘œì‹œ ì—†ëŠ” ì²˜ë¦¬ëœ ê¸°ë³¸ ì´ë¯¸ì§€
        self.auto_annotations = []  # ìë™ ê°ì§€ëœ ì£¼ì„ ë°ì´í„° ì €ì¥

    def reset(self):
        self.manual_points = []
        self.auto_points = []
        self.current_image = None
        self.auto_detected_count = 0
        self.remove_mode = False
        self.original_image = None
        self.removed_points = []  # ì‚­ì œëœ í¬ì¸íŠ¸ íˆìŠ¤í† ë¦¬ë„ ì´ˆê¸°í™”
        self.scale_factor = 1.0
        self.base_image = None
        self.auto_annotations = []

    def set_original_image(self, image):
        self.original_image = np.array(image)

    def toggle_remove_mode(self):
        self.remove_mode = not self.remove_mode
        img_with_points = self.draw_points()
        mode_text = "ğŸ”´ REMOVE MODE" if self.remove_mode else "ğŸŸ¢ ADD MODE"
        return img_with_points, mode_text

    def add_or_remove_point(self, image, evt: gr.SelectData):
        try:
            # í˜„ì¬ ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° ì…ë ¥ëœ ì´ë¯¸ì§€ ì‚¬ìš©
            if self.current_image is None and image is not None:
                self.current_image = np.array(image)
                
            # ì´ë²¤íŠ¸ ì¢Œí‘œ ê°€ì ¸ì˜¤ê¸°
            x, y = evt.index
            
            # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ì²˜ë¦¬ ë¶ˆê°€
            if self.current_image is None and self.base_image is None:
                print("Warning: No image available to add/remove points")
                return image, self.get_count_text()
                
            if self.remove_mode:
                # ì œê±° ëª¨ë“œ: ê°€ì¥ ê°€ê¹Œìš´ ì  ì°¾ê¸°
                closest_auto = self.find_closest_point(x, y, self.auto_points)
                closest_manual = self.find_closest_point(x, y, self.manual_points)
                
                if closest_auto is not None:
                    # ì‚­ì œ ì „ì— í¬ì¸íŠ¸ì™€ íƒ€ì… ì €ì¥
                    removed_point = self.auto_points[closest_auto]
                    self.removed_points.append(('auto', removed_point))
                    self.auto_points.pop(closest_auto)
                    self.auto_detected_count = len(self.auto_points)
                elif closest_manual is not None:
                    # ì‚­ì œ ì „ì— í¬ì¸íŠ¸ì™€ íƒ€ì… ì €ì¥
                    removed_point = self.manual_points[closest_manual]
                    self.removed_points.append(('manual', removed_point))
                    self.manual_points.pop(closest_manual)
            else:
                # ì¶”ê°€ ëª¨ë“œ: ìˆ˜ë™ í¬ì¸íŠ¸ ì¶”ê°€
                self.manual_points.append((x, y))
                
            # ê²°ê³¼ ì´ë¯¸ì§€ ë‹¤ì‹œ ê·¸ë¦¬ê¸°
            img_with_points = self.draw_points()
            
            # ì´ë¯¸ì§€ê°€ Noneì¸ ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬
            if img_with_points is None:
                if image is not None:
                    print("Warning: draw_points returned None, using input image")
                    return image, self.get_count_text()
                else:
                    # ì…ë ¥ ì´ë¯¸ì§€ë„ ì—†ëŠ” ê²½ìš°
                    dummy_img = np.zeros((100, 100, 3), dtype=np.uint8)
                    return dummy_img, self.get_count_text()
                    
            return img_with_points, self.get_count_text()
            
        except Exception as e:
            print(f"Error in add_or_remove_point: {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì…ë ¥ ì´ë¯¸ì§€ ê·¸ëŒ€ë¡œ ë°˜í™˜
            if image is not None:
                return image, self.get_count_text()
            # ëª¨ë“  ì´ë¯¸ì§€ê°€ Noneì¸ ê²½ìš°
            dummy_img = np.zeros((100, 100, 3), dtype=np.uint8)
            return dummy_img, self.get_count_text()

    def find_closest_point(self, x, y, points, threshold=20):
        if not points:
            return None
        distances = [(np.sqrt((x - px) ** 2 + (y - py) ** 2), idx) for idx, (px, py) in enumerate(points)]
        closest_dist, closest_idx = min(distances, key=lambda item: item[0])
        return closest_idx if closest_dist < threshold else None

    def remove_last_point(self, image):
        if self.manual_points:
            removed_point = self.manual_points.pop()
            self.removed_points.append(('manual', removed_point))
        img_with_points = self.draw_points()
        return img_with_points, self.get_count_text()

    def undo_remove(self, image):
        """ì‚­ì œëœ í¬ì¸íŠ¸ ë³µêµ¬ ë©”ì„œë“œ"""
        if not self.removed_points:
            # ë³µêµ¬í•  í¬ì¸íŠ¸ê°€ ì—†ìœ¼ë©´ í˜„ì¬ ì´ë¯¸ì§€ì™€ ì¹´ìš´íŠ¸ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
            return self.current_image, self.get_count_text()
            
        # ê°€ì¥ ìµœê·¼ì— ì‚­ì œëœ í¬ì¸íŠ¸ ë³µêµ¬
        point_type, point = self.removed_points.pop()
        
        if point_type == 'auto':
            self.auto_points.append(point)
            self.auto_detected_count = len(self.auto_points)
        elif point_type == 'manual':
            self.manual_points.append(point)
            
        # í¬ì¸íŠ¸ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸
        img_with_points = self.draw_points()
        return img_with_points, self.get_count_text()

    def get_count_text(self):
        total_count = self.auto_detected_count + len(self.manual_points)
        return (f"ì „ì²´ CFU ìˆ˜: {total_count}\n"
                f"ğŸ¤– ìë™ ê°ì§€ëœ CFU: {self.auto_detected_count}\n"
                f"ğŸ‘† ìˆ˜ë™ ì¶”ê°€ëœ CFU: {len(self.manual_points)}")

    def draw_points(self):
        """
        ì´ë¯¸ì§€ì— ê°ì§€ëœ í¬ì¸íŠ¸ì™€ ì¹´ìš´íŠ¸ë¥¼ ê·¸ë¦½ë‹ˆë‹¤
        
        Return:
            np.ndarray: í¬ì¸íŠ¸ì™€ ì¹´ìš´íŠ¸ê°€ í‘œì‹œëœ ì´ë¯¸ì§€
        """
        # base_imageë‚˜ current_imageê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
        if self.base_image is None and self.current_image is None:
            print("Warning: No image available for drawing points")
            return None
            
        try:
            # ê¸°ë°˜ ì´ë¯¸ì§€(ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë§¤ë²ˆ ìƒˆë¡­ê²Œ ê·¸ë¦¬ê¸°
            if self.base_image is not None:
                img_with_points = self.base_image.copy()
            elif self.current_image is not None:
                img_with_points = self.current_image.copy()
            else:
                print("Warning: Both base_image and current_image are None")
                return None
                
            # ì´ë¯¸ì§€ê°€ Noneì¸ì§€ í™•ì¸
            if img_with_points is None:
                print("Warning: Failed to create a copy of the image")
                return None
                
            overlay = np.zeros_like(img_with_points)
            
            # [ì‚¬ìš©ì ì„¤ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤]
            # 1. ë§ˆì»¤ í¬ê¸° ë° í°íŠ¸ ì„¤ì •
            square_size = 25  # ìˆ˜ë™ í¬ì¸íŠ¸ì˜ ì‚¬ê°í˜• í¬ê¸°
            font = cv2.FONT_HERSHEY_SIMPLEX  # í°íŠ¸ ì¢…ë¥˜
            font_scale = 0.77  # í…ìŠ¤íŠ¸ í¬ê¸°
            font_thickness = 1  # ë‚´ë¶€ í…ìŠ¤íŠ¸ ë‘ê»˜
            outline_thickness = 4  # ì™¸ê³½ì„  ë‘ê»˜

            # 2. ìƒ‰ìƒ ì„¤ì • (B, G, R í˜•ì‹)
            AUTO_TEXT_COLOR = (255, 255, 255)  # ìë™ ê°ì§€ í…ìŠ¤íŠ¸ ìƒ‰ìƒ (í°ìƒ‰)
            AUTO_OUTLINE_COLOR = (0, 0, 0)     # ìë™ ê°ì§€ ì™¸ê³½ì„  ìƒ‰ìƒ (ê²€ì€ìƒ‰)
            MANUAL_RECT_COLOR = (0, 0, 255)    # ìˆ˜ë™ ì¶”ê°€ ì‚¬ê°í˜• ìƒ‰ìƒ (ë¹¨ê°„ìƒ‰)
            MANUAL_BORDER_COLOR = (0, 0, 0)    # ìˆ˜ë™ ì¶”ê°€ í…Œë‘ë¦¬ ìƒ‰ìƒ (ê²€ì€ìƒ‰)
            MANUAL_TEXT_COLOR = (255, 136, 0)  # ìˆ˜ë™ ì¶”ê°€ í…ìŠ¤íŠ¸ ìƒ‰ìƒ (ì£¼í™©ìƒ‰)

            # 3. íˆ¬ëª…ë„ ì„¤ì •
            OVERLAY_OPACITY = 0.4  # ì˜¤ë²„ë ˆì´ íˆ¬ëª…ë„
            
            # ìë™ ê°ì§€ëœ í¬ì¸íŠ¸ í‘œì‹œ (ë…¹ìƒ‰ ì› + ë²ˆí˜¸)
            for idx, (x, y) in enumerate(self.auto_points, 1):
                # ì¢Œí‘œëŠ” ì´ë¯¸ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œê³„ì´ë¯€ë¡œ í˜„ì¬ í™”ë©´ í¬ê¸°ì— ë§ê²Œ ì§ì ‘ í‘œì‹œ
                display_x = x 
                display_y = y
                
                # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°í•˜ì—¬ ì¤‘ì•™ ì •ë ¬
                text = str(idx)
                (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)
                text_x = int(display_x - text_width / 2)
                text_y = int(display_y - 10)
                
                # [ì¤‘ìš”] 8ë°©í–¥ ê²€ì€ìƒ‰ ì™¸ê³½ì„ ìœ¼ë¡œ í…ìŠ¤íŠ¸ ê°€ì‹œì„± í–¥ìƒ
                for dx, dy in [(-1,-1), (-1,0), (-1,1), (0,-1), (0,1), (1,-1), (1,0), (1,1)]:
                    cv2.putText(img_with_points, text, 
                              (text_x + dx, text_y + dy), 
                              font, font_scale, AUTO_OUTLINE_COLOR, outline_thickness)
                
                # í°ìƒ‰ í…ìŠ¤íŠ¸
                cv2.putText(img_with_points, text, (text_x, text_y), 
                          font, font_scale, AUTO_TEXT_COLOR, font_thickness)
                
                # ë…¹ìƒ‰ ì›
                cv2.circle(img_with_points, (display_x, display_y), 5, (0, 255, 0), -1)

            # ìˆ˜ë™ ì¶”ê°€ëœ í¬ì¸íŠ¸ í‘œì‹œ (ë¹¨ê°„ ì‚¬ê°í˜•)
            for idx, (x, y) in enumerate(self.manual_points, len(self.auto_points) + 1):
                # ì¢Œí‘œëŠ” ì´ë¯¸ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œê³„ì´ë¯€ë¡œ í˜„ì¬ í™”ë©´ í¬ê¸°ì— ë§ê²Œ ì§ì ‘ í‘œì‹œ
                display_x = x
                display_y = y
                
                # ì‚¬ê°í˜• ì¢Œí‘œ ê³„ì‚°
                pt1 = (int(display_x - square_size / 2), int(display_y - square_size / 2))
                pt2 = (int(display_x + square_size / 2), int(display_y + square_size / 2))
                
                # ë°˜íˆ¬ëª… ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
                cv2.rectangle(overlay, pt1, pt2, MANUAL_RECT_COLOR, -1)  # ìƒ‰ìƒ ì±„ìš°ê¸°
                cv2.rectangle(overlay, pt1, pt2, MANUAL_BORDER_COLOR, 2)  # í…Œë‘ë¦¬

                # ë²ˆí˜¸ í…ìŠ¤íŠ¸ ì¶”ê°€
                text = str(idx)
                (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)
                text_x = int(display_x - text_width / 2)
                text_y = int(display_y - 10)

                # 8ë°©í–¥ ê²€ì€ìƒ‰ ì™¸ê³½ì„ 
                for dx, dy in [(-1,-1), (-1,0), (-1,1), (0,-1), (0,1), (1,-1), (1,0), (1,1)]:
                    cv2.putText(img_with_points, text,
                              (text_x + dx, text_y + dy),
                              font, font_scale, AUTO_OUTLINE_COLOR, outline_thickness)

                # ì£¼í™©ìƒ‰ í…ìŠ¤íŠ¸
                cv2.putText(img_with_points, text,
                          (text_x, text_y),
                          font, font_scale, MANUAL_TEXT_COLOR, font_thickness)

            # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ë¥¼ ì›ë³¸ê³¼ ë¸”ë Œë”©
            cv2.addWeighted(overlay, OVERLAY_OPACITY, img_with_points, 1.0, 0, img_with_points)

            # ì œê±° ëª¨ë“œ í‘œì‹œ (ìƒë‹¨ì— ë¹¨ê°„ìƒ‰ ë°°ë„ˆ)
            if self.remove_mode:
                # ìƒë‹¨ì— ë¹¨ê°„ìƒ‰ ë°°ë„ˆ ì¶”ê°€
                overlay = img_with_points.copy()
                cv2.rectangle(overlay, (0, 0), (img_with_points.shape[1], 40), MANUAL_RECT_COLOR, -1)
                cv2.addWeighted(overlay, 0.3, img_with_points, 0.7, 0, img_with_points)
                # "REMOVE MODE" í…ìŠ¤íŠ¸ í‘œì‹œ
                cv2.putText(img_with_points, "REMOVE MODE", (10, 30),
                          font, 1, AUTO_TEXT_COLOR, 2)

            # ì „ì²´ ì¹´ìš´íŠ¸ í‘œì‹œ (ì™¼ìª½ í•˜ë‹¨)
            total_count = self.auto_detected_count + len(self.manual_points)
            count_text = f"Total: {total_count}"
            text_size = cv2.getTextSize(count_text, font, 1.5, 3)[0]
            margin = 20
            cv2.rectangle(img_with_points, 
                      (10, img_with_points.shape[0] - text_size[1] - margin * 2),
                      (text_size[0] + margin * 2, img_with_points.shape[0]),
                      (0, 0, 0), -1)
            cv2.putText(img_with_points, count_text, 
                    (margin, img_with_points.shape[0] - margin),
                    font, 1.5, (255, 255, 255), 3)
            
            return img_with_points
        except Exception as e:
            print(f"Error in draw_points: {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ ìµœëŒ€í•œ ì•ˆì „í•˜ê²Œ ë°˜í™˜
            if self.base_image is not None:
                return self.base_image
            if self.current_image is not None:
                return self.current_image
            # ëª¨ë“  ì´ë¯¸ì§€ê°€ Noneì¸ ê²½ìš° ë¹ˆ ì´ë¯¸ì§€ ìƒì„± (100x100 ê²€ì€ìƒ‰)
            print("Creating fallback empty image")
            return np.zeros((100, 100, 3), dtype=np.uint8)

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ (fastsam_prd_v4_okì—ì„œ ê°€ì ¸ì˜´)
def preprocess_image(input_image, to_grayscale, binary_threshold, edge_detection, sharpen):
    if input_image is None:
        return None
    img = np.array(input_image)
    if to_grayscale:
        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    if binary_threshold > 0:
        _, img = cv2.threshold(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), binary_threshold, 255, cv2.THRESH_BINARY)
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    if edge_detection:
        img = cv2.Canny(img, 100, 200)
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    if sharpen > 0:
        kernel = np.array([[0, -sharpen, 0], [-sharpen, 1 + 4*sharpen, -sharpen], [0, -sharpen, 0]])
        img = cv2.filter2D(img, -1, kernel)
    return Image.fromarray(img)

# grok_colony_v1ì˜ ê²€ì¶œ ë¡œì§ ìœ ì§€
def segment_and_count_colonies(
    input_image,
    conf_threshold=0.25,           # AI ì˜ˆì¸¡ ì‹ ë¢°ë„ ì„ê³„ê°’ (ë†’ì„ìˆ˜ë¡ ì—„ê²©)
    iou_threshold=0.7,             # ë§ˆìŠ¤í¬ ì¤‘ë³µ ì„ê³„ê°’ (IoU ê¸°ì¤€)
    circularity_threshold=0.8,     # ìœ¤ê³½ì„ ì˜ ì›í˜•ë„ í•„í„°ë§ ì„ê³„ê°’
    draw_contours=True,            # ìœ¤ê³½ì„  ì‹œê°í™” ì—¬ë¶€
    mask_random_color=True,        # ëœë¤ ì»¬ëŸ¬ ë§ˆìŠ¤í¬ ì—¬ë¶€
    input_size=1024,               # AI ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
    better_quality=False,          # í’ˆì§ˆ í–¥ìƒ ëª¨ë“œ í™œì„±í™” ì—¬ë¶€
    min_area_percentile=1,         # ìµœì†Œ ë©´ì  í•„í„°ë§ ì„ê³„ì¹˜
    max_area_percentile=99,        # ìµœëŒ€ ë©´ì  í•„í„°ë§ ê¸°ì¤€
    use_dish_filtering=False,      # í˜íŠ¸ë¦¬ ì ‘ì‹œ í•„í„°ë§ ì‚¬ìš© ì—¬ë¶€
    dish_overlap_threshold=0.5,    # ë°°ì–‘ ì ‘ì‹œ ì¤‘ì²© ë¹„ìœ¨ ê¸°ì¤€
    device=device,                 # ì¥ì¹˜ ëª…ì‹œí™” (GPU/CPU)
    progress=gr.Progress()
):
    try:
        if input_image is None:
            return None, "ì´ë¯¸ì§€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."
        
        progress(0.1, desc="ì´ˆê¸°í™” ì¤‘...")
        counter.reset()
        counter.set_original_image(input_image)
        
        # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ì €ì¥
        original_width, original_height = input_image.size
        
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ë¹„ìœ¨ ìœ ì§€)
        w, h = input_image.size
        scale = input_size / max(w, h)
        new_w, new_h = int(w * scale), int(h * scale)
        
        # ìŠ¤ì¼€ì¼ ë¹„ìœ¨ ì €ì¥ (ì¢Œí‘œ ë³€í™˜ì— ì‚¬ìš©)
        counter.scale_factor = scale
        
        try:
            input_resized = input_image.resize((new_w, new_h))
        except Exception as e:
            return np.array(input_image), f"ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ì˜¤ë¥˜: {str(e)}"
            
        image_np = np.array(input_resized)

        progress(0.3, desc="AI ë¶„ì„ ì¤‘...")
        try:
            results = model.predict(
                source=image_np,
                device=device,
                conf=conf_threshold,
                iou=iou_threshold,
                imgsz=input_size,
                retina_masks=True
            )
        except Exception as e:
            return image_np, f"AI ëª¨ë¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}"

        # getattr()ë¥¼ ì‚¬ìš©í•´ ë§ˆìŠ¤í¬ ë°ì´í„° ì•ˆì „í•˜ê²Œ ì ‘ê·¼
        annotations = getattr(results[0].masks, 'data', None)
        if annotations is None or len(annotations) == 0:
            return image_np, "CFUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        progress(0.6, desc="ê²°ê³¼ ì²˜ë¦¬ ì¤‘...")
        processed_image = image_np.copy()
        counter.auto_points = []

        # ë°°ì–‘ ì ‘ì‹œ í•„í„°ë§ ì²˜ë¦¬
        dish_mask = None
        dish_idx = -1
        if use_dish_filtering:
            try:
                progress(0.65, desc="ë°°ì–‘ ì ‘ì‹œ ê°ì§€ ì¤‘...")
                # ê°€ì¥ í° ë§ˆìŠ¤í¬ë¥¼ ë°°ì–‘ ì ‘ì‹œë¡œ ì‹ë³„
                if len(annotations) > 0:
                    # ë©´ì  ê³„ì‚°
                    areas = [np.sum(ann.cpu().numpy()) for ann in annotations]
                    dish_idx = np.argmax(areas)
                    dish_annotation = annotations[dish_idx].cpu().numpy()
                    if dish_annotation.ndim == 3 and dish_annotation.shape[0] == 1:
                        dish_annotation = dish_annotation[0]  # (1, H, W) -> (H, W)
                    dish_mask = dish_annotation > 0
                    
                    # ë°°ì–‘ ì ‘ì‹œ ìœ¤ê³½ì„  ì‹œê°í™” (íŒŒë€ìƒ‰)
                    dish_contours, _ = cv2.findContours(dish_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    cv2.drawContours(processed_image, dish_contours, -1, (0, 0, 255), 2)
            except Exception as e:
                print(f"ë°°ì–‘ ì ‘ì‹œ í•„í„°ë§ ì˜¤ë¥˜: {str(e)}")
                # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ì§„í–‰ - ì ‘ì‹œ í•„í„°ë§ ì—†ì´ ê³„ì† ì§„í–‰

        # ë§ˆìŠ¤í¬ ë©´ì  ê³„ì‚° ë° í•„í„°ë§
        all_masks = []
        all_areas = []
        
        try:
            # ëª¨ë“  ì½œë¡œë‹ˆ ë§ˆìŠ¤í¬ ì²˜ë¦¬ (ë°°ì–‘ ì ‘ì‹œ ì œì™¸)
            for idx, mask in enumerate(annotations):
                if idx == dish_idx:  # ë°°ì–‘ ì ‘ì‹œì¸ ê²½ìš° ê±´ë„ˆë›°ê¸°
                    continue
                    
                mask_np = mask.cpu().numpy()
                if mask_np.ndim == 3 and mask_np.shape[0] == 1:
                    mask_np = mask_np[0]  # (1, H, W) -> (H, W) ë³€í™˜
                mask_binary = mask_np > 0
                
                # ë°°ì–‘ ì ‘ì‹œ í•„í„°ë§ ì ìš©
                if use_dish_filtering and dish_mask is not None:
                    # ë°°ì–‘ ì ‘ì‹œ ë‚´ë¶€ ì—¬ë¶€ í™•ì¸ (ë§ˆìŠ¤í¬ êµì§‘í•©)
                    overlap_ratio = np.sum(mask_binary * dish_mask) / np.sum(mask_binary)
                    if overlap_ratio < dish_overlap_threshold:
                        continue  # ë°°ì–‘ ì ‘ì‹œì™€ ì¶©ë¶„íˆ ê²¹ì¹˜ì§€ ì•ŠëŠ” ê²½ìš° ê±´ë„ˆë›°ê¸°
                
                contours, _ = cv2.findContours(mask_binary.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                for contour in contours:
                    area = cv2.contourArea(contour)
                    all_areas.append(area)
                    all_masks.append((mask_binary, contour, area))
                    
            # ë©´ì  ê¸°ì¤€ í•„í„°ë§ ì¤€ë¹„
            if all_areas:
                min_area = np.percentile(all_areas, min_area_percentile)
                max_area = np.percentile(all_areas, max_area_percentile)
            else:
                min_area = 0
                max_area = float('inf')
            
            # í–¥ìƒëœ í’ˆì§ˆ ì„¤ì • ì ìš©
            if better_quality:
                # ë” ì •êµí•œ ìœ¤ê³½ì„  ê·¸ë¦¬ê¸° (ë‘ê»˜ ì¡°ì •)
                contour_thickness = 2
                # ë” ì„ ëª…í•œ ìƒ‰ìƒ ì‚¬ìš©
                color_min = 120
                color_max = 255
            else:
                contour_thickness = 2
                color_min = 100
                color_max = 200
            
            # í•„í„°ë§ëœ ë§ˆìŠ¤í¬ ì²˜ë¦¬ (ë©´ì  ë° ì›í˜•ë„ ê¸°ë°˜)
            for mask_np, contour, area in all_masks:
                if min_area <= area <= max_area:
                    # ì›í˜•ë„ ê³„ì‚° (4Ï€ Ã— area / perimeterÂ²)
                    perimeter = cv2.arcLength(contour, True)
                    circularity = 4 * np.pi * (area / (perimeter ** 2)) if perimeter > 0 else 0
                    
                    # ì›í˜•ë„ ì„ê³„ê°’ ì´ìƒì˜ ìœ¤ê³½ì„ ë§Œ í•„í„°ë§
                    if perimeter > 0 and circularity >= circularity_threshold:
                        # ì¤‘ì‹¬ì  ê³„ì‚°
                        M = cv2.moments(contour)
                        if M["m00"] != 0:
                            cX = int(M["m10"] / M["m00"])
                            cY = int(M["m01"] / M["m00"])
                            counter.auto_points.append((cX, cY))
                            
                            # ì½œë¡œë‹ˆ ìœ¤ê³½ì„  ì‹œê°í™”
                            if draw_contours:
                                color = tuple(np.random.randint(color_min, color_max, 3).tolist()) if mask_random_color else (0, 255, 0)
                                cv2.drawContours(processed_image, [contour], -1, color, contour_thickness)
                                
                                # ë§ˆìŠ¤í¬ ë‚´ë¶€ ì±„ìš°ê¸° (ì„ íƒì )
                                if mask_random_color:
                                    # ì£¼ì„: ì´ ë¶€ë¶„ì€ ë§ˆìŠ¤í¬ ë‚´ë¶€ë¥¼ ì±„ìš°ëŠ” ì½”ë“œì§€ë§Œ
                                    # í˜„ì¬ëŠ” ìœ¤ê³½ì„ ë§Œ ê·¸ë¦¬ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬
                                    # ì›í•˜ëŠ” ê²½ìš° í™œì„±í™”í•˜ì—¬ ë‚´ë¶€ ì±„ìš°ê¸° ê°€ëŠ¥
                                    # color_alpha = tuple(list(color) + [64])  # RGB + Alpha
                                    # processed_image[mask_np] = color[:3]
                                    pass
        except Exception as e:
            print(f"ì½œë¡œë‹ˆ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            # ì´ë¯¸ ì°¾ì€ auto_pointsëŠ” ìœ ì§€

        # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„±
        progress(0.9, desc="ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        try:
            # ì¹´ìš´í„° ì •ë³´ ì—…ë°ì´íŠ¸
            counter.auto_detected_count = len(counter.auto_points)
            
            # ì•ˆì „ ê²€ì‚¬: processed_imageê°€ Noneì´ë©´ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©
            if processed_image is None:
                print("Warning: processed_image is None, using original image instead")
                processed_image = image_np.copy()
                
            # ê¸°ë³¸ ì´ë¯¸ì§€ ì €ì¥
            counter.base_image = processed_image  # í¬ì¸íŠ¸ ì—†ëŠ” ê¸°ë³¸ ì²˜ë¦¬ ì´ë¯¸ì§€ ì €ì¥
            
            # í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
            counter.current_image = counter.draw_points()
            if counter.current_image is None:
                print("Warning: draw_points returned None, using processed_image instead")
                counter.current_image = processed_image
            
            # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ê²°ê³¼ ì´ë¯¸ì§€ ì¡°ì •
            try:
                img_with_points_pil = Image.fromarray(counter.current_image)
                try:
                    # PIL 9.0.0 ì´ìƒ
                    resampling_filter = Image.Resampling.LANCZOS
                except AttributeError:
                    # PIL 9.0.0 ë¯¸ë§Œ
                    resampling_filter = Image.LANCZOS
                img_with_points_resized = img_with_points_pil.resize((original_width, original_height), resampling_filter)
                return np.array(img_with_points_resized), counter.get_count_text()
            except Exception as e:
                print(f"Error during image resizing: {str(e)}")
                # í¬ê¸° ì¡°ì • ì‹¤íŒ¨ ì‹œ ì›ë³¸ í¬ê¸° ê·¸ëŒ€ë¡œ ë°˜í™˜
                return counter.current_image, counter.get_count_text()
                
        except Exception as e:
            print(f"ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
            if input_image is not None:
                try:
                    # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ NumPy ë°°ì—´ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
                    original_np = np.array(input_image)
                    return original_np, f"ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {str(e)}"
                except:
                    # ëª¨ë“  ë³€í™˜ ì‹¤íŒ¨ ì‹œ ë¹ˆ ì´ë¯¸ì§€ ìƒì„±
                    dummy_img = np.zeros((100, 100, 3), dtype=np.uint8)
                    return dummy_img, f"ì‹¬ê°í•œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
            # ì…ë ¥ ì´ë¯¸ì§€ ìì²´ê°€ Noneì¸ ê²½ìš°
            dummy_img = np.zeros((100, 100, 3), dtype=np.uint8)
            return dummy_img, f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    except Exception as e:
        print(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return np.array(input_image) if input_image else None, f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ê²°ê³¼ ì €ì¥ í•¨ìˆ˜ (ì›ë³¸ê³¼ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥)
def save_results(original_image, processed_image):
    try:
        # ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í„°ë¦¬ ì„¤ì •
        output_dir = "outputs"
        try:
            os.makedirs(output_dir, exist_ok=True)
        except Exception as e:
            return f"ê²°ê³¼ í´ë” ìƒì„± ì˜¤ë¥˜: {str(e)}"
            
        # íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ê³ ìœ  ID ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        result_dir = os.path.join(output_dir, f"result_{timestamp}")
        os.makedirs(result_dir, exist_ok=True)
        
        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        original_path = os.path.join(result_dir, f"original.png")
        processed_path = os.path.join(result_dir, f"ì¹´ìš´íŒ…ì™„ë£Œ.png")
        
        # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥
        try:
            if original_image is not None:
                original_image.save(original_path)
            else:
                return "ì›ë³¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤."
        except Exception as e:
            return f"ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ ì˜¤ë¥˜: {str(e)}"
            
        # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì €ì¥
        try:
            if processed_image is not None:
                Image.fromarray(processed_image).save(processed_path)
            else:
                return "ì²˜ë¦¬ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤."
        except Exception as e:
            if os.path.exists(original_path):
                # ì ì–´ë„ ì›ë³¸ì€ ì €ì¥í–ˆë‹¤ë©´ ì•Œë ¤ì¤Œ
                return f"ì›ë³¸ì€ ì €ì¥ë˜ì—ˆìœ¼ë‚˜ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n- ì›ë³¸: {original_path}"
            return f"ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ì˜¤ë¥˜: {str(e)}"
        
        # ê²°ê³¼ ì •ë³´ ì €ì¥ (JSON í˜•ì‹)
        result_info = {
            'date': datetime.now().strftime("%Y-%m-%d"),
            'time': datetime.now().strftime("%H:%M:%S"),
            'auto_count': counter.auto_detected_count,
            'manual_count': len(counter.manual_points),
            'total_count': counter.auto_detected_count + len(counter.manual_points),
            'original_image': original_path,
            'processed_image': processed_path
        }
        
        # JSON íŒŒì¼ ì €ì¥
        json_path = os.path.join(result_dir, "result.json")
        try:
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(result_info, f, indent=4)
        except Exception as e:
            print(f"JSON ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
            
        return f"ì €ì¥ ì™„ë£Œ:\n- ê²°ê³¼ í´ë”: {result_dir}\n- ì›ë³¸: {original_path}\n- ê²°ê³¼: {processed_path}"
    
    except Exception as e:
        return f"ì €ì¥ ê³¼ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜ ì¶”ê°€
def batch_process_images(
    folder_path,
    conf_threshold=0.25,
    iou_threshold=0.7,
    circularity_threshold=0.8,
    draw_contours=True,
    mask_random_color=True,
    input_size=1024,
    better_quality=False,
    min_area_percentile=1,
    max_area_percentile=99,
    use_dish_filtering=False,
    dish_overlap_threshold=0.5,
    progress=gr.Progress()
):
    try:
        # í´ë” ê²½ë¡œ ìœ íš¨ì„± ê²€ì‚¬
        if not folder_path or not os.path.exists(folder_path):
            return "í´ë” ê²½ë¡œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        
        # ì§€ì›í•˜ëŠ” ì´ë¯¸ì§€ í™•ì¥ì
        valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']
        
        # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        image_files = []
        for ext in valid_extensions:
            image_files.extend(glob.glob(os.path.join(folder_path, f"*{ext}")))
            image_files.extend(glob.glob(os.path.join(folder_path, f"*{ext.upper()}")))
        
        if not image_files:
            return "í´ë”ì— ì²˜ë¦¬í•  ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
        
        # ê²°ê³¼ ì €ì¥ í´ë” ìƒì„±
        try:
            batch_output_dir = os.path.join("outputs", f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
            os.makedirs(batch_output_dir, exist_ok=True)
        except Exception as e:
            return f"ê²°ê³¼ í´ë” ìƒì„± ì˜¤ë¥˜: {str(e)}"
        
        # ê²°ê³¼ CSV íŒŒì¼ ìƒì„±
        csv_path = os.path.join(batch_output_dir, "results.csv")
        results_data = []
        
        total_files = len(image_files)
        processed_count = 0
        error_count = 0
        
        progress(0, desc=f"ì´ {total_files}ê°œ íŒŒì¼ ì²˜ë¦¬ ì¤€ë¹„ ì¤‘...")
        
        for idx, img_path in enumerate(image_files):
            try:
                file_name = os.path.basename(img_path)
                progress(idx/total_files, desc=f"ì²˜ë¦¬ ì¤‘: {file_name} ({idx+1}/{total_files})")
                
                # ì´ë¯¸ì§€ ë¡œë“œ
                try:
                    img = Image.open(img_path)
                except Exception as e:
                    error_count += 1
                    print(f"ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜ ({file_name}): {str(e)}")
                    results_data.append({
                        'FileName': file_name,
                        'FilePath': img_path,
                        'TotalCount': 'ERROR',
                        'AutoCount': 'ERROR',
                        'ManualCount': 'ERROR',
                        'ResultPath': 'ERROR',
                        'Error': f"ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜: {str(e)}"
                    })
                    continue
                
                # ì´ë¯¸ì§€ ë¶„ì„
                try:
                    result_img, count_text = segment_and_count_colonies(
                        img,
                        conf_threshold=conf_threshold,
                        iou_threshold=iou_threshold,
                        circularity_threshold=circularity_threshold,
                        draw_contours=draw_contours,
                        mask_random_color=mask_random_color,
                        input_size=input_size,
                        better_quality=better_quality,
                        min_area_percentile=min_area_percentile,
                        max_area_percentile=max_area_percentile,
                        use_dish_filtering=use_dish_filtering,
                        dish_overlap_threshold=dish_overlap_threshold
                    )
                except Exception as e:
                    error_count += 1
                    print(f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜ ({file_name}): {str(e)}")
                    results_data.append({
                        'FileName': file_name,
                        'FilePath': img_path,
                        'TotalCount': 'ERROR',
                        'AutoCount': 'ERROR',
                        'ManualCount': 'ERROR',
                        'ResultPath': 'ERROR',
                        'Error': f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
                    })
                    continue
                
                # ê²°ê³¼ í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ
                try:
                    count_lines = count_text.split('\n')
                    total_count = int(count_lines[0].split(': ')[1]) if len(count_lines) > 0 else 0
                    auto_count = int(count_lines[1].split(': ')[1]) if len(count_lines) > 1 else 0
                    manual_count = int(count_lines[2].split(': ')[1]) if len(count_lines) > 2 else 0
                except Exception as e:
                    print(f"ì¹´ìš´íŠ¸ í…ìŠ¤íŠ¸ íŒŒì‹± ì˜¤ë¥˜ ({file_name}): {str(e)}")
                    total_count = -1
                    auto_count = -1
                    manual_count = -1
                
                # ê²°ê³¼ ì €ì¥
                try:
                    result_file_path = os.path.join(batch_output_dir, f"result_{file_name}")
                    Image.fromarray(result_img).save(result_file_path)
                except Exception as e:
                    print(f"ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜ ({file_name}): {str(e)}")
                    result_file_path = "ì €ì¥ ì‹¤íŒ¨"
                
                # CSV ë°ì´í„° ì¶”ê°€
                results_data.append({
                    'FileName': file_name,
                    'FilePath': img_path,
                    'TotalCount': total_count,
                    'AutoCount': auto_count,
                    'ManualCount': manual_count,
                    'ResultPath': result_file_path
                })
                
                processed_count += 1
                
            except Exception as e:
                error_count += 1
                print(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ({file_name}): {str(e)}")
                results_data.append({
                    'FileName': file_name,
                    'FilePath': img_path,
                    'TotalCount': 'ERROR',
                    'AutoCount': 'ERROR',
                    'ManualCount': 'ERROR',
                    'ResultPath': 'ERROR',
                    'Error': str(e)
                })
        
        # CSV íŒŒì¼ë¡œ ê²°ê³¼ ì €ì¥
        try:
            df = pd.DataFrame(results_data)
            df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        except Exception as e:
            print(f"CSV ì €ì¥ ì˜¤ë¥˜: {str(e)}")
            return f"ì²˜ë¦¬ ì™„ë£Œ ({processed_count}/{total_files} ì„±ê³µ) í•˜ì˜€ìœ¼ë‚˜ CSV ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        
        progress(1.0, desc="ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
        
        summary = (
            f"ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!\n"
            f"- ì´ íŒŒì¼ ìˆ˜: {total_files}\n"
            f"- ì„±ê³µ: {processed_count}\n"
            f"- ì‹¤íŒ¨: {error_count}\n"
            f"- ê²°ê³¼ í´ë”: {batch_output_dir}\n"
            f"- ê²°ê³¼ CSV: {csv_path}"
        )
        
        return summary
    
    except Exception as e:
        print(f"ë°°ì¹˜ ì²˜ë¦¬ ì „ì²´ ì˜¤ë¥˜: {str(e)}")
        return f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# UI ë””ìì¸ (fastsam_prd_v4_ok ê¸°ë°˜)
css = """
body { font-family: Arial, sans-serif; background-color: #f0f0f0; }
.button-primary { 
    background-color: #4CAF50; 
    color: white; 
    border: none; 
    padding: 10px 20px; 
    border-radius: 5px; 
    transition: all 0.3s ease;
}
.button-primary:hover { 
    background-color: #45a049; 
    transform: translateY(-2px);
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
}
.button-secondary {
    background-color: #f1f1f1;
    color: #333;
    border: 1px solid #ddd;
    padding: 8px 16px;
    border-radius: 4px;
    transition: all 0.3s ease;
}
.button-secondary:hover {
    background-color: #e0e0e0;
    transform: translateY(-1px);
}
.result-text { 
    background: #fff; 
    border-left: 5px solid #4CAF50; 
    padding: 10px; 
    border-radius: 0 4px 4px 0;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
}
.accordion-header {
    font-weight: bold;
    color: #333;
}
.section-title {
    font-size: 1.2em;
    font-weight: bold;
    color: #2E7D32;
    margin-bottom: 10px;
    padding-bottom: 5px;
    border-bottom: 2px solid #4CAF50;
}
.filtering-active {
    background-color: #e8f5e9;
    color: #2E7D32;
    padding: 3px 6px;
    border-radius: 4px;
    font-weight: bold;
    display: inline-block;
    animation: pulse 2s infinite;
}
@keyframes pulse {
    0% { opacity: 0.7; }
    50% { opacity: 1; }
    100% { opacity: 0.7; }
}
.footer {
    text-align: center;
    margin-top: 20px;
    padding: 10px;
    color: #666;
    font-size: 0.9em;
    border-top: 1px solid #eee;
}
.manual-edit-row {
    align-items: center;
    justify-content: center;
    gap: 10px;
    margin-top: 10px;
    margin-bottom: 10px;
}
.manual-edit-btn {
    background-color: #f1f1f1;
    color: #333;
    border: 1px solid #ddd;
    padding: 8px 16px;
    border-radius: 4px;
    transition: all 0.3s ease;
}
.manual-edit-btn:hover {
    background-color: #e0e0e0;
    transform: translateY(-1px);
}
.manual-edit-status {
    font-weight: bold;
    text-align: center;
    border: none;
    background-color: #fff;
    color: #2E7D32;
    padding: 8px 12px;
}
"""

counter = ColonyCounter()

with gr.Blocks(theme=gr.themes.Default(), css=css) as demo:
    gr.Markdown("""
    # ğŸ”¬ Colony Counter
    ## **AI ê¸°ë°˜ CFU ìë™ ê°ì§€ ë° ìˆ˜ë™ í¸ì§‘**
    
    ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë°°ì–‘ì ‘ì‹œì˜ CFU(Colony Forming Units)ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ì¹´ìš´íŒ…í•©ë‹ˆë‹¤.
    ì‚¬ìš©ìëŠ” ìë™ ê°ì§€ ê²°ê³¼ë¥¼ ìˆ˜ë™ìœ¼ë¡œ í¸ì§‘í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.    
    
    """)
    
    with gr.Tabs() as tabs:
        with gr.TabItem("ğŸ” ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„"):
            with gr.Row():
                with gr.Column():
                    gr.Markdown("<div class='section-title'>ğŸ“ ì´ë¯¸ì§€ ì—…ë¡œë“œ</div>")
                    input_image = gr.Image(type="pil", label="ì´ë¯¸ì§€ ì—…ë¡œë“œ")
                    
                    with gr.Accordion("ğŸ› ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬", open=False, elem_classes="accordion-header"):
                        gr.Markdown("ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê¸° ì „ì— ì „ì²˜ë¦¬ ì˜µì…˜ì„ ì ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        to_grayscale = gr.Checkbox(label="í‘ë°± ë³€í™˜", value=False, info="ì´ë¯¸ì§€ë¥¼ í‘ë°±ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
                        binary_threshold = gr.Slider(0, 255, 0, label="ë°”ì´ë„ˆë¦¬ ì„ê³„ê°’", info="0ë³´ë‹¤ í¬ë©´ ì´ì§„í™”ë¥¼ ì ìš©í•©ë‹ˆë‹¤.")
                        edge_detection = gr.Checkbox(label="ì—ì§€ ê²€ì¶œ", value=False, info="ì´ë¯¸ì§€ì˜ ì—ì§€ë¥¼ ê²€ì¶œí•©ë‹ˆë‹¤.")
                        sharpen = gr.Slider(0, 1, 0, label="ìƒ¤í”ˆ ê°•ë„", info="ì´ë¯¸ì§€ì˜ ì„ ëª…ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.")
                        
                        with gr.Row():
                            preprocess_btn = gr.Button("ì „ì²˜ë¦¬ ì ìš©", variant="secondary", elem_classes="button-secondary")
                            reset_btn = gr.Button("ì´ˆê¸°í™”", variant="secondary", elem_classes="button-secondary")
                            undo_btn = gr.Button("ì‹¤í–‰ ì·¨ì†Œ", variant="secondary", elem_classes="button-secondary")
                    
                    # FastSAM ë¶„ì„ ì„¤ì • ì¶”ê°€
                    with gr.Accordion("âš™ï¸ ë¶„ì„ ì„¤ì • [ë°°ì–‘ ì ‘ì‹œ í•„í„°ë§ í™œì„±í™”ë¨]", open=False, elem_classes="accordion-header") as analysis_accordion:
                        analysis_setting_title = gr.Markdown("FastSAM AI ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì—¬ CFU ê°ì§€ ê²°ê³¼ë¥¼ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        
                        with gr.Tab("ì¼ë°˜"):
                            input_size_slider = gr.Slider(
                                512, 2048, 1024,
                                step=64,
                                label="ì…ë ¥ í¬ê¸°",
                                info="í¬ê¸°ê°€ í´ìˆ˜ë¡ ì •í™•ë„ê°€ ë†’ì•„ì§€ì§€ë§Œ ì†ë„ëŠ” ëŠë ¤ì§‘ë‹ˆë‹¤."
                            )
                            better_quality_checkbox = gr.Checkbox(
                                label="í–¥ìƒëœ í’ˆì§ˆ",
                                value=False,
                                info="ì†ë„ë¥¼ í¬ìƒí•˜ê³  ì¶œë ¥ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤."
                            )
                            withContours_checkbox = gr.Checkbox(
                                label="ìœ¤ê³½ì„  í‘œì‹œ",
                                value=True,
                                info="CFUì˜ ê²½ê³„ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."
                            )
                            mask_random_color_checkbox = gr.Checkbox(
                                label="ëœë¤ ìƒ‰ìƒ",
                                value=True,
                                info="CFU ë§ˆìŠ¤í¬ì— ëœë¤ ìƒ‰ìƒì„ ì ìš©í•©ë‹ˆë‹¤."
                            )

                        with gr.Tab("AI íƒì§€"):
                            iou_threshold_slider = gr.Slider(
                                0.1, 0.9, 0.7,
                                step=0.1,
                                label="IOU ì„ê³„ê°’",
                                info="ë†’ì„ìˆ˜ë¡ ê²¹ì¹¨ ê¸°ì¤€ì´ ì—„ê²©í•´ì§‘ë‹ˆë‹¤."
                            )
                            conf_threshold_slider = gr.Slider(
                                0.1, 0.9, 0.25,
                                step=0.05,
                                label="ì‹ ë¢°ë„ ì„ê³„ê°’",
                                info="ë†’ì„ìˆ˜ë¡ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íƒì§€ë§Œ í‘œì‹œë©ë‹ˆë‹¤."
                            )
                            circularity_threshold_slider = gr.Slider(
                                0.0, 1.0, 0.8,
                                step=0.01,
                                label="ì›í˜•ë„ ì„ê³„ê°’",
                                info="ëŒ€ëµì ìœ¼ë¡œ ì›í˜•ì¸ CFUë§Œ ê°ì§€í•©ë‹ˆë‹¤ (1 = ì™„ë²½í•œ ì›)."
                            )

                        with gr.Tab("í¬ê¸° í•„í„°"):
                            min_area_percentile_slider = gr.Slider(
                                0, 10, 1,
                                step=1,
                                label="ìµœì†Œ í¬ê¸° ë°±ë¶„ìœ„ìˆ˜",
                                info="ë” ì‘ì€ CFUë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤ (1ì€ ê°€ì¥ ì‘ì€ 1% í•„í„°ë§)."
                            )
                            max_area_percentile_slider = gr.Slider(
                                90, 100, 99,
                                step=1,
                                label="ìµœëŒ€ í¬ê¸° ë°±ë¶„ìœ„ìˆ˜",
                                info="ë” í° ê°ì²´ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤ (99ëŠ” ê°€ì¥ í° 1% í•„í„°ë§)."
                            )

                        with gr.Tab("ë°°ì–‘ ì ‘ì‹œ í•„í„°ë§"):
                            gr.Markdown("""
                            ë°°ì–‘ ì ‘ì‹œ í•„í„°ë§ì€ ì´ë¯¸ì§€ì—ì„œ ê°€ì¥ í° ë§ˆìŠ¤í¬ë¥¼ ë°°ì–‘ ì ‘ì‹œë¡œ ì‹ë³„í•˜ê³ , í•´ë‹¹ ë°°ì–‘ ì ‘ì‹œ ë‚´ë¶€ì— ìˆëŠ” CFUë§Œ ì¹´ìš´íŒ…í•©ë‹ˆë‹¤.
                            ì´ ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš°ì— ìœ ìš©í•©ë‹ˆë‹¤:
                            - ë°°ê²½ì— ë…¸ì´ì¦ˆê°€ ë§ì€ ì´ë¯¸ì§€
                            - ë°°ì–‘ ì ‘ì‹œ ì™¸ë¶€ì˜ ì˜¤íƒì§€ë¥¼ ì œê±°í•˜ê³  ì‹¶ì„ ë•Œ
                            - ì—¬ëŸ¬ ì ‘ì‹œê°€ í•œ ì´ë¯¸ì§€ì— ìˆëŠ” ê²½ìš° ê°€ì¥ í° ì ‘ì‹œë§Œ ë¶„ì„í•˜ê³  ì‹¶ì„ ë•Œ
                            
                            í™œì„±í™”í•˜ë©´ ë°°ì–‘ ì ‘ì‹œ ìœ¤ê³½ì„ ì´ íŒŒë€ìƒ‰ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.
                            """)
                            use_dish_filtering_checkbox = gr.Checkbox(
                                label="ë°°ì–‘ ì ‘ì‹œ í•„í„°ë§ ì‚¬ìš©",
                                value=True,
                                info="ê°€ì¥ í° ì˜ì—­ì„ ë°°ì–‘ ì ‘ì‹œë¡œ ì¸ì‹í•˜ê³  ë‚´ë¶€ CFUë§Œ ê°ì§€í•©ë‹ˆë‹¤."
                            )
                            dish_overlap_threshold_slider = gr.Slider(
                                0.1, 1.0, 0.5,
                                step=0.1,
                                label="ë°°ì–‘ ì ‘ì‹œ ê²¹ì¹¨ ì„ê³„ê°’",
                                info="CFUê°€ ë°°ì–‘ ì ‘ì‹œì™€ ìµœì†Œí•œ ì´ ë¹„ìœ¨ë§Œí¼ ê²¹ì³ì•¼ í•©ë‹ˆë‹¤ (0.5 = 50%)."
                            )
                        
                    analyze_btn = gr.Button("ğŸ” ë¶„ì„ ì‹œì‘", variant="primary", elem_classes="button-primary")
                
                with gr.Column():
                    gr.Markdown("<div class='section-title'>ğŸ“Š ë¶„ì„ ê²°ê³¼</div>")
                    output_image = gr.Image(type="numpy", interactive=True, label="ê²°ê³¼ ì´ë¯¸ì§€")
                    count_text = gr.Textbox(label="ì¹´ìš´íŠ¸ ê²°ê³¼", elem_classes="result-text")
                    
                    gr.Markdown("### ìˆ˜ë™ í¸ì§‘")
                    gr.Markdown("ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ í´ë¦­í•˜ì—¬ í¬ì¸íŠ¸ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì œê±°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    
                    with gr.Row(elem_classes="manual-edit-row"):
                        remove_mode_btn = gr.Button("ğŸ”„ ëª¨ë“œ ì „í™˜", variant="secondary", elem_classes="manual-edit-btn")
                        mode_text = gr.Textbox(value="ğŸŸ¢ ADD MODE", interactive=False, elem_classes="manual-edit-status", show_label=False)
                        remove_last_btn = gr.Button("â†©ï¸ ìµœê·¼ í¬ì¸íŠ¸ ì‚­ì œ", variant="secondary", elem_classes="manual-edit-btn")
                        undo_remove_btn = gr.Button("ğŸ”„ ì‚­ì œ ì·¨ì†Œ", variant="secondary", elem_classes="manual-edit-btn")
                    
                    save_btn = gr.Button("ğŸ’¾ ê²°ê³¼ ì €ì¥", variant="primary", elem_classes="button-primary")
                    save_output = gr.Textbox(label="ì €ì¥ ê²°ê³¼", interactive=False, elem_classes="result-text")
        
        with gr.TabItem("ğŸ“Š ë°°ì¹˜ ì²˜ë¦¬"):
            gr.Markdown("""
            <div class='section-title'>ğŸ“Š ë°°ì¹˜ ì²˜ë¦¬</div>
            <p>ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ì—¬ ì‹œê°„ì„ ì ˆì•½í•˜ì„¸ìš”.</p>
            """)
            
            with gr.Tabs():
                with gr.TabItem("ğŸ“‚ í´ë” ì„ íƒ"):
                    folder_path_input = gr.Textbox(label="ì´ë¯¸ì§€ í´ë” ê²½ë¡œ", placeholder="ì˜ˆ: /path/to/images")
                    gr.Markdown("í´ë” ë‚´ì˜ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼(.jpg, .jpeg, .png, .bmp, .tiff, .webp)ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                
                with gr.TabItem("ğŸ–¼ï¸ íŒŒì¼ ì„ íƒ"):
                    batch_files = gr.File(file_count="multiple", label="ì´ë¯¸ì§€ íŒŒì¼ ì„ íƒ", file_types=["image"])
                    gr.Markdown("ì—¬ëŸ¬ ì´ë¯¸ì§€ íŒŒì¼ì„ ì§ì ‘ ì„ íƒí•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            
            with gr.Accordion("âš™ï¸ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •", open=False):
                with gr.Row():
                    batch_input_size = gr.Slider(
                        512, 2048, 1024,
                        step=64,
                        label="ì…ë ¥ í¬ê¸°",
                        info="í¬ê¸°ê°€ í´ìˆ˜ë¡ ì •í™•ë„ê°€ ë†’ì•„ì§€ì§€ë§Œ ì†ë„ëŠ” ëŠë ¤ì§‘ë‹ˆë‹¤."
                    )
                    batch_better_quality = gr.Checkbox(
                        label="í–¥ìƒëœ í’ˆì§ˆ",
                        value=False,
                        info="ì†ë„ë¥¼ í¬ìƒí•˜ê³  ì¶œë ¥ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤."
                    )
                
                with gr.Row():
                    batch_iou_threshold = gr.Slider(
                        0.1, 0.9, 0.7,
                        step=0.1,
                        label="IOU ì„ê³„ê°’",
                        info="ë†’ì„ìˆ˜ë¡ ê²¹ì¹¨ ê¸°ì¤€ì´ ì—„ê²©í•´ì§‘ë‹ˆë‹¤."
                    )
                    batch_conf_threshold = gr.Slider(
                        0.1, 0.9, 0.25,
                        step=0.05,
                        label="ì‹ ë¢°ë„ ì„ê³„ê°’",
                        info="ë†’ì„ìˆ˜ë¡ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íƒì§€ë§Œ í‘œì‹œë©ë‹ˆë‹¤."
                    )
                
                with gr.Row():
                    batch_min_area_percentile = gr.Slider(
                        0, 10, 1,
                        step=1,
                        label="ìµœì†Œ í¬ê¸° ë°±ë¶„ìœ„ìˆ˜",
                        info="ë” ì‘ì€ CFUë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤."
                    )
                    batch_max_area_percentile = gr.Slider(
                        90, 100, 99,
                        step=1,
                        label="ìµœëŒ€ í¬ê¸° ë°±ë¶„ìœ„ìˆ˜",
                        info="ë” í° ê°ì²´ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤."
                    )
                
                batch_circularity_threshold = gr.Slider(
                    0.0, 1.0, 0.8,
                    step=0.01,
                    label="ì›í˜•ë„ ì„ê³„ê°’",
                    info="ëŒ€ëµì ìœ¼ë¡œ ì›í˜•ì¸ CFUë§Œ ê°ì§€í•©ë‹ˆë‹¤."
                )
                
                batch_use_dish_filtering = gr.Checkbox(
                    label="ë°°ì–‘ ì ‘ì‹œ í•„í„°ë§ ì‚¬ìš©",
                    value=True,
                    info="ê°€ì¥ í° ì˜ì—­ì„ ë°°ì–‘ ì ‘ì‹œë¡œ ì¸ì‹í•˜ê³  ë‚´ë¶€ CFUë§Œ ê°ì§€í•©ë‹ˆë‹¤."
                )
                
                batch_dish_overlap_threshold = gr.Slider(
                    0.1, 1.0, 0.5,
                    step=0.1,
                    label="ë°°ì–‘ ì ‘ì‹œ ê²¹ì¹¨ ì„ê³„ê°’",
                    info="CFUê°€ ë°°ì–‘ ì ‘ì‹œì™€ ìµœì†Œí•œ ì´ ë¹„ìœ¨ë§Œí¼ ê²¹ì³ì•¼ í•©ë‹ˆë‹¤."
                )
            
            with gr.Row():
                batch_process_folder_btn = gr.Button("ğŸ“‚ í´ë” ì²˜ë¦¬ ì‹œì‘", variant="primary", elem_classes="button-primary")
                batch_process_files_btn = gr.Button("ğŸ–¼ï¸ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘", variant="primary", elem_classes="button-primary")
                open_output_btn = gr.Button("ğŸ“‚ ê²°ê³¼ í´ë” ì—´ê¸°", variant="secondary", elem_classes="button-secondary")
            
            batch_summary_output = gr.Textbox(label="ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼", interactive=False, elem_classes="result-text", lines=10)
            
            # ê²°ê³¼ í´ë” ì—´ê¸° í•¨ìˆ˜
            def open_output_folder():
                import webbrowser
                output_dir = os.path.abspath("outputs")
                webbrowser.open(f"file://{output_dir}")
                return "ê²°ê³¼ í´ë”ë¥¼ ì—´ì—ˆìŠµë‹ˆë‹¤."

    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
    input_image.upload(
        lambda img: (image_history.set_original(img), "ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ"),
        inputs=input_image,
        outputs=[input_image, count_text]
    )

    preprocess_btn.click(
        preprocess_image,
        inputs=[input_image, to_grayscale, binary_threshold, edge_detection, sharpen],
        outputs=input_image
    ).then(
        lambda img: image_history.add_state(img),
        inputs=input_image,
        outputs=input_image
    )

    reset_btn.click(
        lambda: image_history.reset(),
        inputs=[],
        outputs=input_image
    )

    undo_btn.click(
        lambda: image_history.undo(),
        inputs=[],
        outputs=input_image
    )

    analyze_btn.click(
        segment_and_count_colonies,
        inputs=[
            input_image,
            conf_threshold_slider,
            iou_threshold_slider,
            circularity_threshold_slider,
            withContours_checkbox,
            mask_random_color_checkbox,
            input_size_slider,
            better_quality_checkbox,
            min_area_percentile_slider,
            max_area_percentile_slider,
            use_dish_filtering_checkbox,
            dish_overlap_threshold_slider
        ],
        outputs=[output_image, count_text]
    )

    output_image.select(
        counter.add_or_remove_point,
        inputs=[output_image],
        outputs=[output_image, count_text]
    )

    remove_mode_btn.click(
        counter.toggle_remove_mode,
        inputs=[],
        outputs=[output_image, mode_text]
    )

    remove_last_btn.click(
        counter.remove_last_point,
        inputs=[output_image],
        outputs=[output_image, count_text]
    )

    undo_remove_btn.click(
        counter.undo_remove,
        inputs=[output_image],
        outputs=[output_image, count_text]
    )

    save_btn.click(
        save_results,
        inputs=[input_image, output_image],
        outputs=save_output
    )
    
    # ë°°ì–‘ ì ‘ì‹œ í•„í„°ë§ ìƒíƒœì— ë”°ë¼ ì œëª© ì—…ë°ì´íŠ¸
    def update_title(is_enabled):
        try:
            if is_enabled:
                return gr.Accordion.update(label="âš™ï¸ ë¶„ì„ ì„¤ì • [ë°°ì–‘ ì ‘ì‹œ í•„í„°ë§ í™œì„±í™”ë¨]")
            else:
                return gr.Accordion.update(label="âš™ï¸ ë¶„ì„ ì„¤ì •")
        except Exception as e:
            print(f"update_title ì˜¤ë¥˜: {str(e)}")
            return gr.Accordion.update(label="âš™ï¸ ë¶„ì„ ì„¤ì •")
    
    use_dish_filtering_checkbox.change(
        update_title,
        inputs=[use_dish_filtering_checkbox],
        outputs=[analysis_accordion]
    )
    
    # íŒŒì¼ ê¸°ë°˜ ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
    def batch_process_files(
        files,
        conf_threshold,
        iou_threshold,
        circularity_threshold,
        draw_contours,
        mask_random_color,
        input_size,
        better_quality,
        min_area_percentile,
        max_area_percentile,
        use_dish_filtering,
        dish_overlap_threshold,
        progress=gr.Progress()
    ):
        try:
            if not files:
                return "ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
            
            # ê²°ê³¼ ì €ì¥ í´ë” ìƒì„±
            try:
                batch_output_dir = os.path.join("outputs", f"batch_files_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
                os.makedirs(batch_output_dir, exist_ok=True)
            except Exception as e:
                return f"ê²°ê³¼ í´ë” ìƒì„± ì˜¤ë¥˜: {str(e)}"
            
            # ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
            results_data = []
            
            total_files = len(files)
            processed_count = 0
            error_count = 0
            
            progress(0, desc=f"ì´ {total_files}ê°œ íŒŒì¼ ì²˜ë¦¬ ì¤€ë¹„ ì¤‘...")
            
            for idx, file in enumerate(files):
                progress_pct = (idx / total_files) * 100
                progress(progress_pct / 100, desc=f"íŒŒì¼ {idx+1}/{total_files} ì²˜ë¦¬ ì¤‘...")
                
                # ê²°ê³¼ ì •ë³´ ì´ˆê¸°í™”
                result_info = {
                    'filename': os.path.basename(file.name),
                    'original_path': file.name,
                    'processed_path': '',
                    'error': None,
                    'auto_count': 0,
                    'manual_count': 0,
                    'total_count': 0,
                    'count_text': '',
                    'process_time': 0
                }
                
                try:
                    start_time = time.time()
                    
                    # ì´ë¯¸ì§€ íŒŒì¼ ë¡œë“œ
                    try:
                        img = Image.open(file.name).convert("RGB")
                    except Exception as e:
                        result_info['error'] = f"ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜: {str(e)}"
                        results_data.append(result_info)
                        error_count += 1
                        continue
                        
                    # ì½œë¡œë‹ˆ ë¶„ì„ ìˆ˜í–‰
                    try:
                        # ë¡œì»¬ ì¹´ìš´í„° ìƒì„± (í˜„ì¬ ì „ì—­ ì¹´ìš´í„°ì— ì˜í–¥ ì—†ë„ë¡)
                        local_counter = ColonyCounter()
                        local_counter.reset()
                        
                        processed_img, count_text = segment_and_count_colonies(
                            input_image=img,
                            conf_threshold=conf_threshold,
                            iou_threshold=iou_threshold,
                            circularity_threshold=circularity_threshold,
                            draw_contours=draw_contours,
                            mask_random_color=mask_random_color,
                            input_size=input_size,
                            better_quality=better_quality,
                            min_area_percentile=min_area_percentile,
                            max_area_percentile=max_area_percentile,
                            use_dish_filtering=use_dish_filtering,
                            dish_overlap_threshold=dish_overlap_threshold
                        )
                        
                        # ì˜¤ë¥˜ í™•ì¸
                        if "ì˜¤ë¥˜" in count_text:
                            result_info['error'] = count_text
                            results_data.append(result_info)
                            error_count += 1
                            continue
                            
                        # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
                        filename_only = os.path.splitext(os.path.basename(file.name))[0]
                        processed_path = os.path.join(batch_output_dir, f"{filename_only}_result.png")
                        Image.fromarray(processed_img).save(processed_path)
                        
                        # ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
                        process_time = time.time() - start_time
                        
                        # ê²°ê³¼ ì •ë³´ ì—…ë°ì´íŠ¸
                        result_info['processed_path'] = processed_path
                        result_info['auto_count'] = counter.auto_detected_count
                        result_info['manual_count'] = len(counter.manual_points)
                        result_info['total_count'] = counter.auto_detected_count + len(counter.manual_points)
                        result_info['count_text'] = count_text
                        result_info['process_time'] = round(process_time, 2)
                        
                        processed_count += 1
                        
                    except Exception as e:
                        result_info['error'] = f"ë¶„ì„ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
                    
                except Exception as e:
                    result_info['error'] = f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
                
                results_data.append(result_info)
                
            # ìš”ì•½ ì •ë³´ ìƒì„±
            progress(0.95, desc="ê²°ê³¼ ìš”ì•½ ìƒì„± ì¤‘...")
            
            try:
                # ìš”ì•½ JSON ìƒì„±
                summary = {
                    'date': datetime.now().strftime("%Y-%m-%d"),
                    'time': datetime.now().strftime("%H:%M:%S"),
                    'total_images': total_files,
                    'successful': processed_count,
                    'failed': error_count,
                    'results': results_data
                }
                
                # JSON íŒŒì¼ë¡œ ì €ì¥
                summary_json_path = os.path.join(batch_output_dir, "summary.json")
                with open(summary_json_path, 'w', encoding='utf-8') as f:
                    json.dump(summary, f, indent=4)
                
                # CSV íŒŒì¼ë¡œë„ ì €ì¥
                df = pd.DataFrame(results_data)
                csv_path = os.path.join(batch_output_dir, "results.csv")
                df.to_csv(csv_path, index=False)
                
            except Exception as e:
                return f"ê²°ê³¼ ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {str(e)}\nì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜: {processed_count}, ì˜¤ë¥˜ ë°œìƒ íŒŒì¼ ìˆ˜: {error_count}"
            
            # ìµœì¢… ìš”ì•½ ë©”ì‹œì§€ ë°˜í™˜
            result_msg = f"""
            ì²˜ë¦¬ ì™„ë£Œ:
            - ì´ íŒŒì¼: {total_files}ê°œ
            - ì²˜ë¦¬ ì„±ê³µ: {processed_count}ê°œ
            - ì˜¤ë¥˜ ë°œìƒ: {error_count}ê°œ
            - ê²°ê³¼ í´ë”: {batch_output_dir}\n
            """
            
            return result_msg
            
        except Exception as e:
            return f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²°
    batch_process_folder_btn.click(
        batch_process_images,
        inputs=[
            folder_path_input,
            batch_conf_threshold,
            batch_iou_threshold,
            batch_circularity_threshold,
            gr.Checkbox(value=True, visible=False),  # draw_contours
            gr.Checkbox(value=True, visible=False),  # mask_random_color
            batch_input_size,
            batch_better_quality,
            batch_min_area_percentile,
            batch_max_area_percentile,
            batch_use_dish_filtering,
            batch_dish_overlap_threshold
        ],
        outputs=batch_summary_output
    )
    
    batch_process_files_btn.click(
        batch_process_files,
        inputs=[
            batch_files,
            batch_conf_threshold,
            batch_iou_threshold,
            batch_circularity_threshold,
            gr.Checkbox(value=True, visible=False),  # draw_contours
            gr.Checkbox(value=True, visible=False),  # mask_random_color
            batch_input_size,
            batch_better_quality,
            batch_min_area_percentile,
            batch_max_area_percentile,
            batch_use_dish_filtering,
            batch_dish_overlap_threshold
        ],
        outputs=batch_summary_output
    )
    
    open_output_btn.click(
        open_output_folder,
        inputs=[],
        outputs=batch_summary_output
    )

    # í‘¸í„° ì¶”ê°€
    gr.Markdown("<div class='footer'>Produced by BDKÂ®</div>")

if __name__ == "__main__":
    demo.launch()