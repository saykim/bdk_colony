import os
from datetime import datetime
from ultralytics import YOLO
import gradio as gr
import torch
from PIL import Image, ImageDraw, ImageFont, ImageFilter, ImageEnhance
import numpy as np
import cv2
import pandas as pd
from pathlib import Path
import json
import time
from typing import List, Dict, Any, Tuple

# AI ê¸°ë°˜ ë¶„í•  ëª¨ë¸ ë¡œë“œ
model_path = 'weights/FastSAM-x.pt'
model = YOLO(model_path)

# ë””ë°”ì´ìŠ¤ ì„¤ì • (CUDA, MPS, CPU ìˆœìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥)
device = torch.device(
    "cuda" if torch.cuda.is_available() else
    "mps" if torch.backends.mps.is_available() else "cpu"
)

class ImagePreprocessHistory:
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íˆìŠ¤í† ë¦¬ ê´€ë¦¬ í´ë˜ìŠ¤"""
    def __init__(self):
        self.original_image = None
        self.current_image = None
        self.history = []
        self.current_index = -1

    def set_original(self, image):
        """ì›ë³¸ ì´ë¯¸ì§€ ì„¤ì •"""
        if image is None:
            return None
            
        # PIL Imageë¡œ ë³€í™˜
        if not isinstance(image, Image.Image):
            try:
                image = Image.fromarray(image)
            except Exception as e:
                print(f"Error converting image: {str(e)}")
                return None
        
        self.original_image = image
        self.current_image = image
        self.history = [image]
        self.current_index = 0
        return image

    def add_state(self, image):
        """ìƒˆë¡œìš´ ì´ë¯¸ì§€ ìƒíƒœ ì¶”ê°€"""
        if image is None:
            return None
            
        # PIL Imageë¡œ ë³€í™˜
        if not isinstance(image, Image.Image):
            try:
                image = Image.fromarray(image)
            except Exception as e:
                print(f"Error converting image: {str(e)}")
                return None
        
        # í˜„ì¬ ì¸ë±ìŠ¤ ì´í›„ì˜ íˆìŠ¤í† ë¦¬ëŠ” ì‚­ì œ
        self.history = self.history[:self.current_index + 1]
        self.history.append(image)
        self.current_index = len(self.history) - 1
        self.current_image = image
        return image

    def reset(self):
        """ì›ë³¸ ì´ë¯¸ì§€ë¡œ ë³µì›"""
        if self.original_image is not None:
            self.current_image = self.original_image
            self.current_index = 0
            return self.original_image
        return None

    def undo(self):
        """ì´ì „ ìƒíƒœë¡œ ë³µì›"""
        if self.current_index > 0:
            self.current_index -= 1
            self.current_image = self.history[self.current_index]
            return self.current_image
        return self.current_image

# ì´ë¯¸ì§€ íˆìŠ¤í† ë¦¬ ê°ì²´ ìƒì„±
image_history = ImagePreprocessHistory()

class ColonyCounter:
    def __init__(self):
        self.manual_points = []  # ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€ëœ í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
        self.auto_points = []    # ìë™ìœ¼ë¡œ ê°ì§€ëœ CFU ì¤‘ì‹¬ì  ë¦¬ìŠ¤íŠ¸
        self.current_image = None
        self.auto_detected_count = 0
        self.remove_mode = False
        self.original_image = None
        self.last_method = None
        self.zoom_factor = 1.0  # í™•ëŒ€/ì¶•ì†Œ ë¹„ìœ¨

    def reset(self):
        """ì¹´ìš´í„° ì´ˆê¸°í™”"""
        self.manual_points = []
        self.auto_points = []  # ìë™ í¬ì¸íŠ¸ ì´ˆê¸°í™”
        self.current_image = None
        self.auto_detected_count = 0
        self.remove_mode = False
        self.original_image = None
        self.last_method = None
        self.zoom_factor = 1.0  # í™•ëŒ€/ì¶•ì†Œ ë¹„ìœ¨ ì´ˆê¸°í™”

    def set_original_image(self, image):
        """
        ì›ë³¸ ì´ë¯¸ì§€ ì„¤ì •

        Args:
            image (PIL.Image): ì›ë³¸ ì´ë¯¸ì§€
        """
        self.original_image = np.array(image)

    def toggle_remove_mode(self):
        """í¸ì§‘ ëª¨ë“œ ì „í™˜ (ì¶”ê°€/ì œê±° ëª¨ë“œ)"""
        self.remove_mode = not self.remove_mode
        img_with_points = self.draw_points()
        mode_text = "ğŸ”´ REMOVE MODE" if self.remove_mode else "ğŸŸ¢ ADD MODE"
        return img_with_points, mode_text

    def add_or_remove_point(self, image, evt: gr.SelectData):
        """
        ì´ë¯¸ì§€ë¥¼ í´ë¦­í•˜ì—¬ í¬ì¸íŠ¸ ì¶”ê°€ ë˜ëŠ” ì œê±°

        Args:
            image (numpy.ndarray): ì¶œë ¥ ì´ë¯¸ì§€
            evt (gr.SelectData): ì„ íƒ ë°ì´í„° ì´ë²¤íŠ¸

        Returns:
            tuple: ì—…ë°ì´íŠ¸ëœ ì´ë¯¸ì§€ì™€ ì¹´ìš´íŠ¸ í…ìŠ¤íŠ¸
        """
        try:
            if self.current_image is None and image is not None:
                self.current_image = np.array(image)

            x, y = evt.index  # í´ë¦­í•œ ì¢Œí‘œ

            if self.remove_mode:
                # ì œê±° ëª¨ë“œ: ìë™ í¬ì¸íŠ¸ ë˜ëŠ” ìˆ˜ë™ í¬ì¸íŠ¸ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ í¬ì¸íŠ¸ ì œê±°
                closest_auto = self.find_closest_point(x, y, self.auto_points)
                closest_manual = self.find_closest_point(x, y, self.manual_points)
                removed = False

                if closest_auto is not None:
                    self.auto_points.pop(closest_auto)
                    self.auto_detected_count = len(self.auto_points)
                    removed = True
                elif closest_manual is not None:
                    self.manual_points.pop(closest_manual)
                    removed = True

                if not removed:
                    print("ì œê±°í•  í¬ì¸íŠ¸ê°€ ì¶©ë¶„íˆ ê°€ê¹Œì´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            else:
                # ì¶”ê°€ ëª¨ë“œ: ìƒˆë¡œìš´ í¬ì¸íŠ¸ ì¶”ê°€
                self.manual_points.append((x, y))

            img_with_points = self.draw_points()
            return img_with_points, self.get_count_text()
        except Exception as e:
            print(f"í¬ì¸íŠ¸ ì¶”ê°€/ì œê±° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return image, self.get_count_text()

    def find_closest_point(self, x, y, points, threshold=20):
        """
        ì£¼ì–´ì§„ ì¢Œí‘œì™€ ê°€ì¥ ê°€ê¹Œìš´ í¬ì¸íŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

        Args:
            x (int): í´ë¦­í•œ x ì¢Œí‘œ
            y (int): í´ë¦­í•œ y ì¢Œí‘œ
            points (list): í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
            threshold (int, optional): ìµœëŒ€ ê±°ë¦¬ ì„ê³„ê°’. Defaults to 20.

        Returns:
            int or None: ê°€ì¥ ê°€ê¹Œìš´ í¬ì¸íŠ¸ì˜ ì¸ë±ìŠ¤ ë˜ëŠ” None
        """
        if not points:
            return None

        distances = []
        for idx, (px, py) in enumerate(points):
            dist = np.sqrt((x - px) ** 2 + (y - py) ** 2)
            distances.append((dist, idx))

        if not distances:
            return None

        closest_dist, closest_idx = min(distances, key=lambda item: item[0])
        return closest_idx if closest_dist < threshold else None

    def remove_last_point(self, image):
        """
        ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€ëœ ë§ˆì§€ë§‰ í¬ì¸íŠ¸ ì œê±°

        Args:
            image (numpy.ndarray): ì¶œë ¥ ì´ë¯¸ì§€

        Returns:
            tuple: ì—…ë°ì´íŠ¸ëœ ì´ë¯¸ì§€ì™€ ì¹´ìš´íŠ¸ í…ìŠ¤íŠ¸
        """
        try:
            if self.manual_points:
                self.manual_points.pop()
                img_with_points = self.draw_points()
                return img_with_points, self.get_count_text()
            return image, self.get_count_text()
        except Exception as e:
            print(f"ë§ˆì§€ë§‰ í¬ì¸íŠ¸ ì œê±° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return image, self.get_count_text()

    def get_count_text(self):
        """
        ì¹´ìš´íŠ¸ ê²°ê³¼ í…ìŠ¤íŠ¸ ìƒì„±

        Returns:
            str: ì¹´ìš´íŠ¸ ê²°ê³¼ í…ìŠ¤íŠ¸
        """
        try:
            method_text = f"ë°©ë²•: {self.last_method}\n" if self.last_method else ""
            return (f"{method_text}ì „ì²´ CFU ìˆ˜: {self.auto_detected_count + len(self.manual_points)}\n"
                    f"ğŸ¤– ìë™ ê°ì§€ëœ CFU: {self.auto_detected_count}\n"
                    f"ğŸ‘† ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€ëœ CFU: {len(self.manual_points)}")
        except Exception as e:
            print(f"ì¹´ìš´íŠ¸ í…ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return "ì¹´ìš´íŠ¸ ê³„ì‚° ì˜¤ë¥˜"

    def draw_points(self):
        """
        í˜„ì¬ ì´ë¯¸ì§€ì— í¬ì¸íŠ¸ë¥¼ ê·¸ë ¤ì„œ ë°˜í™˜

        Returns:
            numpy.ndarray: í¬ì¸íŠ¸ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€
        """
        try:
            if self.current_image is None:
                return None

            img_with_points = self.current_image.copy()
            overlay = np.zeros_like(img_with_points)
            square_size = 30  # 25ì—ì„œ 30ìœ¼ë¡œ 20% ì¦ê°€

            # ê¸€ê¼´ ì„¤ì •
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.7
            font_thickness = 1
            outline_thickness = 3

            # ìë™ ê°ì§€ëœ CFU ë²ˆí˜¸ í‘œì‹œ (íŒŒë€ìƒ‰)
            for idx, (x, y) in enumerate(self.auto_points, 1):
                text = str(idx)
                (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)

                text_x = int(x - text_width / 2)
                text_y = int(y - 10)

                # ê²€ì€ìƒ‰ ì™¸ê³½ì„ 
                for dx, dy in [(-1, -1), (-1, 1), (1, -1), (1, 1)]:
                    cv2.putText(img_with_points, text,
                              (text_x + dx, text_y + dy),
                              font, font_scale, (0, 0, 0), outline_thickness)

                # íŒŒë€ìƒ‰ í…ìŠ¤íŠ¸
                cv2.putText(img_with_points, text,
                          (text_x, text_y),
                          font, font_scale, (255, 0, 0), font_thickness)

            # ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€ëœ í¬ì¸íŠ¸ ì‚¬ê°í˜• ê·¸ë¦¬ê¸° (ë¹¨ê°„ìƒ‰)
            for x, y in self.manual_points:
                pt1 = (int(x - square_size / 2), int(y - square_size / 2))
                pt2 = (int(x + square_size / 2), int(y + square_size / 2))
                cv2.rectangle(overlay, pt1, pt2, (0, 0, 255), -1)  # ë¹¨ê°„ìƒ‰ ì‚¬ê°í˜•

            # ì˜¤ë²„ë ˆì´ ì ìš©
            cv2.addWeighted(overlay, 0.4, img_with_points, 1.0, 0, img_with_points)

            # ìˆ˜ë™ í¬ì¸íŠ¸ ë²ˆí˜¸ í‘œì‹œ (íŒŒë€ìƒ‰)
            for idx, (x, y) in enumerate(self.manual_points, len(self.auto_points) + 1):
                text = str(idx)
                (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)
                text_x = int(x - text_width / 2)
                text_y = int(y - 10)

                # í•˜ì–€ìƒ‰ ì™¸ê³½ì„ 
                for dx, dy in [(-1, -1), (-1, 1), (1, -1), (1, 1)]:
                    cv2.putText(img_with_points, text,
                              (text_x + dx, text_y + dy),
                              font, font_scale, (255, 255, 255), outline_thickness)

                # íŒŒë€ìƒ‰ í…ìŠ¤íŠ¸
                cv2.putText(img_with_points, text,
                          (text_x, text_y),
                          font, font_scale, (255, 0, 0), font_thickness)

            # ì œê±° ëª¨ë“œ í‘œì‹œ
            if self.remove_mode:
                overlay_mode = img_with_points.copy()
                cv2.rectangle(overlay_mode, (0, 0), (img_with_points.shape[1], 50), (255, 0, 0), -1)
                cv2.addWeighted(overlay_mode, 0.3, img_with_points, 0.7, 0, img_with_points)
                cv2.putText(img_with_points, "REMOVE MODE", (10, 35),
                          cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)
            else:
                overlay_mode = img_with_points.copy()
                cv2.rectangle(overlay_mode, (0, 0), (img_with_points.shape[1], 50), (0, 255, 0), -1)
                cv2.addWeighted(overlay_mode, 0.3, img_with_points, 0.7, 0, img_with_points)
                cv2.putText(img_with_points, "ADD MODE", (10, 35),
                          cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)

            # ì „ì²´ ì¹´ìš´íŠ¸ í‘œì‹œ (ì™¼ìª½ í•˜ë‹¨)
            total_count = self.auto_detected_count + len(self.manual_points)
            count_text = f"Total Count: {total_count}"
            
            # ë°°ê²½ ìƒì ê·¸ë¦¬ê¸°
            text_size = cv2.getTextSize(count_text, cv2.FONT_HERSHEY_SIMPLEX, 1.5, 3)[0]
            margin = 20
            cv2.rectangle(img_with_points, 
                         (10, img_with_points.shape[0] - text_size[1] - margin * 2),
                         (text_size[0] + margin * 2, img_with_points.shape[0]),
                         (0, 0, 0), -1)
            
            # ì¹´ìš´íŠ¸ í…ìŠ¤íŠ¸ í‘œì‹œ
            cv2.putText(img_with_points, count_text,
                      (margin, img_with_points.shape[0] - margin),
                      cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 3)

            return img_with_points
        except Exception as e:
            print(f"í¬ì¸íŠ¸ ê·¸ë¦¬ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return self.current_image

def preprocess_image(
    input_image,
    to_grayscale=False,
    binary=False,
    binary_threshold=128,
    edge_detection=False,
    sharpen=False,
    sharpen_amount=1.0
):
    """
    ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    Args:
        input_image (PIL.Image): ì „ì²˜ë¦¬í•  ì…ë ¥ ì´ë¯¸ì§€
        to_grayscale (bool, optional): í‘ë°± ë³€í™˜ ì—¬ë¶€. Defaults to False.
        binary (bool, optional): ë°”ì´ë„ˆë¦¬ ë³€í™˜ ì—¬ë¶€. Defaults to False.
        binary_threshold (int, optional): ë°”ì´ë„ˆë¦¬ ë³€í™˜ ì„ê³„ê°’. Defaults to 128.
        edge_detection (bool, optional): ì—ì§€ ê²€ì¶œ ì—¬ë¶€. Defaults to False.
        sharpen (bool, optional): ìƒ¤í”ˆ ì—¬ë¶€. Defaults to False.
        sharpen_amount (float, optional): ìƒ¤í”ˆ ê°•ë„. Defaults to 1.0.

    Returns:
        PIL.Image: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€
    """
    try:
        image = input_image.copy()

        # í‘ë°± ë³€í™˜
        if to_grayscale:
            image = image.convert('L').convert('RGB')  # í‘ë°± í›„ RGBë¡œ ë³€í™˜

        # ë°”ì´ë„ˆë¦¬ ë³€í™˜
        if binary:
            image_np = np.array(image)
            gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
            _, binary_img = cv2.threshold(gray, binary_threshold, 255, cv2.THRESH_BINARY)
            image = Image.fromarray(binary_img).convert('RGB')

        # ì—ì§€ ê²€ì¶œ
        if edge_detection:
            image_np = np.array(image)
            gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 100, 200)
            image = Image.fromarray(edges).convert('RGB')

        # ìƒ¤í”ˆ
        if sharpen:
            image = image.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3))
            if sharpen_amount != 1.0:
                enhancer = ImageEnhance.Sharpness(image)
                image = enhancer.enhance(sharpen_amount)

        return image
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return input_image

def process_image(colony_annotations, dish_annotation, image, device, scale, better_quality, mask_random_color, bbox, use_retina, withContours):
    """
    ë§ˆìŠ¤í¬ ì£¼ì„ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ì—¬ CFUì˜ ìœ¤ê³½ì„ ì„ ê·¸ë¦½ë‹ˆë‹¤.
    
    Args:
        colony_annotations (list): CFUì˜ ë§ˆìŠ¤í¬ ì£¼ì„ ë¦¬ìŠ¤íŠ¸
        dish_annotation (torch.Tensor): ë°°ì–‘ì ‘ì‹œì˜ ë§ˆìŠ¤í¬ ì£¼ì„
        image (PIL.Image): ì›ë³¸ ì´ë¯¸ì§€
        device (torch.device): ë””ë°”ì´ìŠ¤ ì„¤ì •
        scale (float): ì´ë¯¸ì§€ ìŠ¤ì¼€ì¼
        better_quality (bool): í–¥ìƒëœ í’ˆì§ˆ ì—¬ë¶€
        mask_random_color (bool): ë§ˆìŠ¤í¬ì— ëœë¤ ìƒ‰ìƒ ì ìš© ì—¬ë¶€
        bbox (None): ë°”ìš´ë”© ë°•ìŠ¤ (í˜„ì¬ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)
        use_retina (bool): Retina ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€ (í˜„ì¬ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)
        withContours (bool): ìœ¤ê³½ì„  í‘œì‹œ ì—¬ë¶€

    Returns:
        PIL.Image: ì²˜ë¦¬ëœ ì´ë¯¸ì§€
    """
    image_np = np.array(image).copy()

    # CFU ë§ˆìŠ¤í¬ ì²˜ë¦¬
    for ann in colony_annotations:
        mask = ann.cpu().numpy()
        if mask.ndim == 2:
            mask = mask > 0
            if mask_random_color:
                color = np.random.randint(100, 200, (3,)).tolist()  # ì¤‘ê°„ ë°ê¸°ì˜ ëœë¤ ìƒ‰ìƒ ìƒì„±
                image_np[mask] = color
            else:
                image_np[mask] = (0, 255, 0)  # ê¸°ë³¸ ë…¹ìƒ‰

        if withContours:
            # ìœ¤ê³½ì„  ì°¾ê¸° ë° ê·¸ë¦¬ê¸°
            contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            cv2.drawContours(image_np, contours, -1, (255, 0, 0), 2)  # íŒŒë€ìƒ‰ ìœ¤ê³½ì„ 

    # ë°°ì–‘ì ‘ì‹œ ë§ˆìŠ¤í¬ ì²˜ë¦¬ (ìœ¤ê³½ì„ ë§Œ ê·¸ë¦¬ê¸°)
    if dish_annotation is not None:
        dish_mask = dish_annotation.cpu().numpy()
        if dish_mask.ndim == 2:
            dish_mask = dish_mask > 0
            if withContours:
                contours, _ = cv2.findContours(dish_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(image_np, contours, -1, (0, 0, 255), 3)  # ë¹¨ê°„ìƒ‰ ìœ¤ê³½ì„ 

    processed_image = Image.fromarray(image_np)
    return processed_image

def segment_and_count_colonies(
    input_image,
    input_size=1024,
    iou_threshold=0.7,
    conf_threshold=0.25,
    better_quality=False,
    withContours=True,
    mask_random_color=True,
    min_area_percentile=1,
    max_area_percentile=99,
    circularity_threshold=0.8,
    progress=gr.Progress()
):
    """
    ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  CFUë¥¼ ê°ì§€í•˜ì—¬ ì¹´ìš´íŒ…í•©ë‹ˆë‹¤.

    Args:
        input_image (PIL.Image): ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€
        input_size (int, optional): ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°. Defaults to 1024.
        iou_threshold (float, optional): IOU ì„ê³„ê°’. Defaults to 0.7.
        conf_threshold (float, optional): ì‹ ë¢°ë„ ì„ê³„ê°’. Defaults to 0.25.
        better_quality (bool, optional): í–¥ìƒëœ í’ˆì§ˆ ì—¬ë¶€. Defaults to False.
        withContours (bool, optional): ìœ¤ê³½ì„  í‘œì‹œ ì—¬ë¶€. Defaults to True.
        mask_random_color (bool, optional): ë§ˆìŠ¤í¬ì— ëœë¤ ìƒ‰ìƒ ì ìš© ì—¬ë¶€. Defaults to True.
        min_area_percentile (int, optional): ìµœì†Œ ë©´ì  ë°±ë¶„ìœ„ìˆ˜. Defaults to 1.
        max_area_percentile (int, optional): ìµœëŒ€ ë©´ì  ë°±ë¶„ìœ„ìˆ˜. Defaults to 99.
        circularity_threshold (float, optional): ì›í˜•ë„ ì„ê³„ê°’. Defaults to 0.8.
        progress (gr.Progress, optional): ì§„í–‰ ìƒí™© í‘œì‹œ. Defaults to gr.Progress().

    Returns:
        tuple: ë¶„ì„ëœ ì´ë¯¸ì§€ê³¼ ì¹´ìš´íŠ¸ í…ìŠ¤íŠ¸
    """
    try:
        if input_image is None:
            return None, "ì´ë¯¸ì§€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."

        progress(0.1, desc="ì´ˆê¸°í™” ì¤‘...")
        counter.reset()
        counter.set_original_image(input_image)
        image_to_use = input_image

        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ë¹„ìœ¨ ìœ ì§€)
        w, h = image_to_use.size
        scale = input_size / max(w, h)
        new_w, new_h = int(w * scale), int(h * scale)
        input_resized = image_to_use.resize((new_w, new_h))

        progress(0.3, desc="AI ë¶„ì„ ì¤‘...")
        # CFU ê°ì§€
        results = model.predict(
            input_resized,
            device=device,
            conf=conf_threshold,
            iou=iou_threshold,
            imgsz=input_size,
            retina_masks=True
        )

        if not results[0].masks:
            return np.array(input_resized), "CFUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        progress(0.6, desc="ë§ˆìŠ¤í¬ ë¦¬ì‚¬ì´ì¦ˆ ì¤‘...")
        # ë§ˆìŠ¤í¬ ë¦¬ì‚¬ì´ì¦ˆ
        annotations = results[0].masks.data
        resized_annotations = []
        for ann in annotations:
            mask_np = ann.cpu().numpy().astype(np.uint8) * 255  # ì´ì§„ ë§ˆìŠ¤í¬ë¡œ ë³€í™˜
            mask_resized = cv2.resize(mask_np, (new_w, new_h), interpolation=cv2.INTER_NEAREST)
            mask_resized = mask_resized > 0  # ë‹¤ì‹œ ë¶ˆë¦¬ì–¸ìœ¼ë¡œ ë³€í™˜
            resized_annotations.append(torch.from_numpy(mask_resized))

        # ì˜ì—­ ê³„ì‚°
        areas = [np.sum(ann.numpy()) for ann in resized_annotations]

        # ê°€ì¥ í° ë§ˆìŠ¤í¬ë¥¼ ë°°ì–‘ì ‘ì‹œë¡œ ì¸ì‹
        dish_idx = np.argmax(areas)
        dish_annotation = resized_annotations[dish_idx]
        colony_annotations = [ann for idx, ann in enumerate(resized_annotations) if idx != dish_idx]

        progress(0.8, desc="ê²°ê³¼ ì²˜ë¦¬ ì¤‘...")
        # ê²°ê³¼ ì‹œê°í™”
        fig = process_image(
            colony_annotations=colony_annotations,
            dish_annotation=dish_annotation,
            image=input_resized,
            device=device,
            scale=1.0,
            better_quality=better_quality,
            mask_random_color=mask_random_color,
            bbox=None,
            use_retina=False,
            withContours=withContours
        )

        counter.current_image = np.array(fig)
        counter.auto_detected_count = len(colony_annotations)

        # ìë™ ê°ì§€ëœ CFUì˜ ì¤‘ì‹¬ì  ê³„ì‚°
        counter.auto_points = []
        for ann in colony_annotations:
            mask = ann.numpy()
            if mask.ndim == 2:
                mask = mask > 0
                y_indices, x_indices = np.where(mask)
                if len(x_indices) > 0 and len(y_indices) > 0:
                    center_x = int(np.mean(x_indices))
                    center_y = int(np.mean(y_indices))
                    counter.auto_points.append((center_x, center_y))

        progress(1.0, desc="ì™„ë£Œ!")
        img_with_points = counter.draw_points()
        return img_with_points, counter.get_count_text()
    except Exception as e:
        error_msg = f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        print(error_msg)
        return np.array(preprocessed_image), error_msg

def save_results(original_image, processed_image):
    """
    ì›ë³¸ ì´ë¯¸ì§€ì™€ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¥¼ /outputs í´ë”ì— ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        original_image (PIL.Image): ì›ë³¸ ì´ë¯¸ì§€
        processed_image (numpy.ndarray): ì²˜ë¦¬ëœ ì´ë¯¸ì§€

    Returns:
        str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    try:
        # /outputs í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        output_dir = "outputs"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # ê³ ìœ í•œ ì‹ë³„ì ìƒì„±
        unique_id = datetime.now().strftime("%Y%m%d_%H%M%S") + f"_{os.getpid()}"

        # íŒŒì¼ëª… ì„¤ì •
        original_filename = f"original_{unique_id}.png"
        processed_filename = f"ì¹´ìš´íŒ…ì™„ë£Œ_{unique_id}.png"

        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        original_path = os.path.join(output_dir, original_filename)
        processed_path = os.path.join(output_dir, processed_filename)

        # ì´ë¯¸ì§€ ì €ì¥
        original_image.save(original_path)
        processed_image_pil = Image.fromarray(processed_image)
        processed_image_pil.save(processed_path)

        return f"ì €ì¥ëœ íŒŒì¼:\n- ì›ë³¸: {original_path}\n- ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {processed_path}"
    except Exception as e:
        error_msg = f"ì´ë¯¸ì§€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        print(error_msg)
        return error_msg

def handle_batch_upload(
    files: List[str],
    input_size: int,
    iou_threshold: float,
    conf_threshold: float,
    better_quality: bool,
    withContours: bool,
    min_area_percentile: int,
    max_area_percentile: int,
    circularity_threshold: float,
    progress=gr.Progress()
) -> Tuple[str, str]:
    """
    ë°°ì¹˜ ì—…ë¡œë“œ ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        files (List[str]): ì—…ë¡œë“œëœ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        ... (ë‹¤ë¥¸ ë§¤ê°œë³€ìˆ˜ë“¤ì€ segment_and_count_coloniesì™€ ë™ì¼)

    Returns:
        Tuple[str, str]: ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ë©”ì‹œì§€
    """
    if not files:
        return "ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì—†ìŒ", "íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
    
    # ì´ë¯¸ì§€ íŒŒì¼ë§Œ í•„í„°ë§
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
    valid_images = [f for f in files if Path(f).suffix.lower() in image_extensions]
    
    if not valid_images:
        return "ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì—†ìŒ", "ìœ íš¨í•œ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = os.path.join("batch_outputs", timestamp)
    os.makedirs(output_dir, exist_ok=True)
    
    # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
    results = []
    summary_data = []
    total_images = len(valid_images)
    
    for idx, img_path in enumerate(valid_images):
        progress((idx + 1) / total_images, desc=f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ({idx + 1}/{total_images}): {Path(img_path).name}")
        
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            start_time = time.time()
            image = Image.open(img_path)
            
            # ì´ë¯¸ì§€ ë¶„ì„
            processed_image, count_text = segment_and_count_colonies(
                image,
                input_size=input_size,
                iou_threshold=iou_threshold,
                conf_threshold=conf_threshold,
                better_quality=better_quality,
                withContours=withContours,
                mask_random_color=True,
                min_area_percentile=min_area_percentile,
                max_area_percentile=max_area_percentile,
                circularity_threshold=circularity_threshold
            )
            
            # ê²°ê³¼ ì €ì¥
            filename = Path(img_path).stem
            processed_filename = f"{filename}_processed.png"
            processed_path = os.path.join(output_dir, processed_filename)
            
            # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì €ì¥
            processed_image_pil = Image.fromarray(processed_image)
            processed_image_pil.save(processed_path)
            
            process_time = time.time() - start_time
            
            # ìš”ì•½ ë°ì´í„° ìˆ˜ì§‘
            summary_data.append({
                'filename': Path(img_path).name,
                'total_count': counter.auto_detected_count + len(counter.manual_points),
                'auto_count': counter.auto_detected_count,
                'manual_count': len(counter.manual_points),
                'process_time': f"{process_time:.2f}ì´ˆ",
                'output_path': processed_path,
                'status': 'success'
            })
            
        except Exception as e:
            error_msg = f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            print(f"Error processing {img_path}: {error_msg}")
            summary_data.append({
                'filename': Path(img_path).name,
                'total_count': 0,
                'auto_count': 0,
                'manual_count': 0,
                'process_time': '0ì´ˆ',
                'status': 'error',
                'error_message': error_msg
            })
    
    # ìš”ì•½ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    summary_df = pd.DataFrame(summary_data)
    
    # CSV íŒŒì¼ë¡œ ì €ì¥
    csv_path = os.path.join(output_dir, "summary.csv")
    summary_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    
    # ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ìƒì„±
    successful = summary_df['status'].value_counts().get('success', 0)
    failed = summary_df['status'].value_counts().get('error', 0)
    
    # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ê³„ì‚° (ì„±ê³µí•œ ì¼€ì´ìŠ¤ë§Œ)
    successful_times = [float(t.replace('ì´ˆ', '')) for t in summary_df[summary_df['status'] == 'success']['process_time']]
    avg_time = sum(successful_times) / len(successful_times) if successful_times else 0
    
    summary_message = f"""
    ì²˜ë¦¬ ì™„ë£Œ:
    - ì´ ì´ë¯¸ì§€ ìˆ˜: {total_images}
    - ì„±ê³µ: {successful}
    - ì‹¤íŒ¨: {failed}
    - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ
    
    ì²˜ë¦¬ ê²°ê³¼ëŠ” ë‹¤ìŒ ê²½ë¡œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:
    {output_dir}
    
    ìƒì„¸ ê²°ê³¼ëŠ” summary.csv íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.
    """
    
    # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ê²½ë¡œ ëª©ë¡ ìƒì„±
    processed_images = [row['output_path'] for row in summary_data if row['status'] == 'success']
    
    return processed_images, summary_message

# CSS ìŠ¤íƒ€ì¼ë§ ê°œì„ 
css = """
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;500;700&display=swap');

body {
    background-color: #f8fafc;
    font-family: 'Noto Sans KR', sans-serif;
    color: #334155;
    line-height: 1.4;
}

.container {
    max-width: 1280px;
    margin: 0 auto;
    padding: 20px;
}

.header {
    background: linear-gradient(135deg, #2563EB, #1e40af);
    padding: 30px;
    border-radius: 12px;
    color: #ffffff;
    margin-bottom: 20px;
    box-shadow: 0 4px 10px rgba(37, 99, 235, 0.2);
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.header-content {
    text-align: left;
}

.header-date {
    text-align: right;
    color: rgba(255, 255, 255, 0.9);
    font-size: 14px;
}

.header h1 {
    font-size: 32px;
    font-weight: 700;
    margin: 0;
    background: linear-gradient(90deg, #ffffff, #e2e8f0);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    text-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
}

.header h3 {
    font-size: 16px;
    font-weight: 500;
    margin: 10px 0 0;
    color: #e2e8f0;
}

.section-title {
    font-size: 18px;
    font-weight: 600;
    color: #1e40af;
    margin-bottom: 15px;
    display: flex;
    align-items: center;
    gap: 8px;
}

.button-primary {
    background-color: #2563EB !important;
    color: #ffffff !important;
    border: none !important;
    padding: 12px 24px !important;
    border-radius: 8px !important;
    font-size: 14px !important;
    font-weight: 500 !important;
    cursor: pointer !important;
    transition: all 0.3s ease !important;
    box-shadow: 0 2px 4px rgba(37, 99, 235, 0.2) !important;
}

.button-primary:hover {
    background-color: #1d4ed8 !important;
    box-shadow: 0 4px 6px rgba(37, 99, 235, 0.3) !important;
    transform: translateY(-1px) !important;
}

.button-secondary {
    background-color: #475569 !important;
    color: #ffffff !important;
    border: none !important;
    padding: 12px 24px !important;
    border-radius: 8px !important;
    font-size: 14px !important;
    font-weight: 500 !important;
    cursor: pointer !important;
    transition: all 0.3s ease !important;
    box-shadow: 0 2px 4px rgba(71, 85, 105, 0.2) !important;
}

.button-secondary:hover {
    background-color: #334155 !important;
    box-shadow: 0 4px 6px rgba(71, 85, 105, 0.3) !important;
    transform: translateY(-1px) !important;
}

.accordion-header {
    background-color: #f1f5f9 !important;
    color: #1e40af !important;
    padding: 15px !important;
    border-radius: 8px !important;
    font-weight: 500 !important;
    border: 1px solid #e2e8f0 !important;
    margin: 10px 0 !important;
    transition: all 0.3s ease !important;
}

.accordion-header:hover {
    border-color: #2563EB !important;
    box-shadow: 0 2px 4px rgba(37, 99, 235, 0.1) !important;
}

.input-image, .output-image {
    border: 2px solid #e2e8f0 !important;
    border-radius: 12px !important;
    padding: 20px !important;
    background: #ffffff !important;
    transition: all 0.3s ease !important;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05) !important;
    margin: 15px 0 !important;
}

.input-image:hover, .output-image:hover {
    border-color: #2563EB !important;
    box-shadow: 0 4px 6px rgba(37, 99, 235, 0.1) !important;
}

.result-text {
    background: #ffffff !important;
    border-left: 5px solid #10b981 !important;
    padding: 15px !important;
    border-radius: 8px !important;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05) !important;
    font-size: 14px !important;
    line-height: 1.6 !important;
    margin: 15px 0 !important;
    color: #334155 !important;
}

.gradio-container {
    background-color: #ffffff !important;
    border-radius: 12px !important;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05) !important;
    padding: 20px !important;
    margin: 20px auto !important;
}

.gradio-row {
    gap: 20px !important;
}

.gradio-column {
    background: #ffffff !important;
    padding: 20px !important;
    border-radius: 12px !important;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05) !important;
}

.slider-container {
    background: #f1f5f9 !important;
    padding: 15px !important;
    border-radius: 8px !important;
    margin: 10px 0 !important;
}

.slider {
    accent-color: #2563EB !important;
}

.checkbox-container {
    background: #f1f5f9 !important;
    padding: 12px !important;
    border-radius: 8px !important;
    margin: 8px 0 !important;
}

.checkbox {
    accent-color: #10b981 !important;
}

.instruction-box {
    background-color: #f1f5f9 !important;
    border: 1px solid #e2e8f0 !important;
    border-radius: 12px !important;
    padding: 20px !important;
    margin-top: 30px !important;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05) !important;
}

.instruction-box h3 {
    color: #1e40af !important;
    font-size: 18px !important;
    font-weight: 600 !important;
    margin-bottom: 15px !important;
}

.instruction-box p {
    color: #334155 !important;
    font-size: 14px !important;
    line-height: 1.6 !important;
    margin-bottom: 10px !important;
}

/* íƒ­ ìŠ¤íƒ€ì¼ë§ */
.tabs {
    border-bottom: 1px solid #e2e8f0 !important;
    margin-bottom: 20px !important;
}

.tab-nav {
    padding: 12px 24px !important;
    color: #475569 !important;
    font-weight: 500 !important;
    font-size: 14px !important;
    transition: all 0.3s ease !important;
}

.tab-nav:hover {
    color: #2563EB !important;
}

.tab-nav.selected {
    color: #2563EB !important;
    border-bottom: 2px solid #2563EB !important;
    background-color: rgba(37, 99, 235, 0.05) !important;
}

/* ì¤‘ìš”ë„ í‘œì‹œ */
.priority-high {
    color: #ef4444 !important;
    font-weight: 500 !important;
}

.priority-medium {
    color: #f59e0b !important;
    font-weight: 500 !important;
}

.priority-low {
    color: #10b981 !important;
    font-weight: 500 !important;
}

/* ì¹´ë“œ ì»´í¬ë„ŒíŠ¸ */
.card {
    background: #ffffff !important;
    border-radius: 12px !important;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05) !important;
    padding: 20px !important;
    margin: 15px 0 !important;
    border: 1px solid #e2e8f0 !important;
    transition: all 0.3s ease !important;
}

.card:hover {
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1) !important;
    transform: translateY(-2px) !important;
}

/* ìŠ¤í¬ë¡¤ë°” ì»¤ìŠ¤í„°ë§ˆì´ì§• */
::-webkit-scrollbar {
    width: 8px;
    height: 8px;
}

::-webkit-scrollbar-track {
    background: #f1f5f9;
    border-radius: 4px;
}

::-webkit-scrollbar-thumb {
    background: #cbd5e1;
    border-radius: 4px;
}

::-webkit-scrollbar-thumb:hover {
    background: #94a3b8;
}
"""

# ì „ì—­ counter ê°ì²´
counter = ColonyCounter()

# Gradio ì¸í„°í˜ì´ìŠ¤ ì„¤ì •
with gr.Blocks(theme=gr.themes.Soft(), css=css) as demo:
    gr.Markdown(
        """
        <div class="header">
            <div class="header-content">
                <h1>ğŸ”¬ BDK CFU ì¹´ìš´í„°</h1>
                <h3>AI ìë™ CFU ê°ì§€</h3>
            </div>
            <div class="header-date">
                <span>ìµœì¢… ì—…ë°ì´íŠ¸: 2023ë…„ 12ì›”</span>
            </div>
        </div>
        """
    )

    with gr.Tabs():
        with gr.Tab("ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬"):
            with gr.Row():
                with gr.Column(scale=6, min_width=300):
                    gr.Markdown("<div class='section-title'>ğŸ“ ì´ë¯¸ì§€ ì—…ë¡œë“œ</div>")
                    input_image = gr.Image(
                        type="pil",
                        elem_classes=["input-image"],
                        show_label=False
                    )

                    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì„¤ì •
                    with gr.Accordion("ğŸ› ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì„¤ì •", open=False, elem_classes="accordion-header"):
                        to_grayscale = gr.Checkbox(
                            label="í‘ë°± ë³€í™˜",
                            value=False,
                            info="ì´ë¯¸ì§€ë¥¼ í‘ë°±ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
                        )
                        binary = gr.Checkbox(
                            label="ë°”ì´ë„ˆë¦¬ ë³€í™˜",
                            value=False,
                            info="ì´ë¯¸ì§€ë¥¼ ë°”ì´ë„ˆë¦¬(ì´ì§„) ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
                        )
                        binary_threshold = gr.Slider(
                            0, 255, 128,
                            step=1,
                            label="ë°”ì´ë„ˆë¦¬ ì„ê³„ê°’",
                            info="ë°”ì´ë„ˆë¦¬ ë³€í™˜ ì‹œ ì‚¬ìš©í•  ì„ê³„ê°’ì…ë‹ˆë‹¤."
                        )
                        edge_detection = gr.Checkbox(
                            label="ì—ì§€ ê²€ì¶œ",
                            value=False,
                            info="ì´ë¯¸ì§€ì˜ ì—ì§€ë¥¼ ê²€ì¶œí•©ë‹ˆë‹¤."
                        )
                        sharpen = gr.Checkbox(
                            label="ìƒ¤í”ˆ",
                            value=False,
                            info="ì´ë¯¸ì§€ì˜ ì„ ëª…ë„ë¥¼ ë†’ì…ë‹ˆë‹¤."
                        )
                        sharpen_amount = gr.Slider(
                            0.5, 5.0, 1.0,
                            step=0.1,
                            label="ìƒ¤í”ˆ ê°•ë„",
                            info="ìƒ¤í”ˆì˜ ê°•ë„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤."
                        )
                        with gr.Row():
                            preprocess_button = gr.Button(
                                "ğŸ”„ ì „ì²˜ë¦¬ ì ìš©",
                                variant="secondary",
                                elem_classes="button-secondary"
                            )
                            reset_button = gr.Button(
                                "â†º ì´ˆê¸°í™”",
                                variant="secondary",
                                elem_classes="button-secondary"
                            )
                            undo_button = gr.Button(
                                "â†¶ ì‹¤í–‰ ì·¨ì†Œ",
                                variant="secondary",
                                elem_classes="button-secondary"
                            )

                    with gr.Row():
                        segment_button = gr.Button(
                            "ğŸ” ì´ë¯¸ì§€ ë¶„ì„",
                            variant="primary",
                            scale=2,
                            elem_classes="button-primary"
                        )

                    # ë¶„ì„ ì„¤ì •
                    with gr.Accordion("âš™ï¸ ë¶„ì„ ì„¤ì •", open=False, elem_classes="accordion-header"):
                        with gr.Tab("ì¼ë°˜"):
                            input_size_slider = gr.Slider(
                                512, 2048, 1024,
                                step=64,
                                label="ì…ë ¥ í¬ê¸°",
                                info="í¬ê¸°ê°€ í´ìˆ˜ë¡ ì •í™•ë„ê°€ ë†’ì•„ì§€ì§€ë§Œ ì†ë„ëŠ” ëŠë ¤ì§‘ë‹ˆë‹¤."
                            )
                            better_quality_checkbox = gr.Checkbox(
                                label="í–¥ìƒëœ í’ˆì§ˆ",
                                value=True,
                                info="ì†ë„ë¥¼ í¬ìƒí•˜ê³  ì¶œë ¥ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤."
                            )
                            withContours_checkbox = gr.Checkbox(
                                label="ìœ¤ê³½ì„  í‘œì‹œ",
                                value=True,
                                info="CFUì˜ ê²½ê³„ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."
                            )

                        with gr.Tab("AI íƒì§€"):
                            iou_threshold_slider = gr.Slider(
                                0.1, 0.9, 0.7,
                                step=0.1,
                                label="IOU ì„ê³„ê°’",
                                info="ë†’ì„ìˆ˜ë¡ ê²¹ì¹¨ ê¸°ì¤€ì´ ì—„ê²©í•´ì§‘ë‹ˆë‹¤."
                            )
                            conf_threshold_slider = gr.Slider(
                                0.1, 0.9, 0.25,
                                step=0.05,
                                label="ì‹ ë¢°ë„ ì„ê³„ê°’",
                                info="ë†’ì„ìˆ˜ë¡ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íƒì§€ë§Œ í‘œì‹œë©ë‹ˆë‹¤."
                            )

                        with gr.Tab("í¬ê¸° í•„í„°"):
                            min_area_percentile_slider = gr.Slider(
                                0, 10, 1,
                                step=1,
                                label="ìµœì†Œ í¬ê¸° ë°±ë¶„ìœ„ìˆ˜",
                                info="ë” ì‘ì€ CFUë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤ (1ì€ ê°€ì¥ ì‘ì€ 1% í•„í„°ë§)."
                            )
                            max_area_percentile_slider = gr.Slider(
                                90, 100, 99,
                                step=1,
                                label="ìµœëŒ€ í¬ê¸° ë°±ë¶„ìœ„ìˆ˜",
                                info="ë” í° ê°ì²´ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤ (99ëŠ” ê°€ì¥ í° 1% í•„í„°ë§)."
                            )

                        circularity_threshold_slider = gr.Slider(
                            0.0, 1.0, 0.8,
                            step=0.01,
                            label="ì›í˜•ë„ ì„ê³„ê°’",
                            info="ëŒ€ëµì ìœ¼ë¡œ ì›í˜•ì¸ CFUë§Œ ê°ì§€í•©ë‹ˆë‹¤ (1 = ì™„ë²½í•œ ì›)."
                        )

                with gr.Column(scale=4, min_width=300):
                    gr.Markdown("<div class='section-title'>ğŸ“Š ë¶„ì„ ê²°ê³¼</div>")
                    output_image = gr.Image(
                        type="numpy",
                        interactive=True,
                        elem_classes=["output-image"],
                        show_label=False
                    )
                    colony_count_text = gr.Textbox(
                        label="ì¹´ìš´íŠ¸ ê²°ê³¼",
                        lines=3,
                        elem_classes="result-text"
                    )

                    with gr.Row():
                        with gr.Column(scale=1):
                            remove_mode_button = gr.Button(
                                "ğŸ”„ í¸ì§‘ ëª¨ë“œ ì „í™˜",
                                variant="secondary",
                                elem_classes="button-secondary"
                            )
                            remove_mode_text = gr.Textbox(
                                label="í˜„ì¬ ëª¨ë“œ",
                                value="ğŸŸ¢ ADD MODE",
                                lines=1,
                                interactive=False
                            )
                        with gr.Column(scale=1):
                            remove_point_button = gr.Button(
                                "â†©ï¸ ìµœê·¼ í¬ì¸íŠ¸ ì·¨ì†Œ",
                                variant="secondary",
                                elem_classes="button-secondary"
                            )

                    # ê²°ê³¼ ì €ì¥ ê¸°ëŠ¥
                    save_button = gr.Button("ğŸ’¾ ê²°ê³¼ ì €ì¥", elem_classes="button-primary")
                    save_output = gr.Textbox(
                        label="ì €ì¥ ê²°ê³¼",
                        lines=2,
                        interactive=False,
                        elem_classes="result-text"
                    )

            with gr.Row(elem_classes="instruction-box"):
                gr.Markdown(
                    """
                    <h3>ğŸ“ ë¹ ë¥¸ ê°€ì´ë“œ</h3>
                    <p><span class="priority-high">1. ì´ë¯¸ì§€ ì—…ë¡œë“œ:</span> ë¶„ì„í•  CFU ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.</p>
                    <p><span class="priority-medium">2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì„¤ì •:</span> í•„ìš”ì— ë”°ë¼ í‘ë°± ë³€í™˜, ë°”ì´ë„ˆë¦¬ ë³€í™˜, ì—ì§€ ê²€ì¶œ, ìƒ¤í”ˆ ì„¤ì •ì„ ì¡°ì ˆí•˜ì„¸ìš”.</p>
                    <p><span class="priority-medium">3. ì „ì²˜ë¦¬ ì ìš©:</span> "ì „ì²˜ë¦¬ ì ìš©" ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì„¤ì •í•œ ì „ì²˜ë¦¬ë¥¼ ì´ë¯¸ì§€ì— ì ìš©í•˜ì„¸ìš”.</p>
                    <p><span class="priority-high">4. ì´ë¯¸ì§€ ë¶„ì„:</span> "ì´ë¯¸ì§€ ë¶„ì„" ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ì„¸ìš”.</p>
                    <p><span class="priority-medium">5. ìˆ˜ë™ ìˆ˜ì •:</span></p>
                    <ul>
                        <li>ğŸ‘† ì´ë¯¸ì§€ë¥¼ í´ë¦­í•˜ì—¬ ëˆ„ë½ëœ CFUë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ìë™ìœ¼ë¡œ ì‹ë³„ëœ CFUë¥¼ ì œê±°í•˜ì„¸ìš”.</li>
                        <li>ğŸ”„ 'í¸ì§‘ ëª¨ë“œ ì „í™˜' ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ê°€/ì œê±° ëª¨ë“œë¥¼ ì „í™˜í•˜ì„¸ìš”.</li>
                        <li>â†©ï¸ 'ìµœê·¼ í¬ì¸íŠ¸ ì·¨ì†Œ' ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ê°€ì¥ ìµœê·¼ì— ì¶”ê°€ëœ í¬ì¸íŠ¸ë¥¼ ì œê±°í•˜ì„¸ìš”.</li>
                    </ul>
                    <p><span class="priority-low">6. ë¶„ì„ ì„¤ì • ì¡°ì •:</span></p>
                    <ul>
                        <li>ì…ë ¥ í¬ê¸°: ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì„¤ì •í•˜ì„¸ìš” (í¬ê¸°ê°€ í´ìˆ˜ë¡ ì •í™•ë„ê°€ ì¦ê°€í•˜ì§€ë§Œ ì²˜ë¦¬ ì†ë„ëŠ” ëŠë ¤ì§‘ë‹ˆë‹¤).</li>
                        <li>IOU ì„ê³„ê°’: ê²¹ì¹˜ëŠ” íƒì§€ì— ëŒ€í•œ ë¯¼ê°ë„ë¥¼ ì¡°ì •í•˜ì„¸ìš” (ê°’ì´ ë†’ì„ìˆ˜ë¡ ê²¹ì¹¨ ê¸°ì¤€ì´ ì—„ê²©í•´ì§‘ë‹ˆë‹¤).</li>
                        <li>ì‹ ë¢°ë„ ì„ê³„ê°’: íƒì§€ì˜ ì‹ ë¢° ìˆ˜ì¤€ì„ ì„¤ì •í•˜ì„¸ìš” (ê°’ì´ ë†’ì„ìˆ˜ë¡ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íƒì§€ë§Œ í‘œì‹œë©ë‹ˆë‹¤).</li>
                        <li>ìµœì†Œ/ìµœëŒ€ í¬ê¸° ë°±ë¶„ìœ„ìˆ˜: ë„ˆë¬´ ì‘ê±°ë‚˜ í° CFUë¥¼ ì œì™¸í•˜ê¸° ìœ„í•´ í¬ê¸° í•„í„°ë¥¼ ì ìš©í•˜ì„¸ìš”.</li>
                        <li>ì›í˜•ë„ ì„ê³„ê°’: ëŒ€ëµì ìœ¼ë¡œ ì›í˜•ì¸ CFUë§Œ íƒì§€í•˜ê¸° ìœ„í•´ ì›í˜•ë„ í•„í„°ë¥¼ ì„¤ì •í•˜ì„¸ìš”.</li>
                    </ul>
                    """
                )

            # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²°
            def handle_image_upload(image):
                """ì´ë¯¸ì§€ ì—…ë¡œë“œ ì²˜ë¦¬"""
                if image is None:
                    return None, None
                
                try:
                    # PIL Imageë¡œ ë³€í™˜
                    if not isinstance(image, Image.Image):
                        image = Image.fromarray(image)
                    
                    # ì´ë¯¸ì§€ í¬ê¸° ì œí•œ
                    max_size = 1024
                    w, h = image.size
                    if max(w, h) > max_size:
                        scale = max_size / max(w, h)
                        new_w, new_h = int(w * scale), int(h * scale)
                        image = image.resize((new_w, new_h), Image.LANCZOS)
                    
                    # ì´ë¯¸ì§€ íˆìŠ¤í† ë¦¬ì— ì €ì¥
                    processed_image = image_history.set_original(image)
                    return processed_image, "ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤."
                except Exception as e:
                    print(f"Error in handle_image_upload: {str(e)}")
                    return None, f"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

            def apply_preprocessing(image, to_grayscale, binary, binary_threshold, edge_detection, sharpen, sharpen_amount):
                """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì ìš©"""
                if image is None:
                    return None
                
                try:
                    processed = preprocess_image(
                        image,
                        to_grayscale,
                        binary,
                        binary_threshold,
                        edge_detection,
                        sharpen,
                        sharpen_amount
                    )
                    if processed is not None:
                        return image_history.add_state(processed)
                    return image
                except Exception as e:
                    print(f"Error in apply_preprocessing: {str(e)}")
                    return image

            def reset_image():
                """ì´ë¯¸ì§€ ì´ˆê¸°í™”"""
                try:
                    return image_history.reset()
                except Exception as e:
                    print(f"Error in reset_image: {str(e)}")
                    return None

            def undo_image():
                """ì´ì „ ìƒíƒœë¡œ ë³µì›"""
                try:
                    return image_history.undo()
                except Exception as e:
                    print(f"Error in undo_image: {str(e)}")
                    return None

            # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²°
            input_image.upload(
                handle_image_upload,
                inputs=[input_image],
                outputs=[input_image, colony_count_text]
            )

            preprocess_button.click(
                apply_preprocessing,
                inputs=[
                    input_image,
                    to_grayscale,
                    binary,
                    binary_threshold,
                    edge_detection,
                    sharpen,
                    sharpen_amount
                ],
                outputs=[input_image]
            )

            reset_button.click(
                reset_image,
                inputs=[],
                outputs=[input_image]
            )

            undo_button.click(
                undo_image,
                inputs=[],
                outputs=[input_image]
            )

            segment_button.click(
                segment_and_count_colonies,
                inputs=[
                    input_image,
                    input_size_slider,
                    iou_threshold_slider,
                    conf_threshold_slider,
                    better_quality_checkbox,
                    withContours_checkbox,
                    min_area_percentile_slider,
                    max_area_percentile_slider,
                    circularity_threshold_slider
                ],
                outputs=[output_image, colony_count_text]
            )

            # ìˆ˜ë™ í¬ì¸íŠ¸ ì¶”ê°€/ì œê±° ì´ë²¤íŠ¸
            output_image.select(
                counter.add_or_remove_point,
                inputs=[output_image],
                outputs=[output_image, colony_count_text]
            )

            remove_point_button.click(
                counter.remove_last_point,
                inputs=[output_image],
                outputs=[output_image, colony_count_text]
            )

            remove_mode_button.click(
                counter.toggle_remove_mode,
                inputs=[],
                outputs=[output_image, remove_mode_text]
            )

            # ê²°ê³¼ ì €ì¥ ì´ë²¤íŠ¸
            save_button.click(
                save_results,
                inputs=[input_image, output_image],
                outputs=[save_output]
            )

        with gr.Tab("ë°°ì¹˜ ì²˜ë¦¬"):
            with gr.Row():
                with gr.Column(scale=6, min_width=300):
                    # íŒŒì¼ ì—…ë¡œë“œ ì»´í¬ë„ŒíŠ¸
                    gr.Markdown("<div class='section-title'>ğŸ“ ë°°ì¹˜ ì´ë¯¸ì§€ ì—…ë¡œë“œ</div>")
                    batch_files = gr.File(
                        label="ì´ë¯¸ì§€ íŒŒì¼ ì„ íƒ (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)",
                        file_count="multiple",
                        file_types=["image"],
                        elem_classes=["card"]
                    )

                    # ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •
                    with gr.Accordion("âš™ï¸ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •", open=True, elem_classes="accordion-header"):
                        with gr.Row():
                            batch_input_size = gr.Slider(
                                512, 2048, 1024,
                                step=64,
                                label="ì…ë ¥ í¬ê¸°",
                                info="í¬ê¸°ê°€ í´ìˆ˜ë¡ ì •í™•ë„ê°€ ë†’ì•„ì§€ì§€ë§Œ ì†ë„ëŠ” ëŠë ¤ì§‘ë‹ˆë‹¤."
                            )
                            batch_better_quality = gr.Checkbox(
                                label="í–¥ìƒëœ í’ˆì§ˆ",
                                value=True,
                                info="ì†ë„ë¥¼ í¬ìƒí•˜ê³  ì¶œë ¥ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤."
                            )

                        with gr.Row():
                            batch_iou_threshold = gr.Slider(
                                0.1, 0.9, 0.7,
                                step=0.1,
                                label="IOU ì„ê³„ê°’",
                                info="ë†’ì„ìˆ˜ë¡ ê²¹ì¹¨ ê¸°ì¤€ì´ ì—„ê²©í•´ì§‘ë‹ˆë‹¤."
                            )
                            batch_conf_threshold = gr.Slider(
                                0.1, 0.9, 0.25,
                                step=0.05,
                                label="ì‹ ë¢°ë„ ì„ê³„ê°’",
                                info="ë†’ì„ìˆ˜ë¡ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íƒì§€ë§Œ í‘œì‹œë©ë‹ˆë‹¤."
                            )

                        with gr.Row():
                            batch_min_area = gr.Slider(
                                0, 10, 1,
                                step=1,
                                label="ìµœì†Œ í¬ê¸° ë°±ë¶„ìœ„ìˆ˜",
                                info="ë” ì‘ì€ CFUë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤."
                            )
                            batch_max_area = gr.Slider(
                                90, 100, 99,
                                step=1,
                                label="ìµœëŒ€ í¬ê¸° ë°±ë¶„ìœ„ìˆ˜",
                                info="ë” í° ê°ì²´ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤."
                            )

                        batch_circularity = gr.Slider(
                            0.0, 1.0, 0.8,
                            step=0.01,
                            label="ì›í˜•ë„ ì„ê³„ê°’",
                            info="ëŒ€ëµì ìœ¼ë¡œ ì›í˜•ì¸ CFUë§Œ ê°ì§€í•©ë‹ˆë‹¤."
                        )

                    # ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ ë²„íŠ¼
                    with gr.Row():
                        batch_process_button = gr.Button(
                            "ğŸ” ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘",
                            variant="primary",
                            scale=2,
                            elem_classes="button-primary"
                        )

                with gr.Column(scale=4, min_width=300):
                    # ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
                    gr.Markdown("<div class='section-title'>ğŸ“Š ì²˜ë¦¬ ê²°ê³¼</div>")
                    batch_summary = gr.Textbox(
                        label="ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½",
                        lines=10,
                        elem_classes="result-text"
                    )
                    
                    # ê²°ê³¼ í´ë” ì—´ê¸° ë²„íŠ¼
                    open_output_button = gr.Button(
                        "ğŸ“‚ ê²°ê³¼ í´ë” ì—´ê¸°",
                        variant="secondary",
                        elem_classes="button-secondary"
                    )
            
            with gr.Row(elem_classes="instruction-box"):
                gr.Markdown(
                    """
                    <h3>ğŸ“ ë°°ì¹˜ ì²˜ë¦¬ ê°€ì´ë“œ</h3>
                    <p><span class="priority-high">1. ì´ë¯¸ì§€ ì—…ë¡œë“œ:</span> ë¶„ì„í•  ì—¬ëŸ¬ CFU ì´ë¯¸ì§€ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.</p>
                    <p><span class="priority-medium">2. ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •:</span> í•„ìš”ì— ë”°ë¼ ë¶„ì„ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì •í•˜ì„¸ìš”.</p>
                    <p><span class="priority-high">3. ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘:</span> "ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘" ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ì„¸ìš”.</p>
                    <p><span class="priority-medium">4. ê²°ê³¼ í™•ì¸:</span> ì²˜ë¦¬ê°€ ì™„ë£Œë˜ë©´ ê²°ê³¼ ìš”ì•½ì„ í™•ì¸í•˜ê³  "ê²°ê³¼ í´ë” ì—´ê¸°" ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì €ì¥ëœ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.</p>
                    <p><span class="priority-low">5. ì°¸ê³  ì‚¬í•­:</span></p>
                    <ul>
                        <li>ì²˜ë¦¬ëœ ì´ë¯¸ì§€ëŠ” batch_outputs í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.</li>
                        <li>ê° ë°°ì¹˜ ì²˜ë¦¬ëŠ” íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ìˆëŠ” í•˜ìœ„ í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.</li>
                        <li>summary.csv íŒŒì¼ì—ì„œ ëª¨ë“  ì´ë¯¸ì§€ì˜ ì²˜ë¦¬ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
                    </ul>
                    """
                )

            # ë°°ì¹˜ ì²˜ë¦¬ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
            def open_output_folder():
                import webbrowser
                output_dir = os.path.abspath("batch_outputs")
                webbrowser.open(f"file://{output_dir}")
                return "ê²°ê³¼ í´ë”ë¥¼ ì—´ì—ˆìŠµë‹ˆë‹¤."

            batch_process_button.click(
                handle_batch_upload,
                inputs=[
                    batch_files,
                    batch_input_size,
                    batch_iou_threshold,
                    batch_conf_threshold,
                    batch_better_quality,
                    gr.Checkbox(value=True, visible=False),  # withContours
                    batch_min_area,
                    batch_max_area,
                    batch_circularity
                ],
                outputs=[batch_summary]
            )

            open_output_button.click(
                open_output_folder,
                inputs=[],
                outputs=[batch_summary]
            )

if __name__ == "__main__":
    demo.launch()
