from ultralytics import YOLO
import gradio as gr
import torch
from PIL import Image, ImageDraw, ImageFont
import numpy as np
import cv2

# FastSAM ëª¨ë¸ ë¡œë“œ
model = YOLO('./weights/FastSAM-x.pt')

# ì¥ì¹˜ ì„¤ì •
device = torch.device(
    "cuda" if torch.cuda.is_available() else
    "mps" if torch.backends.mps.is_available() else "cpu"
)

def fast_process(colony_annotations, dish_annotation, image, device, scale, better_quality, mask_random_color, bbox, use_retina, withContours):
    """
    ë§ˆìŠ¤í¬ ì£¼ì„ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ê³ , í˜íŠ¸ë¦¬ ì ‘ì‹œëŠ” ì™¸ê³½ì„ ë§Œ ê·¸ë¦¬ë©° ì½œë¡œë‹ˆëŠ” ì±„ìš°ê³  ì™¸ê³½ì„ ì„ ê·¸ë¦½ë‹ˆë‹¤.
    """
    image_np = np.array(image).copy()

    # ì½œë¡œë‹ˆ ë§ˆìŠ¤í¬ ì²˜ë¦¬
    for ann in colony_annotations:
        mask = ann.cpu().numpy()
        if mask.ndim == 2:
            mask = mask > 0
            if mask_random_color:
                color = np.random.randint(0, 255, (3,)).tolist()
                image_np[mask] = color
            else:
                image_np[mask] = (0, 255, 0)  # ê¸°ë³¸ ì´ˆë¡ìƒ‰

        if withContours:
            contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            cv2.drawContours(image_np, contours, -1, (255, 0, 0), 2)  # íŒŒë€ìƒ‰ ê²½ê³„ì„ 

    # í˜íŠ¸ë¦¬ ì ‘ì‹œ ë§ˆìŠ¤í¬ ì²˜ë¦¬ (ì™¸ê³½ì„ ë§Œ)
    if dish_annotation is not None:
        dish_mask = dish_annotation.cpu().numpy()
        if dish_mask.ndim == 2:
            dish_mask = dish_mask > 0
            if withContours:
                contours, _ = cv2.findContours(dish_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(image_np, contours, -1, (0, 0, 255), 3)  # ë¹¨ê°„ìƒ‰ ì™¸ê³½ì„ 

    processed_image = Image.fromarray(image_np)
    return processed_image

class ColonyCounter:
    def __init__(self):
        self.manual_points = []  # ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€ëœ í¬ì¸íŠ¸ ì €ì¥
        self.auto_points = []    # ìë™ ê°ì§€ëœ colonyì˜ ì¤‘ì‹¬ì  ì €ì¥
        self.current_image = None
        self.auto_detected_count = 0
        self.remove_mode = False
        self.original_image = None
        self.last_method = None

    def reset(self):
        self.manual_points = []
        self.auto_points = []  # ìë™ í¬ì¸íŠ¸ ì´ˆê¸°í™” ì¶”ê°€
        self.current_image = None
        self.auto_detected_count = 0
        self.remove_mode = False
        self.original_image = None
        self.last_method = None

    def set_original_image(self, image):
        self.original_image = np.array(image)

    def toggle_remove_mode(self):
        self.remove_mode = not self.remove_mode
        img_with_points = self.draw_points()
        mode_text = "ğŸ”´ Remove Mode" if self.remove_mode else "ğŸŸ¢ Add Mode"
        return img_with_points, mode_text

    def add_or_remove_point(self, image, evt: gr.SelectData):
        try:
            if self.current_image is None and image is not None:
                self.current_image = np.array(image)

            x, y = evt.index

            if self.remove_mode:
                # ì œê±° ëª¨ë“œ: ê°€ì¥ ê°€ê¹Œìš´ ì  ì°¾ì•„ì„œ ì œê±°
                if self.manual_points:
                    closest_idx = self.find_closest_point(x, y)
                    if closest_idx is not None:
                        self.manual_points.pop(closest_idx)
            else:
                # ì¶”ê°€ ëª¨ë“œ: ìƒˆë¡œìš´ ì  ì¶”ê°€
                self.manual_points.append((x, y))

            img_with_points = self.draw_points()
            return img_with_points, self.get_count_text()
        except Exception as e:
            print(f"Error in add_or_remove_point: {str(e)}")
            return image, self.get_count_text()

    def find_closest_point(self, x, y, threshold=20):
        if not self.manual_points:
            return None

        distances = []
        for idx, (px, py) in enumerate(self.manual_points):
            dist = np.sqrt((x - px) ** 2 + (y - py) ** 2)
            distances.append((dist, idx))

        closest_dist, closest_idx = min(distances, key=lambda item: item[0])
        return closest_idx if closest_dist < threshold else None

    def remove_last_point(self, image):
        try:
            if self.manual_points:
                self.manual_points.pop()
                img_with_points = self.draw_points()
                return img_with_points, self.get_count_text()
            return image, self.get_count_text()
        except Exception as e:
            print(f"Error in remove_last_point: {str(e)}")
            return image, self.get_count_text()

    def get_count_text(self):
        try:
            method_text = f"Method: {self.last_method}\n" if self.last_method else ""
            return (f"{method_text}Total Colony Count: {self.auto_detected_count + len(self.manual_points)}\n"
                    f"ğŸ¤– Auto detected: {self.auto_detected_count}\n"
                    f"ğŸ‘† Manually added: {len(self.manual_points)}")
        except Exception as e:
            print(f"Error in get_count_text: {str(e)}")
            return "Error calculating count"

    def draw_points(self):
        try:
            if self.current_image is None:
                return None

            img_with_points = self.current_image.copy()  # í•œ ë²ˆë§Œ ë³µì‚¬
            overlay = np.zeros_like(img_with_points)  # ì˜¤ë²„ë ˆì´ ë ˆì´ì–´ ìƒì„±
            square_size = 25  # ìˆ˜ë™ í¬ì¸íŠ¸ì˜ í¬ê¸° ì„¤ì •

            # Font settings
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.7
            font_thickness = 1        # í°ìƒ‰ ê¸€ì”¨ë¥¼ ì–‡ê²Œ
            outline_thickness = 3     # ê²€ì€ìƒ‰ ì™¸ê³½ì„ ì„ ë‘ê»ê²Œ

            # ìë™ ê°ì§€ëœ colonyì— ë²ˆí˜¸ í‘œì‹œ
            for idx, (x, y) in enumerate(self.auto_points, 1):
                text = str(idx)
                (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)

                text_x = int(x - text_width / 2)
                text_y = int(y - 10)

                # ê²€ì€ìƒ‰ ì™¸ê³½ì„  (4ë°©í–¥)
                for dx, dy in [(-1, -1), (-1, 1), (1, -1), (1, 1)]:
                    cv2.putText(img_with_points, text,
                                (text_x + dx, text_y + dy),
                                font, font_scale, (0, 0, 0), outline_thickness)

                #í°ìƒ‰ í…ìŠ¤íŠ¸
                cv2.putText(img_with_points, text,
                            (text_x, text_y),
                            font, font_scale, (255, 255, 255), font_thickness)
                


            # ìˆ˜ë™ í¬ì¸íŠ¸ ëª¨ë‘ í•œë²ˆì— ê·¸ë¦¬ê¸°
            for x, y in self.manual_points:
                pt1 = (int(x - square_size / 2), int(y - square_size / 2))
                pt2 = (int(x + square_size / 2), int(y + square_size / 2))
                cv2.rectangle(overlay, pt1, pt2, (255, 0, 0), -1)

            # í•œ ë²ˆì˜ addWeighted ì—°ì‚°ìœ¼ë¡œ ì²˜ë¦¬
            cv2.addWeighted(overlay, 0.4, img_with_points, 1.0, 0, img_with_points)

            # ìˆ˜ë™ í¬ì¸íŠ¸ì— ë²ˆí˜¸ í‘œì‹œ
            for idx, (x, y) in enumerate(self.manual_points, len(self.auto_points) + 1):
                text = str(idx)
                (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)
                text_x = int(x - text_width / 2)
                text_y = int(y - 10)

                # ê²€ì€ìƒ‰ ì™¸ê³½ì„  (4ë°©í–¥)
                for dx, dy in [(-1, -1), (-1, 1), (1, -1), (1, 1)]:
                    cv2.putText(img_with_points, text,
                                (text_x + dx, text_y + dy),
                                font, font_scale, (0, 0, 0), outline_thickness)

                # í°ìƒ‰ í…ìŠ¤íŠ¸
                cv2.putText(img_with_points, text,
                            (text_x, text_y),
                            font, font_scale, (255, 0, 0), font_thickness) # í°ìƒ‰ì€ 255, 255, 255

            # ì œê±° ëª¨ë“œ í‘œì‹œ
            if self.remove_mode:
                overlay = img_with_points.copy()
                cv2.rectangle(overlay, (0, 0), (img_with_points.shape[1], 40), (255, 0, 0), -1)
                cv2.addWeighted(overlay, 0.3, img_with_points, 0.7, 0, img_with_points)
                cv2.putText(img_with_points, "REMOVE MODE", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

            return img_with_points
        except Exception as e:
            print(f"Error in draw_points: {str(e)}")
            return self.current_image

counter = ColonyCounter()

def segment_and_count_colonies(
    input_image,
    method='fastsam',
    input_size=1024,
    iou_threshold=0.7,
    conf_threshold=0.25,
    better_quality=False,
    withContours=True,
    mask_random_color=True,
    min_area_percentile=1,
    max_area_percentile=99,
    circularity_threshold=0.8
):
    try:
        if input_image is None:
            return None, "No input image provided."

        counter.reset()
        counter.set_original_image(input_image)
        counter.last_method = method.upper()

        # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
        input_size = int(input_size)
        w, h = input_image.size
        scale = input_size / max(w, h)
        new_w, new_h = int(w * scale), int(h * scale)
        input_resized = input_image.resize((new_w, new_h))

        # FastSAM ëª¨ë¸ ì‹¤í–‰
        results = model.predict(
            input_resized,
            device=device,
            conf=conf_threshold,
            iou=iou_threshold,
            imgsz=input_size,
            retina_masks=True
        )

        # ë§ˆìŠ¤í¬ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
        if not hasattr(results[0], 'masks') or results[0].masks is None:
            counter.current_image = np.array(input_resized)
            return np.array(input_resized), "No colonies detected"

        annotations = results[0].masks.data

        if len(annotations) == 0:
            counter.current_image = np.array(input_resized)
            return np.array(input_resized), "No colonies detected"

        # ëª¨ë“  ë§ˆìŠ¤í¬ì˜ ë©´ì  ê³„ì‚°
        areas = [np.sum(ann.cpu().numpy() > 0) for ann in annotations]

        # í˜íŠ¸ë¦¬ ì ‘ì‹œ ë§ˆìŠ¤í¬ ì°¾ê¸° (ê°€ì¥ í° ë§ˆìŠ¤í¬)
        dish_idx = np.argmax(areas)
        dish_annotation = annotations[dish_idx]
        colony_annotations = [ann for idx, ann in enumerate(annotations) if idx != dish_idx]

        # ë©´ì  í•„í„°ë§ ë° ì›í˜•ë„ ê³„ì‚°
        valid_colony_annotations = []
        counter.auto_points = []  # ì¤‘ì‹¬ì  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”

        for ann in colony_annotations:
            mask = ann.cpu().numpy()
            area = np.sum(mask > 0)

            # ì›í˜•ë„ ê³„ì‚°
            contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if len(contours) > 0:
                perimeter = cv2.arcLength(contours[0], True)
                circularity = 4 * np.pi * (area / (perimeter ** 2)) if perimeter > 0 else 0
                if circularity >= circularity_threshold:
                    valid_colony_annotations.append(ann)
                    # ë§ˆìŠ¤í¬ì˜ ì¤‘ì‹¬ì  ê³„ì‚°
                    y_indices, x_indices = np.where(mask > 0)
                    center_x = int(np.mean(x_indices))
                    center_y = int(np.mean(y_indices))
                    counter.auto_points.append((center_x, center_y))

        # ì´ë¯¸ì§€ ì²˜ë¦¬
        if valid_colony_annotations:
            fig = fast_process(
                colony_annotations=valid_colony_annotations,
                dish_annotation=dish_annotation,
                image=input_resized,
                device=device,
                scale=(1024 // input_size),
                better_quality=better_quality,
                mask_random_color=mask_random_color,
                bbox=None,
                use_retina=False,
                withContours=withContours
            )
        else:
            fig = input_resized

        # numpy ë°°ì—´ë¡œ ë³€í™˜ ë° auto_detected_count ì„¤ì •
        if isinstance(fig, Image.Image):
            counter.current_image = np.array(fig)
        else:
            counter.current_image = fig

        counter.auto_detected_count = len(counter.auto_points)

        # draw_pointsë¥¼ í˜¸ì¶œí•˜ì—¬ ìˆ«ì í‘œì‹œ
        counter.current_image = counter.draw_points()

        return counter.current_image, counter.get_count_text()

    except Exception as e:
        print(f"Error in segment_and_count_colonies: {str(e)}")
        if input_image is not None:
            return np.array(input_image), f"Error processing image: {str(e)}"
        return None, f"Error processing image: {str(e)}"

# CSS ìŠ¤íƒ€ì¼ ì •ì˜
css = """
.container {max-width: 1100px; margin: auto; padding: 20px;}
.header {text-align: center; margin-bottom: 30px;}
.result-text {font-size: 1.2em; font-weight: bold;}
.instruction-box {
    background-color: #000000;
    color: #ffffff;
    border-radius: 10px;
    padding: 20px;
    margin: 20px 0;
}
.input-image {border: 2px solid #ddd;}
.output-image {border: 2px solid #ddd;}
"""

# Gradio ì¸í„°í˜ì´ìŠ¤ ì„¤ì •
with gr.Blocks(theme=gr.themes.Soft(), css=css) as demo:
    gr.Markdown(
        """
        <div class="header">
            <h1>ğŸ”¬ Advanced Colony Counter</h1>
            <h3>Automated Colony Detection with Manual Correction</h3>
        </div>
        """
    )

    with gr.Tab("Colony Counter"):
        with gr.Row():
            with gr.Column(scale=1):
                input_image = gr.Image(
                    label="Upload Image",
                    type="pil",
                    elem_classes="input-image"
                )
                with gr.Row():
                    method_select = gr.Radio(
                        choices=['FastSAM'],
                        value='FastSAM',
                        label="Detection Method",
                        info="Choose AI-based detection method"
                    )
                    segment_button = gr.Button(
                        "ğŸ” Analyze Image",
                        variant="primary",
                        scale=2
                    )

                with gr.Accordion("âš™ï¸ Analysis Settings", open=False):
                    with gr.Tab("General"):
                        input_size_slider = gr.Slider(
                            512, 1024, 1024,
                            step=64,
                            label="Input Size",
                            info="Larger size = better accuracy but slower"
                        )
                        better_quality_checkbox = gr.Checkbox(
                            label="Enhanced Quality",
                            value=True,
                            info="Improve output quality at the cost of speed"
                        )
                        withContours_checkbox = gr.Checkbox(
                            label="Show Contours",
                            value=True,
                            info="Display colony boundaries"
                        )

                    with gr.Tab("FastSAM"):
                        iou_threshold_slider = gr.Slider(
                            0.1, 0.9, 0.7,
                            label="IOU Threshold",
                            info="Higher = stricter overlap detection"
                        )
                        conf_threshold_slider = gr.Slider(
                            0.1, 0.9, 0.25,
                            label="Confidence Threshold",
                            info="Higher = more confident detections"
                        )

                    with gr.Tab("Size Filters"):
                        min_area_percentile_slider = gr.Slider(
                            0, 10, 1,
                            label="Min Size Percentile",
                            info="Filter out smaller colonies (1 means smallest 1% filtered)"
                        )
                        max_area_percentile_slider = gr.Slider(
                            90, 100, 99,
                            label="Max Size Percentile",
                            info="Filter out larger objects (99 means largest 1% filtered)"
                        )

                    with gr.Tab("Shape Filters"):
                        circularity_threshold_slider = gr.Slider(
                            0.0, 1.0, 0.8,
                            label="Circularity Threshold",
                            info="Set a threshold to detect only circular colonies (1 = perfect circle)"
                        )

            with gr.Column(scale=1):
                output_image = gr.Image(
                    label="Analysis Result",
                    type="numpy",
                    interactive=True,
                    elem_classes="output-image"
                )
                colony_count_text = gr.Textbox(
                    label="Count Result",
                    lines=3,
                    elem_classes="result-text"
                )

                with gr.Row():
                    with gr.Column(scale=1):
                        remove_mode_button = gr.Button(
                            "ğŸ”„ Toggle Edit Mode",
                            variant="secondary"
                        )
                        remove_mode_text = gr.Textbox(
                            label="Current Mode",
                            value="ğŸŸ¢ Add Mode",
                            lines=1
                        )
                    with gr.Column(scale=1):
                        remove_point_button = gr.Button(
                            "â†©ï¸ Undo Last Point",
                            variant="secondary"
                        )

        with gr.Row(elem_classes="instruction-box"):
            gr.Markdown(
                """
                ### ğŸ“ ë¹ ë¥¸ ê°€ì´ë“œ
                1. **ì´ë¯¸ì§€ ì—…ë¡œë“œ**: ë¶„ì„í•  ì½œë¡œë‹ˆ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.
                2. **ë¶„ì„ ë°©ë²• ì„ íƒ**: FastSAM - AI ê¸°ë°˜ íƒì§€ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
                3. **ì´ë¯¸ì§€ ë¶„ì„**: Analyze Image ë²„íŠ¼ì„ ëˆŒëŸ¬ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì„¸ìš”.
                4. **ìˆ˜ë™ ìˆ˜ì •**: 
                   - ğŸ‘† ì´ë¯¸ì§€ë¥¼ í´ë¦­í•˜ì—¬ ëˆ„ë½ëœ ì½œë¡œë‹ˆë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
                   - ğŸ”„ 'Toggle Edit Mode' ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ê°€/ì œê±° ëª¨ë“œë¥¼ ì „í™˜í•˜ì„¸ìš”.
                   - â†©ï¸ 'Undo Last Point' ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ìµœê·¼ ì¶”ê°€ëœ í¬ì¸íŠ¸ë¥¼ ì œê±°í•˜ì„¸ìš”.
                5. **ë¶„ì„ ì„¤ì • ì¡°ì •**:
                   - **Input Size**: ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì„¤ì •í•˜ì„¸ìš” (í¬ë©´ ì •í™•ë„ ì¦ê°€, ì†ë„ ê°ì†Œ).
                   - **IOU Threshold**: ê²¹ì¹¨ì— ëŒ€í•œ ë¯¼ê°ë„ë¥¼ ì„¤ì •í•˜ì„¸ìš” (ë†’ì„ìˆ˜ë¡ ê²¹ì¹¨ì´ ì—„ê²©í•˜ê²Œ íŒë‹¨ë¨).
                   - **Confidence Threshold**: íƒì§€ ì‹ ë¢°ë„ë¥¼ ì„¤ì •í•˜ì„¸ìš” (ë†’ì„ìˆ˜ë¡ ì‹ ë¢°ë„ê°€ ë†’ì€ íƒì§€ë§Œ í‘œì‹œë¨).
                   - **Min/Max Size Percentile**: í¬ê¸° í•„í„°ë¥¼ ì„¤ì •í•˜ì—¬ ë„ˆë¬´ ì‘ê±°ë‚˜ í° ì½œë¡œë‹ˆë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤.
                   - **Circularity Threshold**: ì›í˜•ë„ í•„í„°ë¥¼ ì„¤ì •í•˜ì—¬ ì›í˜•ì— ê°€ê¹Œìš´ ì½œë¡œë‹ˆë§Œ íƒì§€í•©ë‹ˆë‹¤.
                """
            )

    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
    segment_button.click(
        segment_and_count_colonies,
        inputs=[
            input_image,
            method_select,
            input_size_slider,
            iou_threshold_slider,
            conf_threshold_slider,
            better_quality_checkbox,
            withContours_checkbox,
            min_area_percentile_slider,
            max_area_percentile_slider,
            circularity_threshold_slider
        ],
        outputs=[output_image, colony_count_text]
    )

    # ìˆ˜ë™ í¬ì¸íŠ¸ ì¶”ê°€/ì œê±° ì´ë²¤íŠ¸
    output_image.select(
        counter.add_or_remove_point,
        inputs=[output_image],
        outputs=[output_image, colony_count_text]
    )

    remove_point_button.click(
        counter.remove_last_point,
        inputs=[output_image],
        outputs=[output_image, colony_count_text]
    )

    remove_mode_button.click(
        counter.toggle_remove_mode,
        inputs=[],
        outputs=[output_image, remove_mode_text]
    )

# ì•± ì‹¤í–‰
demo.launch()
