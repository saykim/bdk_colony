from ultralytics import YOLO
import gradio as gr
import torch
from PIL import Image
import numpy as np
import cv2
import os
from datetime import datetime
import pandas as pd
from pathlib import Path
import json
import sys
import warnings

# FutureWarning ë¬´ì‹œ (ì˜µì…˜, ê¶Œì¥í•˜ì§€ ì•ŠìŒ)
warnings.filterwarnings("ignore", category=FutureWarning)

# ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
DEFAULT_OUTPUT_DIR = os.path.join(str(Path.home()), 'colony_counter_results')
os.makedirs(DEFAULT_OUTPUT_DIR, exist_ok=True)

# FastSAM ëª¨ë¸ ë¡œë“œ
try:
    model = YOLO('./weights/FastSAM-x.pt')
except Exception as e:
    print(f"Error loading YOLO model: {str(e)}")
    sys.exit(1)

# ì¥ì¹˜ ì„¤ì •
device = torch.device(
    "cuda" if torch.cuda.is_available() else
    "mps" if torch.backends.mps.is_available() else "cpu"
)

def fast_process(colony_annotations, dish_annotation, image, mask_random_color, withContours):
    """
    ë§ˆìŠ¤í¬ ì£¼ì„ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ê³ , í˜íŠ¸ë¦¬ ì ‘ì‹œëŠ” ì™¸ê³½ì„ ë§Œ ê·¸ë¦¬ë©° ì½œë¡œë‹ˆëŠ” ì±„ìš°ê³  ì™¸ê³½ì„ ì„ ê·¸ë¦½ë‹ˆë‹¤.
    """
    try:
        image_np = np.array(image).copy()

        # ì½œë¡œë‹ˆ ë§ˆìŠ¤í¬ ì²˜ë¦¬
        for ann in colony_annotations:
            ann_cpu = ann.cpu().numpy()
            if ann_cpu.ndim == 3 and ann_cpu.shape[0] == 1:
                ann_cpu = ann_cpu[0]  # (1, H, W) -> (H, W)
            
            mask = ann_cpu > 0
            if mask.ndim == 2:
                if mask_random_color:
                    color = np.random.randint(0, 255, (3,)).tolist()
                    image_np[mask] = color
                else:
                    image_np[mask] = (0, 255, 0)  # ê¸°ë³¸ ì´ˆë¡ìƒ‰

            if withContours:
                contours = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                contours = contours[0] if len(contours) == 2 else contours[1]
                cv2.drawContours(image_np, contours, -1, (255, 0, 0), 2)  # íŒŒë€ìƒ‰ ê²½ê³„ì„ 

        # í˜íŠ¸ë¦¬ ì ‘ì‹œ ë§ˆìŠ¤í¬ ì²˜ë¦¬ (ì™¸ê³½ì„ ë§Œ)
        if dish_annotation is not None:
            dish_mask = dish_annotation.cpu().numpy()
            if dish_mask.ndim == 3 and dish_mask.shape[0] == 1:
                dish_mask = dish_mask[0]
            if dish_mask.ndim == 2:
                dish_mask = dish_mask > 0
                if withContours:
                    contours = cv2.findContours(dish_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    contours = contours[0] if len(contours) == 2 else contours[1]
                    cv2.drawContours(image_np, contours, -1, (0, 0, 255), 3)  # ë¹¨ê°„ìƒ‰ ì™¸ê³½ì„ 

        processed_image = Image.fromarray(image_np)
        return processed_image
    except Exception as e:
        print(f"Error in fast_process: {str(e)}")
        return image

class ColonyCounter:
    """
    ì½œë¡œë‹ˆ ì¹´ìš´í„° í´ë˜ìŠ¤
    ìë™/ìˆ˜ë™ ì½œë¡œë‹ˆ ê°ì§€ ë° ì¹´ìš´íŒ…ì„ ìœ„í•œ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    def __init__(self):
        """
        ì½œë¡œë‹ˆ ì¹´ìš´í„° ì´ˆê¸°í™”
        - manual_points: ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€ëœ í¬ì¸íŠ¸ ëª©ë¡
        - auto_points: AIê°€ ìë™ ê°ì§€í•œ colony ì¤‘ì‹¬ì  ëª©ë¡
        - current_image: í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì´ë¯¸ì§€
        - auto_detected_count: ìë™ ê°ì§€ëœ ì½œë¡œë‹ˆ ìˆ˜
        - remove_mode: í¬ì¸íŠ¸ ì œê±° ëª¨ë“œ ì—¬ë¶€
        - last_method: ë§ˆì§€ë§‰ìœ¼ë¡œ ì‚¬ìš©ëœ ê°ì§€ ë°©ë²•
        """
        self.manual_points = []
        self.auto_points = []
        self.current_image = None
        self.auto_detected_count = 0
        self.remove_mode = False
        self.original_image = None
        self.last_method = None

    def reset(self):
        self.manual_points = []
        self.auto_points = []
        self.current_image = None
        self.auto_detected_count = 0
        self.remove_mode = False
        self.original_image = None
        self.last_method = None

    def set_original_image(self, image):
        self.original_image = np.array(image)

    def toggle_remove_mode(self):
        self.remove_mode = not self.remove_mode
        img_with_points = self.draw_points()
        mode_text = "ğŸ”´ Remove Mode" if self.remove_mode else "ğŸŸ¢ Add Mode"
        return img_with_points, mode_text

    def find_closest_point(self, x, y, threshold=20):
        """
        í´ë¦­í•œ ì¢Œí‘œì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ í¬ì¸íŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

        Args:
            x (int): í´ë¦­í•œ x ì¢Œí‘œ
            y (int): í´ë¦­í•œ y ì¢Œí‘œ
            threshold (int): ìµœëŒ€ í—ˆìš© ê±°ë¦¬

        Returns:
            tuple: (ì¸ë±ìŠ¤, í¬ì¸íŠ¸ íƒ€ì…) ë˜ëŠ” (None, None)
        """
        min_dist = float('inf')
        closest_idx = None
        point_type = None

        # ìë™ ê°ì§€ í¬ì¸íŠ¸ í™•ì¸
        for idx, (px, py) in enumerate(self.auto_points):
            dist = np.sqrt((x - px) ** 2 + (y - py) ** 2)
            if dist < min_dist and dist <= threshold:
                min_dist = dist
                closest_idx = idx
                point_type = 'auto'

        # ìˆ˜ë™ ì¶”ê°€ í¬ì¸íŠ¸ í™•ì¸
        for idx, (px, py) in enumerate(self.manual_points):
            dist = np.sqrt((x - px) ** 2 + (y - py) ** 2)
            if dist < min_dist and dist <= threshold:
                min_dist = dist
                closest_idx = idx
                point_type = 'manual'

        return closest_idx, point_type

    def add_or_remove_point(self, image, evt: gr.SelectData):
        """
        ì´ë¯¸ì§€ë¥¼ í´ë¦­í•˜ì—¬ í¬ì¸íŠ¸ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì œê±°í•©ë‹ˆë‹¤.

        Args:
            image (numpy.ndarray): í˜„ì¬ ì´ë¯¸ì§€
            evt (gr.SelectData): í´ë¦­ ì´ë²¤íŠ¸ ë°ì´í„°

        Returns:
            tuple: (ì—…ë°ì´íŠ¸ëœ ì´ë¯¸ì§€, ì¹´ìš´íŠ¸ í…ìŠ¤íŠ¸)
        """
        try:
            if self.current_image is None and image is not None:
                self.current_image = np.array(image)

            x, y = evt.index

            if self.remove_mode:
                # ê°€ì¥ ê°€ê¹Œìš´ í¬ì¸íŠ¸ ì°¾ê¸°
                closest_idx, point_type = self.find_closest_point(x, y)
                
                if closest_idx is not None:
                    if point_type == 'auto':
                        self.auto_points.pop(closest_idx)
                        self.auto_detected_count = len(self.auto_points)
                        print(f"ìë™ ê°ì§€ í¬ì¸íŠ¸ ì œê±°: {closest_idx}")
                    elif point_type == 'manual':
                        self.manual_points.pop(closest_idx)
                        print(f"ìˆ˜ë™ ì¶”ê°€ í¬ì¸íŠ¸ ì œê±°: {closest_idx}")
                else:
                    print("ê·¼ì²˜ì—ì„œ ì œê±°í•  í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # í¬ì¸íŠ¸ ì¶”ê°€
                self.manual_points.append((x, y))
                print(f"ìƒˆ í¬ì¸íŠ¸ ì¶”ê°€: ({x}, {y})")

            img_with_points = self.draw_points()
            return img_with_points, self.get_count_text()
        except Exception as e:
            print(f"í¬ì¸íŠ¸ ì¶”ê°€/ì œê±° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return image, self.get_count_text()

    def remove_last_point(self, image):
        try:
            if self.manual_points:
                self.manual_points.pop()
                img_with_points = self.draw_points()
                return img_with_points, self.get_count_text()
            return image, self.get_count_text()
        except Exception as e:
            print(f"Error in remove_last_point: {str(e)}")
            return image, self.get_count_text()

    def get_count_text(self):
        try:
            method_text = f"Method: {self.last_method}\n" if self.last_method else ""
            total = self.auto_detected_count + len(self.manual_points)
            return (f"{method_text}Total Colony Count: {total}\n"
                    f"ğŸ¤– Auto detected: {self.auto_detected_count}\n"
                    f"ğŸ‘† Manually added: {len(self.manual_points)}")
        except Exception as e:
            print(f"Error in get_count_text: {str(e)}")
            return "Error calculating count"

    def draw_points(self):
        """
        í˜„ì¬ ì´ë¯¸ì§€ì— í¬ì¸íŠ¸ë¥¼ ê·¸ë ¤ì„œ ë°˜í™˜

        Returns:
            numpy.ndarray: í¬ì¸íŠ¸ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€
        """
        try:
            if self.current_image is None:
                return None

            img_with_points = self.current_image.copy()
            overlay = np.zeros_like(img_with_points)
            square_size = 30  # 25ì—ì„œ 30ìœ¼ë¡œ 20% ì¦ê°€

            # ê¸€ê¼´ ì„¤ì •
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.7
            font_thickness = 1
            outline_thickness = 3

            # ìë™ ê°ì§€ëœ CFU ë²ˆí˜¸ í‘œì‹œ (íŒŒë€ìƒ‰)
            for idx, (x, y) in enumerate(self.auto_points, 1):
                text = str(idx)
                (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)

                text_x = int(x - text_width / 2)
                text_y = int(y - 10)

                # ê²€ì€ìƒ‰ ì™¸ê³½ì„ 
                for dx, dy in [(-1, -1), (-1, 1), (1, -1), (1, 1)]:
                    cv2.putText(img_with_points, text,
                                (text_x + dx, text_y + dy),
                                font, font_scale, (0, 0, 0), outline_thickness)

                # íŒŒë€ìƒ‰ í…ìŠ¤íŠ¸
                cv2.putText(img_with_points, text,
                            (text_x, text_y),
                            font, font_scale, (255, 0, 0), font_thickness)  # íŒŒë€ìƒ‰ í…ìŠ¤íŠ¸

            # ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€ëœ í¬ì¸íŠ¸ ì‚¬ê°í˜• ê·¸ë¦¬ê¸° (ë¹¨ê°„ìƒ‰)
            for x, y in self.manual_points:
                pt1 = (int(x - square_size / 2), int(y - square_size / 2))
                pt2 = (int(x + square_size / 2), int(y + square_size / 2))
                cv2.rectangle(overlay, pt1, pt2, (0, 0, 255), -1)  # ë¹¨ê°„ìƒ‰ ì‚¬ê°í˜•

            # ì˜¤ë²„ë ˆì´ ì ìš©
            cv2.addWeighted(overlay, 0.4, img_with_points, 1.0, 0, img_with_points)

            # ìˆ˜ë™ í¬ì¸íŠ¸ ë²ˆí˜¸ í‘œì‹œ (íŒŒë€ìƒ‰)
            for idx, (x, y) in enumerate(self.manual_points, len(self.auto_points) + 1):
                text = str(idx)
                (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)
                text_x = int(x - text_width / 2)
                text_y = int(y - 10)

                # í•˜ì–€ìƒ‰ ì™¸ê³½ì„ 
                for dx, dy in [(-1, -1), (-1, 1), (1, -1), (1, 1)]:
                    cv2.putText(img_with_points, text,
                                (text_x + dx, text_y + dy),
                                font, font_scale, (255, 255, 255), outline_thickness)

                # íŒŒë€ìƒ‰ í…ìŠ¤íŠ¸
                cv2.putText(img_with_points, text,
                            (text_x, text_y),
                            font, font_scale, (255, 0, 0), font_thickness)  # íŒŒë€ìƒ‰ í…ìŠ¤íŠ¸

            # ì œê±° ëª¨ë“œ í‘œì‹œ
            if self.remove_mode:
                overlay_mode = img_with_points.copy()
                cv2.rectangle(overlay_mode, (0, 0), (img_with_points.shape[1], 40), (255, 0, 0), -1)  # ë¹¨ê°„ìƒ‰ ìƒì
                cv2.addWeighted(overlay_mode, 0.3, img_with_points, 0.7, 0, img_with_points)
                cv2.putText(img_with_points, "ì œê±° ëª¨ë“œ", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)  # í°ìƒ‰ í…ìŠ¤íŠ¸

            # Total Count í‘œì‹œ ì¶”ê°€
            total_count = self.auto_detected_count + len(self.manual_points)
            text = f'Total Count: {total_count}'
            
            # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
            height, width = img_with_points.shape[:2]
            
            # í°íŠ¸ ì„¤ì •
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 1.5
            font_thickness = 2
            
            # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
            (text_width, text_height), baseline = cv2.getTextSize(
                text, font, font_scale, font_thickness
            )
            
            # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ê³„ì‚° (ì¢Œí•˜ë‹¨)
            text_x = 20
            text_y = height - 20  # í•˜ë‹¨ì—ì„œ 20í”½ì…€ ì—¬ë°±
            
            # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸° (ê°€ë…ì„± í–¥ìƒ)
            padding = 5
            cv2.rectangle(
                img_with_points,
                (text_x - padding, text_y - text_height - padding),
                (text_x + text_width + padding, text_y + padding),
                (0, 0, 0),  # ê²€ì • ë°°ê²½
                -1
            )
            
            # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
            cv2.putText(
                img_with_points,
                text,
                (text_x, text_y),
                font,
                font_scale,
                (0, 255, 255),  # ë…¸ë€ìƒ‰
                font_thickness
            )

            return img_with_points
        
        except Exception as e:
            print(f"í¬ì¸íŠ¸ ê·¸ë¦¬ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return self.current_image

    def save_results(self, output_dir, img_filename):
        """ê²°ê³¼ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì €ì¥"""
        try:
            image_name = os.path.splitext(img_filename)[0]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            save_dir = os.path.join(output_dir, f"{image_name}_{timestamp}")
            os.makedirs(save_dir, exist_ok=True)
            
            if self.original_image is not None:
                original_path = os.path.join(save_dir, "original.png")
                cv2.imwrite(original_path, cv2.cvtColor(self.original_image, cv2.COLOR_RGB2BGR))
            
            if self.current_image is not None:
                result_path = os.path.join(save_dir, "result.png")
                cv2.imwrite(result_path, cv2.cvtColor(self.current_image, cv2.COLOR_RGB2BGR))
            
            result_txt = os.path.join(save_dir, "count_results.txt")
            with open(result_txt, 'w') as f:
                f.write(self.get_count_text())
                
            return f"Results saved to {save_dir}"
        except Exception as e:
            return f"Error saving results: {str(e)}"

class ImagePreprocessHistory:
    def __init__(self):
        self.original_image = None
        self.current_image = None
        self.history = []
        self.current_index = -1

    def set_original(self, image):
        """ì›ë³¸ ì´ë¯¸ì§€ ì„¤ì •"""
        if image is None:
            return None
            
        # PIL Imageë¡œ ë³€í™˜
        if not isinstance(image, Image.Image):
            try:
                image = Image.fromarray(image)
            except Exception as e:
                print(f"Error converting image: {str(e)}")
                return None
        
        self.original_image = image
        self.current_image = image
        self.history = [image]
        self.current_index = 0
        return image

    def add_state(self, image):
        """ìƒˆë¡œìš´ ì´ë¯¸ì§€ ìƒíƒœ ì¶”ê°€"""
        if image is None:
            return None
            
        # PIL Imageë¡œ ë³€í™˜
        if not isinstance(image, Image.Image):
            try:
                image = Image.fromarray(image)
            except Exception as e:
                print(f"Error converting image: {str(e)}")
                return None
        
        # í˜„ì¬ ì¸ë±ìŠ¤ ì´í›„ì˜ íˆìŠ¤í† ë¦¬ëŠ” ì‚­ì œ
        self.history = self.history[:self.current_index + 1]
        self.history.append(image)
        self.current_index = len(self.history) - 1
        self.current_image = image
        return image

    def reset(self):
        """ì›ë³¸ ì´ë¯¸ì§€ë¡œ ë³µì›"""
        if self.original_image is not None:
            self.current_image = self.original_image
            self.current_index = 0
            return self.original_image
        return None

    def redo(self):
        """ì´ì „ ìƒíƒœë¡œ ë³µì›"""
        if self.current_index > 0:
            self.current_index -= 1
            self.current_image = self.history[self.current_index]
            return self.current_image
        return self.current_image

# ì „ì—­ ì´ë¯¸ì§€ íˆìŠ¤í† ë¦¬ ê°ì²´
image_history = ImagePreprocessHistory()

def segment_and_count_colonies(
    input_image,
    method='fastsam',
    input_size=1024,
    iou_threshold=0.7,
    conf_threshold=0.25,
    better_quality=False,
    withContours=True,
    mask_random_color=True,
    min_area_percentile=1,
    max_area_percentile=99,
    circularity_threshold=0.8
):
    try:
        if input_image is None:
            return None, "No input image provided.", None

        # ìƒˆë¡œìš´ counter ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        new_counter = ColonyCounter()
        new_counter.reset()
        new_counter.set_original_image(input_image)
        new_counter.last_method = method.upper()

        # ì…ë ¥ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
        input_size = int(input_size)
        w, h = input_image.size
        scale = input_size / max(w, h)
        new_w, new_h = int(w * scale), int(h * scale)
        input_resized = input_image.resize((new_w, new_h))

        # FastSAM ëª¨ë¸ ì˜ˆì¸¡
        input_array = np.array(input_resized)
        results = model.predict(
            source=input_array,
            device=device,
            conf=conf_threshold,
            iou=iou_threshold,
            imgsz=input_size,
            retina_masks=True  # FastSAM ë§ˆìŠ¤í¬ë¥¼ ìœ„í•´ í•„ìš”
        )

        annotations = getattr(results[0].masks, 'data', None)
        if annotations is None or len(annotations) == 0:
            new_counter.current_image = np.array(input_resized)
            return np.array(input_resized), "No colonies detected", new_counter

        # ê° ë§ˆìŠ¤í¬ ë©´ì 
        areas = [np.sum(ann.cpu().numpy() > 0) for ann in annotations]

        # ê°€ì¥ í° ë§ˆìŠ¤í¬ = í˜íŠ¸ë¦¬ ì ‘ì‹œ(dish)
        dish_idx = np.argmax(areas)
        dish_annotation = annotations[dish_idx]
        colony_annotations = [ann for idx, ann in enumerate(annotations) if idx != dish_idx]

        # í•„í„°ë§ + ì›í˜•ë„ ê³„ì‚°
        valid_colony_annotations = []
        new_counter.auto_points = []  # ìë™ ê°ì§€ëœ ì  ì´ˆê¸°í™”

        for ann in colony_annotations:
            ann_cpu = ann.cpu().numpy()
            if ann_cpu.ndim == 3 and ann_cpu.shape[0] == 1:
                ann_cpu = ann_cpu[0]
            mask = ann_cpu > 0
            area = np.sum(mask)

            contours = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            contours = contours[0] if len(contours) == 2 else contours[1]
            if contours and len(contours) > 0:
                perimeter = cv2.arcLength(contours[0], True)
                circularity = 4 * np.pi * (area / (perimeter ** 2)) if perimeter > 0 else 0
                if circularity >= circularity_threshold:
                    valid_colony_annotations.append(ann)
                    # ë§ˆìŠ¤í¬ ì¤‘ì‹¬ì 
                    y_indices, x_indices = np.where(mask)
                    center_x = int(np.mean(x_indices))
                    center_y = int(np.mean(y_indices))
                    new_counter.auto_points.append((center_x, center_y))

        if valid_colony_annotations:
            processed_image = fast_process(
                colony_annotations=valid_colony_annotations,
                dish_annotation=dish_annotation,
                image=input_resized,
                mask_random_color=mask_random_color,
                withContours=withContours
            )
        else:
            processed_image = input_resized

        # counter ê°ì²´ì— ê²°ê³¼ ë°˜ì˜
        if isinstance(processed_image, Image.Image):
            new_counter.current_image = np.array(processed_image)
        else:
            new_counter.current_image = processed_image

        new_counter.auto_detected_count = len(new_counter.auto_points)
        new_counter.current_image = new_counter.draw_points()

        return new_counter.current_image, new_counter.get_count_text(), new_counter
    except Exception as e:
        print(f"Error in segment_and_count_colonies: {str(e)}")
        if input_image is not None:
            return np.array(input_image), f"Error processing image: {str(e)}", None
        return None, f"Error processing image: {str(e)}", None

def batch_process(
    input_dir,
    output_dir='',
    method='fastsam',
    input_size=1024,
    iou_threshold=0.7,
    conf_threshold=0.25,
    better_quality=False,
    withContours=True,
    mask_random_color=True,
    min_area_percentile=1,
    max_area_percentile=99,
    circularity_threshold=0.8
):
    """ì—¬ëŸ¬ ì´ë¯¸ì§€ ì¼ê´„ ì²˜ë¦¬"""
    try:
        if not isinstance(input_dir, str) or not os.path.isdir(input_dir):
            return "Invalid input directory.", []

        if not output_dir or output_dir.strip() == "":
            output_dir = DEFAULT_OUTPUT_DIR

        try:
            os.makedirs(output_dir, exist_ok=True)
        except Exception as e:
            return f"Error creating output directory: {str(e)}", []

        valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')
        image_files = [f for f in os.listdir(input_dir) 
                       if f.lower().endswith(valid_extensions)]
        
        if not image_files:
            return "No valid image files found in the input directory.", []

        results = []
        progress_text = (f"Processing images from: {input_dir}\n"
                         f"Saving results to: {output_dir}\n\n")
        gallery_items = []
        
        for idx, img_file in enumerate(image_files, 1):
            try:
                progress_text += f"Processing image {idx}/{len(image_files)}: {img_file}\n"
                img_path = os.path.join(input_dir, img_file)

                try:
                    input_image = Image.open(img_path).convert('RGB')
                except Exception as e:
                    raise Exception(f"Error loading image: {str(e)}")
                
                # ì´ë¯¸ì§€ ë¶„ì„
                result_image, count_text, counter = segment_and_count_colonies(
                    input_image=input_image,
                    method=method,
                    input_size=input_size,
                    iou_threshold=iou_threshold,
                    conf_threshold=conf_threshold,
                    better_quality=better_quality,
                    withContours=withContours,
                    mask_random_color=mask_random_color,
                    min_area_percentile=min_area_percentile,
                    max_area_percentile=max_area_percentile,
                    circularity_threshold=circularity_threshold
                )
                
                if counter is not None:
                    save_result = counter.save_results(output_dir, img_file)
                else:
                    save_result = "Failed to process image."

                results.append({
                    'filename': img_file,
                    'count_text': count_text,
                    'save_result': save_result
                })
                
                if result_image is not None:
                    gallery_items.append({
                        'image': result_image,
                        'caption': f"{img_file}\n{count_text}"
                    })
                else:
                    gallery_items.append({
                        'image': None,
                        'caption': f"{img_file}\n{count_text}"
                    })
                
                progress_text += f"Processed {img_file}: {count_text}\n{save_result}\n\n"
            except Exception as e:
                error_msg = f"Error processing {img_file}: {str(e)}\n"
                print(error_msg)
                results.append({
                    'filename': img_file,
                    'count_text': f"Error: {str(e)}",
                    'save_result': "Failed to save results"
                })
                gallery_items.append({
                    'image': None,
                    'caption': f"{img_file}\nError: {str(e)}"
                })
                progress_text += error_msg

        summary_path = os.path.join(output_dir, "batch_summary.csv")
        try:
            pd.DataFrame(results).to_csv(summary_path, index=False)
        except Exception as e:
            progress_text += f"Error saving summary CSV: {str(e)}\n"

        # summary.json ìƒì„±
        try:
            create_summary(results, output_dir)
            progress_text += f"\nBatch processing complete. Summary saved to {summary_path} and summary.json"
        except Exception as e:
            progress_text += f"\nError creating summary: {str(e)}"

        return progress_text, gallery_items

    except Exception as e:
        return f"Error in batch processing: {str(e)}", []

def get_output_subdir(output_dir):
    date_str = datetime.now().strftime("%Y-%m-%d")
    time_str = datetime.now().strftime("%H-%M-%S")
    return os.path.join(output_dir, date_str, time_str)

def create_summary(results, output_dir):
    summary = {
        'date': datetime.now().strftime("%Y-%m-%d"),
        'time': datetime.now().strftime("%H:%M:%S"),
        'total_images': len(results),
        'successful': sum(1 for r in results if 'Error' not in r['count_text']),
        'failed': sum(1 for r in results if 'Error' in r['count_text']),
        'results': results
    }
    
    summary_json_path = os.path.join(output_dir, "summary.json")
    with open(summary_json_path, 'w') as f:
        json.dump(summary, f, indent=4)
        
    df = pd.DataFrame(results)
    csv_path = os.path.join(output_dir, "results.csv")
    df.to_csv(csv_path, index=False)

def preprocess_image(image, method='none'):
    """
    ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
    Args:
        image: PIL Image ë˜ëŠ” numpy array
        method: ì „ì²˜ë¦¬ ë°©ë²• ('grayscale', 'binary', 'edge', 'sharpen', 'none')
    Returns:
        ì²˜ë¦¬ëœ PIL Image
    """
    try:
        # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
        if isinstance(image, Image.Image):
            image_np = np.array(image)
        else:
            image_np = image.copy()

        if method == 'none':
            return Image.fromarray(image_np)

        if method == 'grayscale':
            if len(image_np.shape) == 3:
                gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
                return Image.fromarray(cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB))
            return Image.fromarray(image_np)

        elif method == 'binary':
            if len(image_np.shape) == 3:
                gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
            else:
                gray = image_np
            _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
            return Image.fromarray(cv2.cvtColor(binary, cv2.COLOR_GRAY2RGB))

        elif method == 'edge':
            if len(image_np.shape) == 3:
                gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
            else:
                gray = image_np
            edges = cv2.Canny(gray, 100, 200)
            return Image.fromarray(cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB))

        elif method == 'sharpen':
            kernel = np.array([[-1,-1,-1],
                             [-1, 9,-1],
                             [-1,-1,-1]])
            sharpened = cv2.filter2D(image_np, -1, kernel)
            return Image.fromarray(sharpened)

        return Image.fromarray(image_np)
    except Exception as e:
        print(f"Error in preprocess_image: {str(e)}")
        return image

# CSS ìŠ¤íƒ€ì¼ ìˆ˜ì •
css = """
.container {max-width: 1100px; margin: auto; padding: 20px;}
.header {text-align: center; margin-bottom: 30px;}
.result-text {font-size: 1.2em; font-weight: bold;}
.instruction-box {
    background-color: #000000;
    color: #ffffff;
    border-radius: 10px;
    padding: 20px;
    margin: 20px 0;
}
.input-image {
    border: 2px solid #ddd;
    margin-top: 10px;
    border-radius: 8px;
    background-color: #f8f9fa;
    max-height: 600px;
}
.output-image {
    border: 2px solid #ddd;
    margin-top: 10px;
    border-radius: 8px;
    background-color: #f8f9fa;
    min-height: 600px;
}
.image-label {
    font-size: 1.1em;
    font-weight: bold;
    margin-bottom: 5px;
    color: #444;
}
.footer {
    text-align: center;
    padding: 20px;
    margin-top: 30px;
    color: #666;
    font-size: 0.9em;
}
"""

# ì „ì—­ counter ê°ì²´
counter = ColonyCounter()

with gr.Blocks(theme=gr.themes.Soft(), css=css) as demo:
    gr.Markdown(
        """
        <div class="header">
            <h1>ğŸ”¬ Advanced Colony Counter</h1>
            <h3>AI-Powered Colony Detection & Analysis</h3>
        </div>
        """
    )

    with gr.Tabs():
        with gr.Tab("Colony Counter"):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown(
                        """<p class="image-label">Upload Image</p>""",
                        elem_classes="image-label"
                    )
                    input_image = gr.Image(
                        label="",
                        type="pil",
                        elem_classes="input-image",
                        show_label=False,
                        show_download_button=False
                    )
                    
                    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì˜µì…˜
                    with gr.Row():
                        preprocess_method = gr.Radio(
                            choices=['none', 'grayscale', 'binary', 'edge', 'sharpen'],
                            value='none',
                            label="Image Preprocessing",
                            info="Select preprocessing method"
                        )
                    
                    with gr.Row():
                        preprocess_button = gr.Button(
                            "ğŸ¨ Apply Preprocessing",
                            variant="secondary",
                            scale=1
                        )
                        reset_button = gr.Button(
                            "â†º Reset to Original",
                            variant="secondary",
                            scale=1
                        )
                        redo_button = gr.Button(
                            "â†¶ Undo Preprocessing",
                            variant="secondary",
                            scale=1
                        )

                    with gr.Row():
                        method_select = gr.Radio(
                            choices=['AI Detection'],
                            value='AI Detection',
                            label="Detection Method",
                            info="Advanced AI-based colony detection"
                        )
                        segment_button = gr.Button(
                            "ğŸ” Analyze Image",
                            variant="primary",
                            scale=2
                        )

                    # ë¶„ì„ ì„¤ì • ì¶”ê°€
                    with gr.Accordion("âš™ï¸ Analysis Settings", open=False):
                        with gr.Row():
                            input_size_slider = gr.Slider(
                                512, 1024, 1024,
                                step=64,
                                label='Input Size',
                                info='Larger size = better accuracy but slower'
                            )
                            better_quality_checkbox = gr.Checkbox(
                                label="Enhanced Quality",
                                value=True,
                                info="Improve output quality"
                            )
                        
                        with gr.Row():
                            withContours_checkbox = gr.Checkbox(
                                label="Show Contours",
                                value=True,
                                info="Display colony boundaries"
                            )
                            iou_threshold_slider = gr.Slider(
                                0.1, 0.9, 0.7,
                                label="IOU Threshold",
                                info="Higher = stricter detection"
                            )
                        
                        with gr.Row():
                            conf_threshold_slider = gr.Slider(
                                0.1, 0.9, 0.25,
                                label="Confidence Threshold",
                                info="Higher = more confident detection"
                            )
                            circularity_threshold_slider = gr.Slider(
                                0.0, 1.0, 0.8,
                                label="Circularity",
                                info="Higher = more circular colonies"
                            )
                        
                        with gr.Row():
                            min_area_percentile_slider = gr.Slider(
                                0, 10, 1,
                                label="Min Size %",
                                info="Filter smaller colonies"
                            )
                            max_area_percentile_slider = gr.Slider(
                                90, 100, 99,
                                label="Max Size %",
                                info="Filter larger objects"
                            )

                with gr.Column(scale=1):
                    gr.Markdown(
                        """<p class="image-label">Analysis Result</p>""",
                        elem_classes="image-label"
                    )
                    output_image = gr.Image(
                        label="",
                        type="numpy",
                        interactive=True,
                        elem_classes="output-image",
                        show_label=False,
                        show_download_button=True
                    )
                    colony_count_text = gr.Textbox(
                        label="Count Result",
                        lines=3,
                        elem_classes="result-text"
                    )

                    with gr.Row():
                        with gr.Column(scale=1):
                            remove_mode_button = gr.Button(
                                "ğŸ”„ Toggle Edit Mode",
                                variant="secondary"
                            )
                            remove_mode_text = gr.Textbox(
                                label="Current Mode",
                                value="ğŸŸ¢ Add Mode",
                                lines=1
                            )
                        with gr.Column(scale=1):
                            remove_point_button = gr.Button(
                                "â†©ï¸ Undo Last Point",
                                variant="secondary"
                            )

        with gr.Tab("Batch Processing"):
            with gr.Row():
                input_dir = gr.Textbox(
                    label="Input Directory",
                    placeholder="Enter the full path to the input directory",
                    lines=1
                )
                output_dir = gr.Textbox(
                    label="Output Directory",
                    value=DEFAULT_OUTPUT_DIR,
                    info="Results will be saved here",
                    placeholder="Enter path or use default",
                    lines=1
                )
            
            with gr.Row():
                batch_process_btn = gr.Button("ğŸ” Process All Images", scale=2)
                open_folder_btn = gr.Button("ğŸ“‚ Open Output Folder", scale=1)

            with gr.Row():
                batch_progress = gr.Textbox(
                    label="Progress",
                    lines=10,
                    max_lines=15
                )
            
            with gr.Row():
                batch_gallery = gr.Gallery(
                    label="Batch Processing Results",
                    show_label=True,
                    elem_id="gallery",
                    columns=3
                )

            with gr.Row():
                with gr.Accordion("ğŸ“‹ Batch Processing Instructions", open=False):
                    gr.Markdown("""
                    ### How to use batch processing:
                    1. Enter the full path to the input directory containing your images.
                    2. Enter the output directory path or use the default.
                    3. Click 'Process All Images' to start.
                    4. Progress will be shown in the text box below.
                    5. Results for each image will be saved in separate folders and displayed in the gallery.
                    6. A summary CSV and JSON file will be created in the output directory.
                    """)

    # Footer ì¶”ê°€
    gr.Markdown(
        """
        <div class="footer">
            Produced By BDK&copy;
        </div>
        """
    )

    # ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜
    def handle_image_upload(image):
        """ì´ë¯¸ì§€ ì—…ë¡œë“œ ì²˜ë¦¬ ìµœì í™”"""
        if image is None:
            return None, None
        
        try:
            # PIL Imageë¡œ ë³€í™˜
            if not isinstance(image, Image.Image):
                image = Image.fromarray(image)
            
            # ì´ë¯¸ì§€ í¬ê¸° ì œí•œ
            max_size = 1024
            w, h = image.size
            if max(w, h) > max_size:
                scale = max_size / max(w, h)
                new_w, new_h = int(w * scale), int(h * scale)
                image = image.resize((new_w, new_h), Image.LANCZOS)
            
            # ì´ë¯¸ì§€ íˆìŠ¤í† ë¦¬ì— ì €ì¥
            processed_image = image_history.set_original(image)
            return processed_image, "Image uploaded successfully"
        except Exception as e:
            print(f"Error in handle_image_upload: {str(e)}")
            return None, f"Error uploading image: {str(e)}"

    # ì „ì²˜ë¦¬ í•¨ìˆ˜ ìˆ˜ì •
    def apply_preprocessing(image, method):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì ìš©"""
        if image is None:
            return None
        
        try:
            processed = preprocess_image(image, method)
            if processed is not None:
                return image_history.add_state(processed)
            return image
        except Exception as e:
            print(f"Error in apply_preprocessing: {str(e)}")
            return image

    # Reset í•¨ìˆ˜
    def reset_image():
        """ì´ë¯¸ì§€ ì´ˆê¸°í™”"""
        try:
            return image_history.reset()
        except Exception as e:
            print(f"Error in reset_image: {str(e)}")
            return None

    # Redo í•¨ìˆ˜
    def redo_image():
        """ì´ì „ ìƒíƒœë¡œ ë³µì›"""
        try:
            return image_history.redo()
        except Exception as e:
            print(f"Error in redo_image: {str(e)}")
            return None

    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²°
    input_image.upload(
        handle_image_upload,
        inputs=[input_image],
        outputs=[input_image, colony_count_text]
    )

    preprocess_button.click(
        apply_preprocessing,
        inputs=[input_image, preprocess_method],
        outputs=[input_image]
    )

    reset_button.click(
        reset_image,
        inputs=[],
        outputs=[input_image]
    )

    redo_button.click(
        redo_image,
        inputs=[],
        outputs=[input_image]
    )

    # analyze_image í•¨ìˆ˜ ìˆ˜ì •
    def analyze_image(
        input_image, method, input_size=1024, iou_threshold=0.7,
        conf_threshold=0.25, better_quality=True, withContours=True,
        min_area_percentile=1, max_area_percentile=99,
        circularity_threshold=0.8,
        progress=gr.Progress()
    ):
        """ì´ë¯¸ì§€ ë¶„ì„ í•¨ìˆ˜ ìµœì í™”"""
        if input_image is None:
            return None, "No input image provided."

        try:
            progress(0, desc="ì´ˆê¸°í™” ì¤‘...")
            
            # ì´ë¯¸ì§€ í¬ê¸° ìµœì í™”
            if isinstance(input_image, Image.Image):
                w, h = input_image.size
                if max(w, h) > input_size:
                    progress(0.1, desc="ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ì¤‘...")
                    scale = input_size / max(w, h)
                    new_w, new_h = int(w * scale), int(h * scale)
                    input_image = input_image.resize((new_w, new_h), Image.LANCZOS)

            progress(0.2, desc="AI ëª¨ë¸ ì¤€ë¹„ ì¤‘...")
            # FastSAMì„ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©
            method = 'fastsam'
            
            progress(0.3, desc="ì½œë¡œë‹ˆ ë¶„ì„ ì¤‘...")
            processed_image, count_text, new_counter = segment_and_count_colonies(
                input_image=input_image,
                method=method,
                input_size=input_size,
                iou_threshold=iou_threshold,
                conf_threshold=conf_threshold,
                better_quality=better_quality,
                withContours=withContours,
                mask_random_color=True,
                min_area_percentile=min_area_percentile,
                max_area_percentile=max_area_percentile,
                circularity_threshold=circularity_threshold
            )

            progress(0.8, desc="ê²°ê³¼ ì²˜ë¦¬ ì¤‘...")
            if new_counter is not None:
                counter.auto_points = new_counter.auto_points
                counter.auto_detected_count = new_counter.auto_detected_count
                counter.current_image = new_counter.current_image
                counter.original_image = new_counter.original_image
                counter.last_method = "AI Detection"

            progress(1.0, desc="ì™„ë£Œ!")
            return processed_image, count_text
        except Exception as e:
            print(f"Error in analyze_image: {str(e)}")
            return None, f"Error analyzing image: {str(e)}"

    segment_button.click(
        analyze_image,
        inputs=[
            input_image,
            method_select,
            input_size_slider,
            iou_threshold_slider,
            conf_threshold_slider,
            better_quality_checkbox,
            withContours_checkbox,
            min_area_percentile_slider,
            max_area_percentile_slider,
            circularity_threshold_slider
        ],
        outputs=[output_image, colony_count_text],
        show_progress=True
    )

    # ìˆ˜ë™ í¬ì¸íŠ¸ ì¶”ê°€/ì œê±° ì´ë²¤íŠ¸
    output_image.select(
        counter.add_or_remove_point,
        inputs=[output_image],
        outputs=[output_image, colony_count_text]
    )

    remove_point_button.click(
        counter.remove_last_point,
        inputs=[output_image],
        outputs=[output_image, colony_count_text]
    )

    remove_mode_button.click(
        counter.toggle_remove_mode,
        inputs=[],
        outputs=[output_image, remove_mode_text]
    )

    # ë°°ì¹˜ ì²˜ë¦¬ ì´ë²¤íŠ¸
    def handle_batch_process(
        input_dir, output_dir, method, input_size, iou_threshold,
        conf_threshold, better_quality, withContours,
        min_area_percentile, max_area_percentile, circularity_threshold,
        progress=gr.Progress()
    ):
        try:
            progress(0, desc="ì´ˆê¸°í™” ì¤‘...")
            
            if not isinstance(input_dir, str) or not os.path.isdir(input_dir):
                return "ì˜ëª»ëœ ì…ë ¥ ë””ë ‰í† ë¦¬ì…ë‹ˆë‹¤.", []

            if not output_dir or output_dir.strip() == "":
                output_dir = DEFAULT_OUTPUT_DIR

            try:
                os.makedirs(output_dir, exist_ok=True)
            except Exception as e:
                return f"ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± ì˜¤ë¥˜: {str(e)}", []

            valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')
            image_files = [f for f in os.listdir(input_dir) 
                          if f.lower().endswith(valid_extensions)]
            
            if not image_files:
                return "ì…ë ¥ ë””ë ‰í† ë¦¬ì— ìœ íš¨í•œ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.", []

            results = []
            progress_text = (f"ì²˜ë¦¬ ì¤‘ì¸ ë””ë ‰í† ë¦¬: {input_dir}\n"
                            f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_dir}\n\n")
            gallery_items = []
            
            total_files = len(image_files)
            for idx, img_file in enumerate(image_files, 1):
                try:
                    progress((idx-1)/total_files, desc=f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ({idx}/{total_files}): {img_file}")
                    progress_text += f"ì²˜ë¦¬ ì¤‘ì¸ ì´ë¯¸ì§€ {idx}/{total_files}: {img_file}\n"
                    
                    img_path = os.path.join(input_dir, img_file)
                    try:
                        input_image = Image.open(img_path).convert('RGB')
                    except Exception as e:
                        raise Exception(f"Error loading image: {str(e)}")
                    
                    # ì´ë¯¸ì§€ ë¶„ì„
                    result_image, count_text, counter = segment_and_count_colonies(
                        input_image=input_image,
                        method=method,
                        input_size=input_size,
                        iou_threshold=iou_threshold,
                        conf_threshold=conf_threshold,
                        better_quality=better_quality,
                        withContours=withContours,
                        mask_random_color=True,
                        min_area_percentile=min_area_percentile,
                        max_area_percentile=max_area_percentile,
                        circularity_threshold=circularity_threshold
                    )
                    
                    if counter is not None:
                        save_result = counter.save_results(output_dir, img_file)
                    else:
                        save_result = "Failed to process image."

                    results.append({
                        'filename': img_file,
                        'count_text': count_text,
                        'save_result': save_result
                    })
                    
                    if result_image is not None:
                        gallery_items.append({
                            'image': result_image,
                            'caption': f"{img_file}\n{count_text}"
                        })
                    else:
                        gallery_items.append({
                            'image': None,
                            'caption': f"{img_file}\n{count_text}"
                        })

                except Exception as e:
                    error_msg = f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜ {img_file}: {str(e)}\n"
                    print(error_msg)
                    progress_text += error_msg
                    results.append({
                        'filename': img_file,
                        'count_text': f"Error: {str(e)}",
                        'save_result': "Failed to save results"
                    })
                    gallery_items.append({
                        'image': None,
                        'caption': f"{img_file}\nError: {str(e)}"
                    })

            progress(0.9, desc="ê²°ê³¼ ì €ì¥ ì¤‘...")
            summary_path = os.path.join(output_dir, "batch_summary.csv")
            try:
                pd.DataFrame(results).to_csv(summary_path, index=False)
            except Exception as e:
                progress_text += f"Error saving summary CSV: {str(e)}\n"

            # summary.json ìƒì„±
            try:
                create_summary(results, output_dir)
                progress_text += f"\nBatch processing complete. Summary saved to {summary_path} and summary.json"
            except Exception as e:
                progress_text += f"\nError creating summary: {str(e)}"

            progress(1.0, desc="ì™„ë£Œ!")
            return progress_text, gallery_items

        except Exception as e:
            return f"ì¼ê´„ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}", []

    batch_process_btn.click(
        handle_batch_process,
        inputs=[
            input_dir,
            output_dir,
            method_select,
            input_size_slider,
            iou_threshold_slider,
            conf_threshold_slider,
            better_quality_checkbox,
            withContours_checkbox,
            min_area_percentile_slider,
            max_area_percentile_slider,
            circularity_threshold_slider
        ],
        outputs=[batch_progress, batch_gallery],
        show_progress=True
    )

    def open_output_folder(folder_to_open):
        try:
            if os.path.exists(folder_to_open):
                if os.name == 'nt':  # Windows
                    os.startfile(folder_to_open)
                elif os.name == 'posix':  # macOS, Linux
                    if sys.platform == 'darwin':
                        os.system(f'open "{folder_to_open}"')
                    else:
                        os.system(f'xdg-open "{folder_to_open}"')
                return f"Opened output folder: {folder_to_open}"
            else:
                return f"Output folder does not exist: {folder_to_open}"
        except Exception as e:
            return f"Error opening folder: {str(e)}"

    open_folder_btn.click(
        open_output_folder,
        inputs=[output_dir],
        outputs=[batch_progress]
    )

if __name__ == "__main__":
    demo.launch()