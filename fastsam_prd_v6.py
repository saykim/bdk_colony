import os
import sys # sys ëª¨ë“ˆ ì¶”ê°€ (í”„ë¡œê·¸ë¨ ì¢…ë£Œìš©)
from datetime import datetime
from ultralytics import YOLO
import gradio as gr
import torch
from PIL import Image, ImageDraw, ImageFont, ImageFilter, ImageEnhance
import numpy as np
import cv2
import pandas as pd
from pathlib import Path
import json
import time
from typing import List, Dict, Any, Tuple
import webbrowser # ê²°ê³¼ í´ë” ì—´ê¸°ìš©

# --- ìˆ˜ì •: ëª¨ë¸ ê²½ë¡œ ë° ì¡´ì¬ í™•ì¸ ---
model_path = 'weights/FastSAM-x.pt'
if not os.path.exists(model_path):
    print(f"ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼ '{model_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    sys.exit(1) # ëª¨ë¸ íŒŒì¼ ì—†ìœ¼ë©´ ì¢…ë£Œ
# ---------------------------------

# AI ê¸°ë°˜ ë¶„í•  ëª¨ë¸ ë¡œë“œ
model = YOLO(model_path)

# ë””ë°”ì´ìŠ¤ ì„¤ì • (CUDA, MPS, CPU ìˆœìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥)
device = torch.device(
    "cuda" if torch.cuda.is_available() else
    "mps" if torch.backends.mps.is_available() else "cpu"
)
print(f"ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}")

# --- ìˆ˜ì •: ê²°ê³¼ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ ---
OUTPUT_BASE_DIR = "outputs"
os.makedirs(OUTPUT_BASE_DIR, exist_ok=True)
# ---------------------------------

class ImagePreprocessHistory:
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íˆìŠ¤í† ë¦¬ ê´€ë¦¬ í´ë˜ìŠ¤"""
    def __init__(self):
        self.original_image = None
        self.current_image = None
        self.history = []
        self.current_index = -1

    def set_original(self, image):
        """ì›ë³¸ ì´ë¯¸ì§€ ì„¤ì •"""
        if image is None:
            return None

        # PIL Imageë¡œ ë³€í™˜
        if not isinstance(image, Image.Image):
            try:
                image = Image.fromarray(image)
            except Exception as e:
                print(f"Error converting image: {str(e)}")
                return None

        self.original_image = image
        self.current_image = image
        self.history = [image]
        self.current_index = 0
        return image

    def add_state(self, image):
        """ìƒˆë¡œìš´ ì´ë¯¸ì§€ ìƒíƒœ ì¶”ê°€"""
        if image is None:
            return None

        # PIL Imageë¡œ ë³€í™˜
        if not isinstance(image, Image.Image):
            try:
                image = Image.fromarray(image)
            except Exception as e:
                print(f"Error converting image: {str(e)}")
                return None

        # í˜„ì¬ ì¸ë±ìŠ¤ ì´í›„ì˜ íˆìŠ¤í† ë¦¬ëŠ” ì‚­ì œ
        self.history = self.history[:self.current_index + 1]
        self.history.append(image)
        self.current_index = len(self.history) - 1
        self.current_image = image
        return image

    def reset(self):
        """ì›ë³¸ ì´ë¯¸ì§€ë¡œ ë³µì›"""
        if self.original_image is not None:
            self.current_image = self.original_image
            self.current_index = 0
            return self.original_image
        return None

    def undo(self):
        """ì´ì „ ìƒíƒœë¡œ ë³µì›"""
        if self.current_index > 0:
            self.current_index -= 1
            self.current_image = self.history[self.current_index]
            return self.current_image
        # ë” ì´ìƒ ë˜ëŒë¦´ ìˆ˜ ì—†ìœ¼ë©´ í˜„ì¬ ì´ë¯¸ì§€ ë°˜í™˜
        return self.current_image

# ì´ë¯¸ì§€ íˆìŠ¤í† ë¦¬ ê°ì²´ ìƒì„±
image_history = ImagePreprocessHistory()

class ColonyCounter:
    """ì½œë¡œë‹ˆ ì¹´ìš´íŒ… ë° í¬ì¸íŠ¸ ê´€ë¦¬ í´ë˜ìŠ¤"""
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.auto_points = []  # ìë™ ê°ì§€ëœ í¬ì¸íŠ¸ (ì¤‘ì‹¬ì  ì¢Œí‘œ)
        self.manual_points = []  # ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€ëœ í¬ì¸íŠ¸
        self.auto_detected_count = 0  # ìë™ ê°ì§€ëœ ì½œë¡œë‹ˆ ìˆ˜
        self.original_image = None  # ì›ë³¸ ì´ë¯¸ì§€ (ë¦¬ì‚¬ì´ì§• í›„)
        self.current_image = None  # í˜„ì¬ ì´ë¯¸ì§€ (í¬ì¸íŠ¸ê°€ ê·¸ë ¤ì§„ ìƒíƒœ)
        self.colony_masks = []  # ì½œë¡œë‹ˆ ë§ˆìŠ¤í¬ ë¦¬ìŠ¤íŠ¸ (Tensor ë¦¬ìŠ¤íŠ¸)
        self.dish_mask = None  # ë°°ì–‘ì ‘ì‹œ ë§ˆìŠ¤í¬ (Tensor)
        self.base_image = None  # ì²˜ë¦¬ëœ ë² ì´ìŠ¤ ì´ë¯¸ì§€ (Numpy array)
        self.remove_mode = False  # ì œê±° ëª¨ë“œ ì—¬ë¶€
        self.scale_factor = 1.0  # ì´ë¯¸ì§€ ìŠ¤ì¼€ì¼ íŒ©í„°
        self.last_method = None  # ë§ˆì§€ë§‰ìœ¼ë¡œ ì‚¬ìš©í•œ ë¶„ì„ ë°©ë²•

    def reset(self):
        """ì¹´ìš´í„° ì´ˆê¸°í™”"""
        self.auto_points = []
        self.manual_points = []
        self.auto_detected_count = 0
        self.original_image = None
        self.current_image = None
        self.colony_masks = []
        self.dish_mask = None
        self.base_image = None
        self.remove_mode = False
        self.scale_factor = 1.0
        self.last_method = None

    def set_original_image(self, image):
        """ì›ë³¸ ì´ë¯¸ì§€ ì„¤ì • (ë¦¬ì‚¬ì´ì§• í›„)"""
        if image is not None:
            if isinstance(image, Image.Image):
                self.original_image = np.array(image)
            else:
                # ì´ë¯¸ Numpy ë°°ì—´ì¸ ê²½ìš°
                self.original_image = image.copy()
            # base_imageë„ ì´ˆê¸°ì—ëŠ” ì›ë³¸ê³¼ ë™ì¼í•˜ê²Œ ì„¤ì •
            self.base_image = self.original_image.copy()

    def toggle_remove_mode(self):
        """í¸ì§‘ ëª¨ë“œ ì „í™˜ (ì¶”ê°€/ì œê±° ëª¨ë“œ)"""
        self.remove_mode = not self.remove_mode
        # ëª¨ë“œ ë³€ê²½ ì‹œ í˜„ì¬ ìƒíƒœë¡œ ì´ë¯¸ì§€ ë‹¤ì‹œ ê·¸ë¦¼
        img_with_points = self.draw_points()
        # mode_text = "ğŸ”´ REMOVE MODE" if self.remove_mode else "ğŸŸ¢ ADD MODE"
        # return img_with_points, mode_text

        # HTML í˜•ì‹ìœ¼ë¡œ ëª¨ë“œ í‘œì‹œ ë¬¸ìì—´ ë°˜í™˜
        if self.remove_mode:
            mode_indicator_html = "<span style='color: red; font-weight: bold; padding: 10px; display: inline-block;'>ğŸ”´ REMOVE MODE</span>"
        else:
            mode_indicator_html = "<span style='color: green; font-weight: bold; padding: 10px; display: inline-block;'>ğŸŸ¢ ADD MODE</span>"
        return img_with_points, mode_indicator_html

    def set_segmentation_data(self, colony_masks, dish_mask, processed_image_np):
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°ì´í„° ì„¤ì • (ì½œë¡œë‹ˆ ë§ˆìŠ¤í¬, ì ‘ì‹œ ë§ˆìŠ¤í¬, ì²˜ë¦¬ëœ ì´ë¯¸ì§€)"""
        self.colony_masks = colony_masks if colony_masks is not None else []
        self.dish_mask = dish_mask
        # base_imageëŠ” í•­ìƒ Numpy ë°°ì—´ë¡œ ì €ì¥
        self.base_image = processed_image_np.copy() if processed_image_np is not None else None
        # current_imageë„ ì´ˆê¸°ì—ëŠ” base_imageì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
        self.current_image = self.base_image.copy() if self.base_image is not None else None


    def _get_mask_centroid(self, mask_tensor):
        """ë§ˆìŠ¤í¬ í…ì„œì˜ ì¤‘ì‹¬ì ì„ ê³„ì‚°í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜"""
        if mask_tensor is None:
            return None
        mask_np = mask_tensor.cpu().numpy()
        if mask_np.ndim == 3 and mask_np.shape[0] == 1:
            mask_np = mask_np[0]
        mask_bool = mask_np > 0
        if np.any(mask_bool):
            y_indices, x_indices = np.where(mask_bool)
            center_x = int(np.mean(x_indices))
            center_y = int(np.mean(y_indices))
            return (center_x, center_y)
        return None

    def add_or_remove_point(self, image, evt: gr.SelectData):
        """ì´ë¯¸ì§€ë¥¼ í´ë¦­í•˜ì—¬ í¬ì¸íŠ¸ ì¶”ê°€ ë˜ëŠ” ì œê±°"""
        try:
            # current_imageê°€ Noneì´ë©´ ì´ˆê¸°í™” ì‹œë„ (ì˜¤ë¥˜ ë°©ì§€)
            if self.current_image is None and self.base_image is not None:
                 self.current_image = self.base_image.copy()
            elif self.current_image is None and image is not None:
                 self.current_image = np.array(image) # Fallback

            if self.current_image is None:
                 print("ì˜¤ë¥˜: í˜„ì¬ ì´ë¯¸ì§€ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ í¬ì¸íŠ¸ ì¶”ê°€/ì œê±° ë¶ˆê°€")
                 return image, self.get_count_text() # ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜

            x, y = evt.index  # Gradioì—ì„œ í´ë¦­ëœ ì¢Œí‘œ (UI ê¸°ì¤€)

            if self.remove_mode:
                # ì œê±° ëª¨ë“œ: ê°€ì¥ ê°€ê¹Œìš´ í¬ì¸íŠ¸ ì°¾ê¸° (ìë™/ìˆ˜ë™ í†µí•©)
                closest_point_idx = -1
                min_dist_sq = float('inf')
                is_auto = False

                # ìë™ í¬ì¸íŠ¸ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ì  ì°¾ê¸°
                for idx, (px, py) in enumerate(self.auto_points):
                    dist_sq = (x - px)**2 + (y - py)**2
                    if dist_sq < min_dist_sq:
                        min_dist_sq = dist_sq
                        closest_point_idx = idx
                        is_auto = True

                # ìˆ˜ë™ í¬ì¸íŠ¸ì—ì„œ ë” ê°€ê¹Œìš´ ì ì´ ìˆëŠ”ì§€ í™•ì¸
                for idx, (px, py) in enumerate(self.manual_points):
                    dist_sq = (x - px)**2 + (y - py)**2
                    if dist_sq < min_dist_sq:
                        min_dist_sq = dist_sq
                        closest_point_idx = idx
                        is_auto = False

                threshold_sq = 20**2 # ê±°ë¦¬ ì„ê³„ê°’ (ì œê³±ìœ¼ë¡œ ë¹„êµí•˜ì—¬ sqrt ì—°ì‚° ì¤„ì„)
                removed = False

                if min_dist_sq < threshold_sq:
                    if is_auto:
                        # ìë™ í¬ì¸íŠ¸ ë° í•´ë‹¹ ë§ˆìŠ¤í¬ ì œê±° ë¡œì§
                        removed_point = self.auto_points.pop(closest_point_idx)
                        # ì¸ë±ìŠ¤ ëŒ€ì‹  ì¢Œí‘œ ê¸°ë°˜ìœ¼ë¡œ ë§ˆìŠ¤í¬ ì°¾ê¸°
                        mask_to_remove_idx = -1
                        min_centroid_dist_sq = float('inf')
                        for mask_idx, mask_tensor in enumerate(self.colony_masks):
                            centroid = self._get_mask_centroid(mask_tensor)
                            if centroid:
                                centroid_dist_sq = (removed_point[0] - centroid[0])**2 + (removed_point[1] - centroid[1])**2
                                # ë§¤ìš° ê°€ê¹Œìš´ ë§ˆìŠ¤í¬ë¥¼ ì°¾ìŒ (ë™ì¼ ì¢Œí‘œë¡œ ê°€ì •)
                                if centroid_dist_sq < 1.0: # ì¤‘ì‹¬ì ì´ ê±°ì˜ ì¼ì¹˜í•˜ëŠ” ë§ˆìŠ¤í¬
                                     mask_to_remove_idx = mask_idx
                                     break # ì°¾ìœ¼ë©´ ì¤‘ë‹¨
                                # elif centroid_dist_sq < min_centroid_dist_sq: # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ê°€ì¥ ê°€ê¹Œìš´ ê²ƒë„ ê¸°ë¡
                                #      min_centroid_dist_sq = centroid_dist_sq

                        if mask_to_remove_idx != -1:
                             self.colony_masks.pop(mask_to_remove_idx)
                             print(f"ìë™ í¬ì¸íŠ¸ {closest_point_idx}ì™€ ì—°ê´€ëœ ë§ˆìŠ¤í¬ {mask_to_remove_idx} ì œê±°ë¨.")
                        else:
                             print(f"ê²½ê³ : ìë™ í¬ì¸íŠ¸ {closest_point_idx} ({removed_point}) ì— í•´ë‹¹í•˜ëŠ” ë§ˆìŠ¤í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

                        self.auto_detected_count = len(self.auto_points)
                        removed = True
                    else:
                        # ìˆ˜ë™ í¬ì¸íŠ¸ ì œê±° (ì¸ë±ìŠ¤ ì£¼ì˜: is_autoê°€ Falseì¼ ë•Œ closest_point_idxëŠ” manual_points ë‚´ì˜ ì¸ë±ìŠ¤)
                        actual_manual_idx = closest_point_idx # closest_point_idxê°€ manual_points ë‚´ ì¸ë±ìŠ¤ì„
                        if actual_manual_idx < len(self.manual_points):
                            self.manual_points.pop(actual_manual_idx)
                            removed = True
                        else:
                            print(f"ì˜¤ë¥˜: ì˜ëª»ëœ ìˆ˜ë™ í¬ì¸íŠ¸ ì¸ë±ìŠ¤ {actual_manual_idx}")


                if removed:
                    # ë§ˆìŠ¤í¬ê°€ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ìˆ˜ë™ í¬ì¸íŠ¸ê°€ ì œê±°ë˜ì—ˆìœ¼ë¯€ë¡œ base_imageë¥¼ ë‹¤ì‹œ ìƒì„±í•˜ê³  current_image ì—…ë°ì´íŠ¸
                    self.redraw_segmentation_and_base() # ìë™ ì œê±° ì‹œ ë§ˆìŠ¤í¬ ê¸°ë°˜ ì´ë¯¸ì§€ ì¬ìƒì„±
                else:
                    print("ì œê±°í•  í¬ì¸íŠ¸ê°€ ì¶©ë¶„íˆ ê°€ê¹Œì´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

            else:
                # ì¶”ê°€ ëª¨ë“œ: ìƒˆë¡œìš´ ìˆ˜ë™ í¬ì¸íŠ¸ ì¶”ê°€
                self.manual_points.append((x, y))
                # ì¶”ê°€ ì‹œì—ëŠ” ì„¸ê·¸ë©˜í…Œì´ì…˜ ë³€ê²½ ì—†ìœ¼ë¯€ë¡œ redraw í•„ìš” ì—†ìŒ

            # ìµœì¢…ì ìœ¼ë¡œ í¬ì¸íŠ¸ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸
            img_with_points = self.draw_points()
            self.current_image = img_with_points # current_image ì—…ë°ì´íŠ¸
            return img_with_points, self.get_count_text()

        except Exception as e:
            print(f"í¬ì¸íŠ¸ ì¶”ê°€/ì œê±° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            traceback.print_exc() # ìƒì„¸ ì˜¤ë¥˜ ì¶œë ¥
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ í˜„ì¬ ì´ë¯¸ì§€ ë˜ëŠ” ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
            return self.current_image if self.current_image is not None else image, self.get_count_text()

    def redraw_segmentation_and_base(self):
        """
        ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ base_imageë¥¼ ë‹¤ì‹œ ê·¸ë¦¬ê³ ,
        current_imageë„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. (ìë™ í¬ì¸íŠ¸ ì œê±° ì‹œ í˜¸ì¶œ)
        """
        if self.original_image is None:
            print("ì˜¤ë¥˜: ì›ë³¸ ì´ë¯¸ì§€ê°€ ì—†ì–´ ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ë‹¤ì‹œ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬ (ë¦¬ì‚¬ì´ì§•ëœ ì´ë¯¸ì§€ ê¸°ì¤€)
        image_np = self.original_image.copy()

        # í˜„ì¬ ë‚¨ì•„ìˆëŠ” ì½œë¡œë‹ˆ ë§ˆìŠ¤í¬ ì²˜ë¦¬
        for mask_tensor in self.colony_masks:
            mask_np = mask_tensor.cpu().numpy()
            if mask_np.ndim == 3 and mask_np.shape[0] == 1:
                mask_np = mask_np[0]
            mask_bool = mask_np > 0

            if mask_bool.ndim == 2 and np.any(mask_bool):
                # ëœë¤ ìƒ‰ìƒ ì ìš©
                color = np.random.randint(100, 200, (3,)).tolist()
                image_np[mask_bool] = color

                # ìœ¤ê³½ì„  ê·¸ë¦¬ê¸°
                contours, _ = cv2.findContours(mask_bool.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(image_np, contours, -1, (255, 0, 0), 2) # íŒŒë€ìƒ‰ ìœ¤ê³½ì„ 

        # ë°°ì–‘ì ‘ì‹œ ë§ˆìŠ¤í¬ ì²˜ë¦¬
        if self.dish_mask is not None:
            dish_mask_np = self.dish_mask.cpu().numpy()
            if dish_mask_np.ndim == 3 and dish_mask_np.shape[0] == 1:
                dish_mask_np = dish_mask_np[0]
            dish_mask_bool = dish_mask_np > 0

            if dish_mask_bool.ndim == 2 and np.any(dish_mask_bool):
                contours, _ = cv2.findContours(dish_mask_bool.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(image_np, contours, -1, (0, 0, 255), 3) # ë¹¨ê°„ìƒ‰ ìœ¤ê³½ì„ 

        # ì—…ë°ì´íŠ¸ëœ ì´ë¯¸ì§€ë¥¼ base_imageë¡œ ì„¤ì •
        self.base_image = image_np
        # current_imageë„ ì¦‰ì‹œ ì—…ë°ì´íŠ¸ (í¬ì¸íŠ¸ëŠ” draw_pointsì—ì„œ ê·¸ë ¤ì§)
        self.current_image = self.base_image.copy()


    def remove_last_point(self, image):
        """ë§ˆì§€ë§‰ìœ¼ë¡œ ì¶”ê°€ëœ *ìˆ˜ë™* í¬ì¸íŠ¸ ì œê±°"""
        try:
            if len(self.manual_points) > 0:
                self.manual_points.pop()
                # í¬ì¸íŠ¸ ì œê±° í›„ ì´ë¯¸ì§€ ë‹¤ì‹œ ê·¸ë¦¼
                updated_image = self.draw_points()
                self.current_image = updated_image # current_image ì—…ë°ì´íŠ¸
                return updated_image, self.get_count_text()
            else:
                # ì œê±°í•  ìˆ˜ë™ í¬ì¸íŠ¸ê°€ ì—†ìœ¼ë©´ ë³€í™” ì—†ìŒ
                return image, self.get_count_text()
        except Exception as e:
            print(f"ë§ˆì§€ë§‰ ìˆ˜ë™ í¬ì¸íŠ¸ ì œê±° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return image, self.get_count_text()

    def get_count_text(self):
        """í˜„ì¬ ì¹´ìš´íŠ¸ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        auto_count = self.auto_detected_count
        manual_count = len(self.manual_points)
        total_count = auto_count + manual_count

        # ë°©ë²• ì •ë³´ ì œê±° (FastSAM í‘œì‹œ ì•ˆí•¨)
        text = f"ì´ ì½œë¡œë‹ˆ ìˆ˜: {total_count}\n(ìë™: {auto_count}, ìˆ˜ë™: {manual_count})"
        return text

    def draw_points(self):
        """í˜„ì¬ ì´ë¯¸ì§€ì— í¬ì¸íŠ¸ë¥¼ ê·¸ë ¤ì„œ ë°˜í™˜"""
        try:
            # base_imageë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê·¸ë¦¼
            if self.base_image is None:
                print("ê²½ê³ : base_imageê°€ ì—†ì–´ í¬ì¸íŠ¸ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                # current_imageë¼ë„ ìˆìœ¼ë©´ ë°˜í™˜, ì•„ë‹ˆë©´ None
                return self.current_image if self.current_image is not None else None
            img_with_points = self.base_image.copy()
            overlay = np.zeros_like(img_with_points, dtype=np.uint8) # ì˜¤ë²„ë ˆì´ íƒ€ì… ëª…ì‹œ

            # ì‚¬ìš©ì ì„¤ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤
            square_size = 40
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.7
            font_thickness = 1
            outline_thickness = 3
            AUTO_TEXT_COLOR = (255, 255, 255)
            AUTO_OUTLINE_COLOR = (0, 0, 0)
            MANUAL_RECT_COLOR = (0, 0, 255)
            MANUAL_BORDER_COLOR = (0, 0, 0)
            MANUAL_TEXT_COLOR = (255, 255, 0)
            OVERLAY_OPACITY = 0.6
            REMOVE_MODE_OPACITY = 0.3

            # 1. ìë™ ê°ì§€ëœ CFU ë²ˆí˜¸ í‘œì‹œ
            for idx, (x, y) in enumerate(self.auto_points, 1):
                text = str(idx)
                (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)
                text_x = int(x - text_width / 2)
                text_y = int(y + text_height / 2) # Y ì¢Œí‘œ ì¤‘ì•™ ì •ë ¬ ê°œì„ 

                # ì™¸ê³½ì„ 
                for dx in [-1, 0, 1]:
                    for dy in [-1, 0, 1]:
                        if dx != 0 or dy != 0:
                             cv2.putText(img_with_points, text, (text_x + dx, text_y + dy),
                                         font, font_scale, AUTO_OUTLINE_COLOR, outline_thickness)
                # í…ìŠ¤íŠ¸
                cv2.putText(img_with_points, text, (text_x, text_y),
                          font, font_scale, AUTO_TEXT_COLOR, font_thickness)

            # 2. ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€ëœ í¬ì¸íŠ¸ í‘œì‹œ
            manual_font_scale = 1.0
            manual_font_thickness = 2
            for idx, (x, y) in enumerate(self.manual_points, len(self.auto_points) + 1):
                pt1 = (int(x - square_size / 2), int(y - square_size / 2))
                pt2 = (int(x + square_size / 2), int(y + square_size / 2))

                # ì˜¤ë²„ë ˆì´ì— ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
                cv2.rectangle(overlay, pt1, pt2, MANUAL_RECT_COLOR, -1)
                cv2.rectangle(overlay, pt1, pt2, MANUAL_BORDER_COLOR, 2)

                text = str(idx)
                (text_width, text_height), _ = cv2.getTextSize(text, font, manual_font_scale, manual_font_thickness)
                text_x = int(x - text_width / 2)
                text_y = int(y + text_height / 2) # Y ì¢Œí‘œ ì¤‘ì•™ ì •ë ¬ ê°œì„ 

                # ì™¸ê³½ì„  (ì˜¤ë²„ë ˆì´ì— ê·¸ë¦¼)
                for dx in [-1, 0, 1]:
                    for dy in [-1, 0, 1]:
                         if dx != 0 or dy != 0:
                              cv2.putText(overlay, text, (text_x + dx, text_y + dy),
                                          font, manual_font_scale, AUTO_OUTLINE_COLOR, outline_thickness + 1) # ì™¸ê³½ì„  ë” ë‘ê»ê²Œ
                # í…ìŠ¤íŠ¸ (ì˜¤ë²„ë ˆì´ì— ê·¸ë¦¼)
                cv2.putText(overlay, text, (text_x, text_y),
                          font, manual_font_scale, MANUAL_TEXT_COLOR, manual_font_thickness)

            # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ë¥¼ ì›ë³¸ê³¼ ë¸”ë Œë”©
            cv2.addWeighted(overlay, OVERLAY_OPACITY, img_with_points, 1.0, 0, img_with_points)

            # 3. ì œê±° ëª¨ë“œ í‘œì‹œ
            mode_overlay = img_with_points.copy() # ëª¨ë“œ í‘œì‹œìš© ë³µì‚¬ë³¸
            if self.remove_mode:
                cv2.rectangle(mode_overlay, (0, 0), (img_with_points.shape[1], 50), (0, 0, 255), -1) # ë¹¨ê°„ìƒ‰ ë°°ê²½
                cv2.addWeighted(mode_overlay, REMOVE_MODE_OPACITY, img_with_points, 1.0 - REMOVE_MODE_OPACITY, 0, img_with_points)
                cv2.putText(img_with_points, "REMOVE MODE", (10, 35),
                          cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)
            else:
                cv2.rectangle(mode_overlay, (0, 0), (img_with_points.shape[1], 50), (0, 255, 0), -1) # ì´ˆë¡ìƒ‰ ë°°ê²½
                cv2.addWeighted(mode_overlay, REMOVE_MODE_OPACITY, img_with_points, 1.0 - REMOVE_MODE_OPACITY, 0, img_with_points)
                cv2.putText(img_with_points, "ADD MODE", (10, 35),
                          cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)

            # 4. ì „ì²´ ì¹´ìš´íŠ¸ í‘œì‹œ (ì™¼ìª½ í•˜ë‹¨)
            # count_text_str = self.get_count_text().split('\\n')[0] # ì²« ì¤„ë§Œ í‘œì‹œ (ê¸°ì¡´ ì½”ë“œ ì£¼ì„ ì²˜ë¦¬)
            total_count = len(self.auto_points) + len(self.manual_points)
            count_text_str = f"Total count : {total_count}" # ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ í˜•ì‹
            count_font_scale = 1.0
            count_font_thickness = 2
            (text_width, text_height), baseline = cv2.getTextSize(count_text_str, font, count_font_scale, count_font_thickness)
            margin = 15
            # í…ìŠ¤íŠ¸ ë°°ê²½ ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
            cv2.rectangle(img_with_points,
                          (margin, img_with_points.shape[0] - margin - text_height - baseline),
                          (margin + text_width + margin, img_with_points.shape[0] - margin + baseline),
                          (0, 0, 0), -1) # ê²€ì€ìƒ‰ ë°°ê²½
            # ì¹´ìš´íŠ¸ í…ìŠ¤íŠ¸ í‘œì‹œ
            cv2.putText(img_with_points, count_text_str, # ë³€ê²½ëœ í…ìŠ¤íŠ¸ ì‚¬ìš©
                      (margin + margin // 2, img_with_points.shape[0] - margin - baseline // 2),
                      font, count_font_scale, (255, 255, 255), count_font_thickness) # í°ìƒ‰ í…ìŠ¤íŠ¸

            return img_with_points
        except Exception as e:
            print(f"ì´ë¯¸ì§€ì— í¬ì¸íŠ¸ë¥¼ ê·¸ë¦¬ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ì•ˆì „í•˜ê²Œ í˜„ì¬ ì´ë¯¸ì§€ ë˜ëŠ” base ì´ë¯¸ì§€ ë°˜í™˜
            return self.current_image if self.current_image is not None else self.base_image

def preprocess_image(
    input_image,
    to_grayscale=False,
    binary=False,
    binary_threshold=128,
    edge_detection=False,
    sharpen=False,
    sharpen_amount=1.0
):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    try:
        if not isinstance(input_image, Image.Image):
             print("ì „ì²˜ë¦¬ ì…ë ¥ì€ PIL Imageì—¬ì•¼ í•©ë‹ˆë‹¤.")
             return input_image # ì›ë³¸ ë°˜í™˜

        image = input_image.copy()

        if to_grayscale:
            image = image.convert('L').convert('RGB')
        if binary:
            image_np = np.array(image.convert('L')) # í‘ë°±ìœ¼ë¡œ ë³€í™˜ í›„ ì²˜ë¦¬
            _, binary_img = cv2.threshold(image_np, binary_threshold, 255, cv2.THRESH_BINARY)
            image = Image.fromarray(binary_img).convert('RGB')
        if edge_detection:
            image_np = np.array(image.convert('L'))
            edges = cv2.Canny(image_np, 100, 200)
            image = Image.fromarray(edges).convert('RGB')
        if sharpen:
            image = image.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3))
            if sharpen_amount != 1.0:
                enhancer = ImageEnhance.Sharpness(image)
                image = enhancer.enhance(sharpen_amount)
        return image
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return input_image # ì˜¤ë¥˜ ì‹œ ì›ë³¸ ë°˜í™˜

def process_image(colony_annotations, dish_annotation, image, device, scale, better_quality, mask_random_color, bbox, use_retina, withContours):
    """ë§ˆìŠ¤í¬ ì£¼ì„ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ì—¬ CFUì˜ ìœ¤ê³½ì„ ì„ ê·¸ë¦½ë‹ˆë‹¤."""
    try:
        image_np = np.array(image).copy()

        # CFU ë§ˆìŠ¤í¬ ì²˜ë¦¬
        for ann in colony_annotations:
            ann_cpu = ann.cpu().numpy()
            if ann_cpu.ndim == 3 and ann_cpu.shape[0] == 1:
                ann_cpu = ann_cpu[0]

            mask = ann_cpu > 0
            if mask.ndim == 2 and np.any(mask):
                if mask_random_color:
                    color = np.random.randint(100, 200, (3,)).tolist()
                    image_np[mask] = color
                else:
                    image_np[mask] = (0, 255, 0) # ê¸°ë³¸ ë…¹ìƒ‰

                if withContours:
                    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    cv2.drawContours(image_np, contours, -1, (255, 0, 0), 2) # íŒŒë€ìƒ‰ ìœ¤ê³½ì„ 

        # ë°°ì–‘ì ‘ì‹œ ë§ˆìŠ¤í¬ ì²˜ë¦¬ (ìœ¤ê³½ì„ ë§Œ ê·¸ë¦¬ê¸°)
        if dish_annotation is not None:
            dish_mask = dish_annotation.cpu().numpy()
            if dish_mask.ndim == 3 and dish_mask.shape[0] == 1:
                dish_mask = dish_mask[0]
            dish_mask = dish_mask > 0
            if dish_mask.ndim == 2 and np.any(dish_mask):
                if withContours:
                    contours, _ = cv2.findContours(dish_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    cv2.drawContours(image_np, contours, -1, (0, 0, 255), 3) # ë¹¨ê°„ìƒ‰ ìœ¤ê³½ì„ 

        processed_image = Image.fromarray(image_np)
        return processed_image
    except Exception as e:
        print(f"Error in process_image: {str(e)}")
        return image # ì˜¤ë¥˜ ì‹œ ì›ë³¸ PIL ì´ë¯¸ì§€ ë°˜í™˜

def segment_and_count_colonies(
    input_image, # PIL Image ì…ë ¥
    input_size=1024,
    iou_threshold=0.7,
    conf_threshold=0.25,
    better_quality=False,
    withContours=True,
    mask_random_color=True, # ê¸°ë³¸ê°’ True ì‚¬ìš©
    # min_area_percentile=1, # ê¸°ì¡´ íŒŒë¼ë¯¸í„° ì œê±°
    # max_area_percentile=99, # ê¸°ì¡´ íŒŒë¼ë¯¸í„° ì œê±°
    circularity_threshold=0.8,
    # --- ë©´ì  í•„í„°ë§ íŒŒë¼ë¯¸í„° ì¶”ê°€ ---
    enable_area_filter=False,
    min_area_percentile=1,
    max_area_percentile=99,
    # -------------------------------
    progress=gr.Progress()
):
    """ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  CFUë¥¼ ê°ì§€í•˜ì—¬ ì¹´ìš´íŒ…í•©ë‹ˆë‹¤."""
    global counter # ì „ì—­ counter ê°ì²´ ì‚¬ìš©

    try:
        if input_image is None:
            return None, "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."

        # ë¶„ì„ ì‹œì‘ ì‹œ ì „ì—­ counter ë¦¬ì…‹
        counter.reset()

        progress(0.1, desc="ì´ë¯¸ì§€ ì¤€ë¹„ ì¤‘...")
        image_to_use = input_image
        original_width, original_height = image_to_use.size
        w, h = image_to_use.size
        scale = input_size / max(w, h)
        new_w, new_h = int(w * scale), int(h * scale)

        # PIL 9.0.0 ì´ìƒ/ë¯¸ë§Œ í˜¸í™˜ì„±
        try: resampling_filter = Image.Resampling.LANCZOS
        except AttributeError: resampling_filter = Image.LANCZOS
        input_resized_pil = image_to_use.resize((new_w, new_h), resampling_filter)
        input_resized_np = np.array(input_resized_pil) # ëª¨ë¸ ì…ë ¥ìš© Numpy ë°°ì—´

        # counterì— ì›ë³¸(ë¦¬ì‚¬ì´ì¦ˆëœ) ì´ë¯¸ì§€ì™€ ìŠ¤ì¼€ì¼ ì €ì¥
        counter.set_original_image(input_resized_np) # Numpy ë°°ì—´ë¡œ ì €ì¥
        counter.scale_factor = scale
        counter.last_method = "FastSAM" # ë¶„ì„ ë°©ë²• ê¸°ë¡

        progress(0.3, desc="AI ë¶„ì„ ì¤‘...")
        results = model.predict(
            input_resized_np, # Numpy ë°°ì—´ ì…ë ¥
            device=device,
            conf=conf_threshold,
            iou=iou_threshold,
            imgsz=input_size,
            retina_masks=True
        )

        annotations = getattr(results[0].masks, 'data', None)
        if annotations is None or len(annotations) == 0:
            counter.current_image = input_resized_np # ë¶„ì„ ì‹¤íŒ¨ ì‹œ ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ í‘œì‹œ
            return input_resized_np, "CFUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        progress(0.6, desc="ë§ˆìŠ¤í¬ ì²˜ë¦¬ ë° í•„í„°ë§ ì¤‘...")
        areas = [np.sum(ann.cpu().numpy() > 0) for ann in annotations]
        if not areas: # ëª¨ë“  ë§ˆìŠ¤í¬ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ë°©ì§€
             counter.current_image = input_resized_np
             return input_resized_np, "ìœ íš¨í•œ ë§ˆìŠ¤í¬ ì˜ì—­ì´ ì—†ìŠµë‹ˆë‹¤."

        dish_idx = np.argmax(areas)
        dish_annotation = annotations[dish_idx]
        colony_annotations_all = [ann for idx, ann in enumerate(annotations) if idx != dish_idx]

        # ë©´ì  ë° ì›í˜•ë„ í•„í„°ë§
        valid_colony_annotations = []
        valid_auto_points = []
        colony_areas = [areas[i] for i in range(len(areas)) if i != dish_idx]

        if colony_areas: # ì½œë¡œë‹ˆ í›„ë³´ê°€ ìˆì„ ê²½ìš°ì—ë§Œ í•„í„°ë§
             # ë°±ë¶„ìœ„ìˆ˜ ëŒ€ì‹  ì‹¤ì œ ë©´ì  ì„ê³„ê°’ ì‚¬ìš© ê³ ë ¤ (ì˜µì…˜)
             # min_area = np.percentile(colony_areas, min_area_percentile)
             # max_area = np.percentile(colony_areas, max_area_percentile)
             # min_area = 3 # ìµœì†Œ ë©´ì  ì„ê³„ê°’ì„ 3ìœ¼ë¡œ ë³€ê²½ # í•˜ë“œì½”ë”©ëœ ê°’ ì‚­ì œ
             # max_area = input_size * input_size * 0.1 # í•˜ë“œì½”ë”©ëœ ê°’ ì‚­ì œ

             # --- ë©´ì  í•„í„°ë§ ë¡œì§ ìˆ˜ì • ---
             if enable_area_filter:
                 min_area = np.percentile(colony_areas, min_area_percentile)
                 max_area = np.percentile(colony_areas, max_area_percentile)
                 print(f"ë©´ì  í•„í„°ë§ í™œì„±í™”: ìµœì†Œ {min_area:.2f}, ìµœëŒ€ {max_area:.2f} (ë°±ë¶„ìœ„ {min_area_percentile}-{max_area_percentile} %)")
             # ---------------------------

             for ann, area in zip(colony_annotations_all, colony_areas):
                 # ë©´ì  í•„í„°ë§ (í•„í„°ë§ í™œì„±í™” ì‹œ ì ìš©)
                 if enable_area_filter and (area < min_area or area > max_area):
                      continue

                 ann_cpu = ann.cpu().numpy()
                 if ann_cpu.ndim == 3 and ann_cpu.shape[0] == 1: ann_cpu = ann_cpu[0]
                 mask = ann_cpu > 0

                 # ì›í˜•ë„ ê³„ì‚°
                 contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                 if contours:
                     perimeter = cv2.arcLength(contours[0], True)
                     circularity = 4 * np.pi * (area / (perimeter ** 2)) if perimeter > 0 else 0
                     if circularity >= circularity_threshold:
                         valid_colony_annotations.append(ann)
                         # ì¤‘ì‹¬ì  ê³„ì‚° ë° ì¶”ê°€
                         centroid = counter._get_mask_centroid(ann)
                         if centroid:
                             valid_auto_points.append(centroid)

        progress(0.8, desc="ê²°ê³¼ ì‹œê°í™” ì¤‘...")
        processed_image_pil = process_image(
            colony_annotations=valid_colony_annotations,
            dish_annotation=dish_annotation,
            image=input_resized_pil, # PIL ì´ë¯¸ì§€ ì „ë‹¬
            device=device,
            scale=1.0, # process_image ë‚´ë¶€ ìŠ¤ì¼€ì¼ì€ 1.0
            better_quality=better_quality,
            mask_random_color=mask_random_color, # í•¨ìˆ˜ ì¸ìë¡œ ì „ë‹¬ëœ ê°’ ì‚¬ìš©
            bbox=None,
            use_retina=False,
            withContours=withContours
        )
        processed_image_np = np.array(processed_image_pil) # Numpy ë°°ì—´ë¡œ ë³€í™˜

        # counter ê°ì²´ ì—…ë°ì´íŠ¸
        counter.set_segmentation_data(valid_colony_annotations, dish_annotation, processed_image_np)
        counter.auto_points = valid_auto_points
        counter.auto_detected_count = len(valid_auto_points)

        progress(1.0, desc="ì™„ë£Œ!")
        img_with_points_np = counter.draw_points() # ìµœì¢… í¬ì¸íŠ¸ í¬í•¨ ì´ë¯¸ì§€ (Numpy)

        # UIì—ëŠ” ë¦¬ì‚¬ì´ì¦ˆëœ ê²°ê³¼ ì´ë¯¸ì§€ ë°˜í™˜
        return img_with_points_np, counter.get_count_text()

    except Exception as e:
        error_msg = f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc() # ìƒì„¸ ì˜¤ë¥˜ ì¶œë ¥
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜ (ë¦¬ì‚¬ì´ì¦ˆëœ)
        if 'input_resized_np' in locals():
             return input_resized_np, error_msg
        elif input_image is not None:
             return np.array(input_image), error_msg
        return None, error_msg

def save_results(original_input_pil, processed_output_np):
    """
    ì›ë³¸ ì´ë¯¸ì§€(PIL)ì™€ ì²˜ë¦¬ëœ ì´ë¯¸ì§€(Numpy)ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    """
    global counter # ì „ì—­ counter ì‚¬ìš©
    try:
        if processed_output_np is None:
             return "ì €ì¥í•  ì²˜ë¦¬ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ê³ ìœ í•œ ì‹ë³„ì ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # ì €ì¥ ê²½ë¡œ í‘œì¤€í™”
        save_dir = os.path.join(OUTPUT_BASE_DIR, f"result_{timestamp}")
        os.makedirs(save_dir, exist_ok=True)

        # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ (ì—…ë¡œë“œëœ ì›ë³¸ PIL ì´ë¯¸ì§€ ì‚¬ìš©)
        original_path = os.path.join(save_dir, "original.png")
        if original_input_pil is not None and isinstance(original_input_pil, Image.Image):
             original_input_pil.save(original_path)
        else:
             print("ê²½ê³ : ì›ë³¸ PIL ì´ë¯¸ì§€ê°€ ì—†ì–´ ì €ì¥í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì €ì¥ (Numpy ë°°ì—´ -> PIL -> ì €ì¥)
        result_path = os.path.join(save_dir, "result.png")
        processed_image_pil = Image.fromarray(processed_output_np)
        processed_image_pil.save(result_path)

        # ê²°ê³¼ í…ìŠ¤íŠ¸ ì €ì¥
        count_text = counter.get_count_text()
        result_txt_path = os.path.join(save_dir, "count_results.txt")
        with open(result_txt_path, 'w', encoding='utf-8') as f:
            f.write(f"ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(count_text)
            # ì¶”ê°€ ì •ë³´ (ì˜µì…˜)
            f.write(f"\n\n--- ìƒì„¸ ì •ë³´ ---\n")
            f.write(f"ì‚¬ìš©ëœ ë¶„ì„ ë°©ë²•: {counter.last_method}\n")
            f.write(f"ìë™ ê°ì§€ëœ ì½œë¡œë‹ˆ: {counter.auto_detected_count}\n")
            f.write(f"ìˆ˜ë™ ì¶”ê°€ëœ ì½œë¡œë‹ˆ: {len(counter.manual_points)}\n")

        # ìš”ì•½ JSON ì €ì¥
        summary = {
            'datetime': datetime.now().isoformat(),
            'auto_count': counter.auto_detected_count,
            'manual_count': len(counter.manual_points),
            'total_count': counter.auto_detected_count + len(counter.manual_points),
            'analysis_method': counter.last_method
        }
        summary_json_path = os.path.join(save_dir, "summary.json")
        with open(summary_json_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=4, ensure_ascii=False)

        return f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ:\n{save_dir}"
    except Exception as e:
        error_msg = f"ì´ë¯¸ì§€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        print(error_msg)
        return error_msg

def handle_batch_upload(
    files: List[Any], # Gradio File ì»´í¬ë„ŒíŠ¸ëŠ” íŒŒì¼ ê°ì²´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    input_size: int,
    iou_threshold: float,
    conf_threshold: float,
    better_quality: bool,
    withContours: bool,
    # min_area_percentile: int,
    # max_area_percentile: int,
    # ---
    enable_area_filter: bool,
    min_area_percentile: int,
    max_area_percentile: int,
    # ---
    circularity_threshold: float,
    progress=gr.Progress()
) -> Tuple[str, List[Tuple[np.ndarray, str]]]: # ê²°ê³¼ ë©”ì‹œì§€ì™€ ê°¤ëŸ¬ë¦¬ ë°ì´í„° ë°˜í™˜
    """ë°°ì¹˜ ëª¨ë“œì—ì„œ ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    global counter # ì „ì—­ counter ì‚¬ìš©

    try:
        if not files:
            return "ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.", []

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ í‘œì¤€í™”
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = os.path.join(OUTPUT_BASE_DIR, f"batch_{timestamp}")
        os.makedirs(output_dir, exist_ok=True)

        results_summary = [] # CSV/JSON ìš”ì•½ìš©
        gallery_data = [] # Gradio ê°¤ëŸ¬ë¦¬ í‘œì‹œìš©

        total_files = len(files)
        progress(0, desc="ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘...")

        for idx, file_obj in enumerate(files):
            current_progress = (idx + 1) / total_files
            # file_obj.nameì´ Noneì¼ ìˆ˜ ìˆëŠ” ê²½ìš° ë°©ì§€
            img_filename = os.path.basename(file_obj.name) if file_obj and file_obj.name else f"unknown_file_{idx+1}"
            progress(current_progress, desc=f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ({idx + 1}/{total_files}): {img_filename}")

            # ë°°ì¹˜ ì²˜ë¦¬ ì‹œ ìƒíƒœ ì´ˆê¸°í™”
            counter.reset() # ê° ì´ë¯¸ì§€ ì²˜ë¦¬ ì „ counter ìƒíƒœ ì´ˆê¸°í™”

            try:
                # íŒŒì¼ ê°ì²´ ìœ íš¨ì„± ê²€ì‚¬
                if not file_obj or not hasattr(file_obj, 'name') or not file_obj.name:
                     raise ValueError("ì˜ëª»ëœ íŒŒì¼ ê°ì²´ì…ë‹ˆë‹¤.")

                # ì´ë¯¸ì§€ ë¡œë“œ (íŒŒì¼ ê°ì²´ì—ì„œ ì§ì ‘ ë¡œë“œ)
                image_pil = Image.open(file_obj.name).convert("RGB")

                # ì´ë¯¸ì§€ ë¶„ì„ (segment_and_count_colonies í•¨ìˆ˜ ì¬ì‚¬ìš©)
                processed_image_np, count_text = segment_and_count_colonies(
                    image_pil, # ì›ë³¸ PIL ì´ë¯¸ì§€ ì „ë‹¬
                    input_size=input_size,
                    iou_threshold=iou_threshold,
                    conf_threshold=conf_threshold,
                    better_quality=better_quality,
                    withContours=withContours,
                    mask_random_color=True, # ë°°ì¹˜ì—ì„œëŠ” ëœë¤ ìƒ‰ìƒ ê³ ì •
                    # min_area_percentile=min_area_percentile,
                    # max_area_percentile=max_area_percentile,
                    # ---
                    enable_area_filter=enable_area_filter,
                    min_area_percentile=min_area_percentile,
                    max_area_percentile=max_area_percentile,
                    # ---
                    circularity_threshold=circularity_threshold
                )

                # ê°œë³„ ì´ë¯¸ì§€ ê²°ê³¼ ì €ì¥
                img_name_base = Path(img_filename).stem
                img_save_dir = os.path.join(output_dir, f"{img_name_base}_result")
                os.makedirs(img_save_dir, exist_ok=True)

                # ì›ë³¸ ì €ì¥
                original_path = os.path.join(img_save_dir, "original.png")
                image_pil.save(original_path)
                # ê²°ê³¼ ì €ì¥
                result_path = os.path.join(img_save_dir, "result.png")
                if processed_image_np is not None:
                    Image.fromarray(processed_image_np).save(result_path)
                else:
                    print(f"ê²½ê³ : {img_filename}ì˜ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ê°€ ì—†ì–´ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                # í…ìŠ¤íŠ¸ ì €ì¥
                result_txt_path = os.path.join(img_save_dir, "count_results.txt")
                with open(result_txt_path, 'w', encoding='utf-8') as f:
                     f.write(f"íŒŒì¼: {img_filename}\n")
                     f.write(f"ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                     f.write(count_text)

                # ìš”ì•½ ì •ë³´ ì¶”ê°€
                results_summary.append({
                    'filename': img_filename,
                    'total_count': counter.auto_detected_count + len(counter.manual_points),
                    'auto_count': counter.auto_detected_count,
                    'manual_count': len(counter.manual_points),
                    'status': 'success',
                    'output_path': img_save_dir
                })
                # ê°¤ëŸ¬ë¦¬ ë°ì´í„° ì¶”ê°€
                if processed_image_np is not None:
                    gallery_data.append((processed_image_np, f"{img_filename}\n{count_text}"))
                else: # ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì´ë¯¸ì§€ì™€ í•¨ê»˜ í‘œì‹œ
                    gallery_data.append((np.array(image_pil), f"{img_filename}\në¶„ì„ ì‹¤íŒ¨"))


            except Exception as e:
                error_msg = f"ì˜¤ë¥˜ ì²˜ë¦¬ ì¤‘ {img_filename}: {str(e)}"
                print(error_msg)
                results_summary.append({
                    'filename': img_filename,
                    'total_count': 0, 'auto_count': 0, 'manual_count': 0,
                    'status': 'error', 'error_message': error_msg,
                    'output_path': None
                })
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê°¤ëŸ¬ë¦¬ì— ì›ë³¸ ì´ë¯¸ì§€ì™€ ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ (ì˜µì…˜)
                try:
                     error_img_np = np.array(Image.open(file_obj.name).convert("RGB"))
                     cv2.putText(error_img_np, "ERROR", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 3, (0,0,255), 5)
                     gallery_data.append((error_img_np, f"{img_filename}\nì²˜ë¦¬ ì˜¤ë¥˜"))
                except:
                     gallery_data.append((None, f"{img_filename}\nì²˜ë¦¬ ì˜¤ë¥˜")) # ì´ë¯¸ì§€ ë¡œë“œë„ ì‹¤íŒ¨ ì‹œ

        # ì „ì²´ ë°°ì¹˜ ìš”ì•½ CSV/JSON ì €ì¥
        summary_df = pd.DataFrame(results_summary)
        csv_path = os.path.join(output_dir, "batch_summary.csv")
        summary_df.to_csv(csv_path, index=False, encoding='utf-8-sig')

        summary_json_path = os.path.join(output_dir, "batch_summary.json")
        summary_final = {
             'batch_start_time': timestamp,
             'total_images': total_files,
             'success_count': sum(1 for r in results_summary if r['status'] == 'success'),
             'error_count': sum(1 for r in results_summary if r['status'] == 'error'),
             'results': results_summary
        }
        with open(summary_json_path, 'w', encoding='utf-8') as f:
            json.dump(summary_final, f, indent=4, ensure_ascii=False)

        # ì²˜ë¦¬ ì™„ë£Œ ë©”ì‹œì§€ ìƒì„±
        success_count = summary_final['success_count']
        fail_count = summary_final['error_count']
        result_msg = f"ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: ì´ {total_files}ê°œ ì¤‘ {success_count}ê°œ ì„±ê³µ, {fail_count}ê°œ ì‹¤íŒ¨.\n"
        result_msg += f"ê²°ê³¼ ì €ì¥ í´ë”: {output_dir}\n"
        result_msg += f"ìš”ì•½ íŒŒì¼: batch_summary.csv, batch_summary.json"

        return result_msg, gallery_data

    except Exception as e:
        error_msg = f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc() # ìƒì„¸ ì˜¤ë¥˜ ì¶œë ¥
        return error_msg, []


# --- UI ì½”ë“œ ---

# CSS ìŠ¤íƒ€ì¼ë§ ê°œì„ 
css = """
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;500;700&display=swap');

body {
    background-color: #f8fafc;
    font-family: 'Noto Sans KR', sans-serif;
    color: #334155;
    line-height: 1.4;
}
.container { max-width: 1280px; margin: 0 auto; padding: 20px; }
.header { background: linear-gradient(135deg, #2563EB, #1e40af); padding: 30px; border-radius: 12px; color: #ffffff; margin-bottom: 20px; box-shadow: 0 4px 10px rgba(37, 99, 235, 0.2); display: flex; justify-content: space-between; align-items: center; }
.header-content { text-align: left; }
.header-date { text-align: right; color: rgba(255, 255, 255, 0.9); font-size: 14px; }
.header h1 { font-size: 32px; font-weight: 700; margin: 0; background: linear-gradient(90deg, #ffffff, #e2e8f0); -webkit-background-clip: text; -webkit-text-fill-color: transparent; text-shadow: 0 2px 4px rgba(0, 0, 0, 0.1); }
.header h3 { font-size: 16px; font-weight: 500; margin: 10px 0 0; color: #e2e8f0; }
.section-title { font-size: 18px; font-weight: 600; color: #1e40af; margin-bottom: 15px; display: flex; align-items: center; gap: 8px; }
.button-primary { background-color: #2563EB !important; color: #ffffff !important; border: none !important; padding: 12px 24px !important; border-radius: 8px !important; font-size: 14px !important; font-weight: 500 !important; cursor: pointer !important; transition: all 0.3s ease !important; box-shadow: 0 2px 4px rgba(37, 99, 235, 0.2) !important; }
.button-primary:hover { background-color: #1d4ed8 !important; box-shadow: 0 4px 6px rgba(37, 99, 235, 0.3) !important; transform: translateY(-1px) !important; }
.button-secondary { background-color: #475569 !important; color: #ffffff !important; border: none !important; padding: 12px 24px !important; border-radius: 8px !important; font-size: 14px !important; font-weight: 500 !important; cursor: pointer !important; transition: all 0.3s ease !important; box-shadow: 0 2px 4px rgba(71, 85, 105, 0.2) !important; }
.button-secondary:hover { background-color: #334155 !important; box-shadow: 0 4px 6px rgba(71, 85, 105, 0.3) !important; transform: translateY(-1px) !important; }
.accordion-header { background-color: #f1f5f9 !important; color: #1e40af !important; padding: 15px !important; border-radius: 8px !important; font-weight: 500 !important; border: 1px solid #e2e8f0 !important; margin: 10px 0 !important; transition: all 0.3s ease !important; }
.accordion-header:hover { border-color: #2563EB !important; box-shadow: 0 2px 4px rgba(37, 99, 235, 0.1) !important; }
.input-image, .output-image { border: 2px solid #e2e8f0 !important; border-radius: 12px !important; padding: 10px !important; background: #ffffff !important; transition: all 0.3s ease !important; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05) !important; margin: 10px 0 !important; width: 100% !important; height: 500px !important; object-fit: contain !important; display: flex !important; justify-content: center !important; align-items: center !important; } /* íŒ¨ë”©/ë§ˆì§„ ì¡°ì •, ê³ ì • ë†’ì´ */
.input-image img, .output-image img { max-width: 100% !important; max-height: 100% !important; object-fit: contain !important; }
.input-image:hover, .output-image:hover { border-color: #2563EB !important; box-shadow: 0 4px 6px rgba(37, 99, 235, 0.1) !important; }
.result-text { background: #ffffff !important; border-left: 5px solid #10b981 !important; padding: 15px !important; border-radius: 8px !important; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05) !important; font-size: 14px !important; line-height: 1.6 !important; margin: 15px 0 !important; color: #334155 !important; }
.gradio-container { background-color: #ffffff !important; border-radius: 12px !important; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05) !important; padding: 20px !important; margin: 20px auto !important; }
.gradio-row { gap: 20px !important; }
.gradio-column { background: #ffffff !important; padding: 20px !important; border-radius: 12px !important; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05) !important; }
.slider-container { background: #f1f5f9 !important; padding: 15px !important; border-radius: 8px !important; margin: 10px 0 !important; }
.slider { accent-color: #2563EB !important; }
.checkbox-container { background: #f1f5f9 !important; padding: 12px !important; border-radius: 8px !important; margin: 8px 0 !important; }
.checkbox { accent-color: #10b981 !important; }
.instruction-box { background-color: #f1f5f9 !important; border: 1px solid #e2e8f0 !important; border-radius: 12px !important; padding: 20px !important; margin-top: 30px !important; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05) !important; }
.instruction-box h3 { color: #1e40af !important; font-size: 18px !important; font-weight: 600 !important; margin-bottom: 15px !important; }
.instruction-box p { color: #334155 !important; font-size: 14px !important; line-height: 1.6 !important; margin-bottom: 10px !important; }
.tabs { border-bottom: 1px solid #e2e8f0 !important; margin-bottom: 20px !important; }
.tab-nav { padding: 12px 24px !important; color: #475569 !important; font-weight: 500 !important; font-size: 14px !important; transition: all 0.3s ease !important; }
.tab-nav:hover { color: #2563EB !important; }
.tab-nav.selected { color: #2563EB !important; border-bottom: 2px solid #2563EB !important; background-color: rgba(37, 99, 235, 0.05) !important; }
.priority-high { color: #ef4444 !important; font-weight: 500 !important; }
.priority-medium { color: #f59e0b !important; font-weight: 500 !important; }
.priority-low { color: #10b981 !important; font-weight: 500 !important; }
.card { background: #ffffff !important; border-radius: 12px !important; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05) !important; padding: 20px !important; margin: 15px 0 !important; border: 1px solid #e2e8f0 !important; transition: all 0.3s ease !important; }
.card:hover { box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1) !important; transform: translateY(-2px) !important; }
::-webkit-scrollbar { width: 8px; height: 8px; }
::-webkit-scrollbar-track { background: #f1f5f9; border-radius: 4px; }
::-webkit-scrollbar-thumb { background: #cbd5e1; border-radius: 4px; }
::-webkit-scrollbar-thumb:hover { background: #94a3b8; }
.batch-gallery { min-height: 300px; border: 1px solid #e2e8f0; border-radius: 8px; padding: 10px; background-color: #f8fafc;} /* ë°°ì¹˜ ê°¤ëŸ¬ë¦¬ ìŠ¤íƒ€ì¼ */
"""

# ì „ì—­ counter ê°ì²´
counter = ColonyCounter()

# Gradio ì¸í„°í˜ì´ìŠ¤ ì„¤ì •
with gr.Blocks(theme=gr.themes.Soft(), css=css) as demo:
    # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ìˆ¨ê²¨ì§„ ìƒíƒœ ë³€ìˆ˜
    original_input_image_state = gr.State(None)

    gr.Markdown(
        """
        <div class="header">
            <div class="header-content">
                <h1>ğŸ”¬ BDK CFU ì¹´ìš´í„° (v5 ìˆ˜ì •)</h1>
                <h3>AI ìë™ CFU ê°ì§€ ë° ìˆ˜ë™ ë³´ì •</h3>
            </div>
            <div class="header-date">
                <span>ìµœì¢… ì—…ë°ì´íŠ¸: 2025ë…„ 4ì›”</span>
            </div>
        </div>
        """
    )

    with gr.Tabs():
        with gr.Tab("ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬"):
            with gr.Row():
                # --- ì…ë ¥ ì»¬ëŸ¼ ---
                with gr.Column(scale=1): # scale ì¡°ì • (1:1 ë¹„ìœ¨)
                    gr.Markdown("<div class='section-title'>ğŸ“ ì´ë¯¸ì§€ ì—…ë¡œë“œ & ì „ì²˜ë¦¬</div>")
                    input_image = gr.Image(
                        type="pil",
                        label="ì…ë ¥ ì´ë¯¸ì§€",
                        elem_classes=["input-image"],
                        show_label=False,
                        height=500, # ê³ ì • ë†’ì´
                    )

                    with gr.Accordion("ğŸ› ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì„¤ì •", open=False, elem_classes="accordion-header"):
                        to_grayscale = gr.Checkbox(label="í‘ë°± ë³€í™˜", value=False)
                        binary = gr.Checkbox(label="ë°”ì´ë„ˆë¦¬ ë³€í™˜", value=False)
                        binary_threshold = gr.Slider(0, 255, 128, step=1, label="ë°”ì´ë„ˆë¦¬ ì„ê³„ê°’")
                        edge_detection = gr.Checkbox(label="ì—ì§€ ê²€ì¶œ", value=False)
                        sharpen = gr.Checkbox(label="ìƒ¤í”ˆ", value=False)
                        sharpen_amount = gr.Slider(0.5, 5.0, 1.0, step=0.1, label="ìƒ¤í”ˆ ê°•ë„")
                        with gr.Row():
                            preprocess_button = gr.Button("ğŸ”„ ì „ì²˜ë¦¬ ì ìš©", elem_classes="button-secondary")
                            reset_button = gr.Button("â†º ì›ë³¸ ë³µì›", elem_classes="button-secondary")
                            undo_button = gr.Button("â†¶ ì‹¤í–‰ ì·¨ì†Œ", elem_classes="button-secondary")

                    gr.Markdown("<div class='section-title' style='margin-top: 20px;'>âš™ï¸ ë¶„ì„ ì„¤ì •</div>")
                    with gr.Accordion("ë¶„ì„ íŒŒë¼ë¯¸í„°", open=True, elem_classes="accordion-header"): # ê¸°ë³¸ ì—´ë¦¼
                        input_size_slider = gr.Slider(512, 2048, 1024, step=64, label="ì…ë ¥ í¬ê¸°", info="í´ìˆ˜ë¡ ì •í™•, ëŠë¦¼")
                        iou_threshold_slider = gr.Slider(0.1, 0.9, 0.7, step=0.1, label="IOU ì„ê³„ê°’", info="ë†’ì„ìˆ˜ë¡ ì—„ê²©")
                        conf_threshold_slider = gr.Slider(0.1, 0.9, 0.25, step=0.05, label="ì‹ ë¢°ë„ ì„ê³„ê°’", info="ë†’ì„ìˆ˜ë¡ í™•ì‹¤")
                        circularity_threshold_slider = gr.Slider(0.0, 1.0, 0.8, step=0.01, label="ì›í˜•ë„ ì„ê³„ê°’", info="1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì›í˜•")
                        withContours_checkbox = gr.Checkbox(label="ìœ¤ê³½ì„  í‘œì‹œ", value=True, info="ì½œë¡œë‹ˆ ê²½ê³„ í‘œì‹œ")
                        better_quality_checkbox = gr.Checkbox(label="í–¥ìƒëœ í’ˆì§ˆ (ë¯¸ì‚¬ìš©)", value=True, visible=False)
                        # --- ë©´ì  í•„í„°ë§ UI ì¶”ê°€ ---
                        enable_area_filter_checkbox = gr.Checkbox(label="ë©´ì  í•„í„°ë§ ì‚¬ìš©", value=False, info="ì²´í¬ ì‹œ ì•„ë˜ ë°±ë¶„ìœ„ ê¸°ì¤€ìœ¼ë¡œ ì½œë¡œë‹ˆ í•„í„°ë§")
                        min_area_percentile_slider = gr.Slider(0, 10, 1, step=1, label="ìµœì†Œ ë©´ì  (ë°±ë¶„ìœ„ %)", visible=True) # visible=Trueë¡œ ë³€ê²½
                        max_area_percentile_slider = gr.Slider(90, 100, 99, step=1, label="ìµœëŒ€ ë©´ì  (ë°±ë¶„ìœ„ %)", visible=True) # visible=Trueë¡œ ë³€ê²½

                    segment_button = gr.Button(
                        "ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰",
                        variant="primary",
                        elem_classes="button-primary",
                    )

                # --- ì¶œë ¥ ë° ìˆ˜ì • ì»¬ëŸ¼ ---
                with gr.Column(scale=1): # scale ì¡°ì • (1:1 ë¹„ìœ¨)
                    gr.Markdown("<div class='section-title'>ğŸ“Š ë¶„ì„ ê²°ê³¼ & ìˆ˜ë™ ìˆ˜ì •</div>")
                    output_image = gr.Image(
                        type="numpy",
                        label="ê²°ê³¼ ì´ë¯¸ì§€",
                        interactive=True, # í´ë¦­ ì´ë²¤íŠ¸ í™œì„±í™”
                        elem_classes=["output-image"],
                        show_label=False,
                        height=500, # ê³ ì • ë†’ì´
                    )
                    colony_count_text = gr.Textbox(
                        label="ì¹´ìš´íŠ¸ ê²°ê³¼",
                        lines=3, # 3ì¤„ë¡œ ëŠ˜ë¦¼
                        elem_classes="result-text",
                        interactive=False # ì§ì ‘ ìˆ˜ì • ë¶ˆê°€
                    )

                    # --- í¸ì§‘ ëª¨ë“œ UI ê°œì„  ---
                    # with gr.Row(): # ê¸°ì¡´ ì½”ë“œ ì£¼ì„ ì²˜ë¦¬
                    #     remove_mode_button = gr.Button("ğŸ”„ í¸ì§‘ ëª¨ë“œ (ì¶”ê°€/ì œê±°)", elem_classes="button-secondary")
                    #     remove_mode_text = gr.Textbox(label="í˜„ì¬ ëª¨ë“œ", value="ğŸŸ¢ ADD MODE", lines=1, interactive=False)
                    with gr.Row(variant="panel"): # ë²„íŠ¼ê³¼ ëª¨ë“œ í‘œì‹œë¥¼ í•œ ì¤„ì— ë°°ì¹˜
                        remove_mode_button = gr.Button("ğŸ”„ í¸ì§‘ ëª¨ë“œ ì „í™˜", elem_classes="button-secondary") # scale ì œê±°
                        remove_mode_indicator = gr.Markdown(value="<span style='color: green; font-weight: bold; padding: 10px; display: inline-block;'>ğŸŸ¢ ADD MODE</span>", elem_classes="mode-indicator") # scale ì œê±°

                    with gr.Row():
                        remove_point_button = gr.Button("â†©ï¸ ë§ˆì§€ë§‰ ìˆ˜ë™ í¬ì¸íŠ¸ ì·¨ì†Œ", elem_classes="button-secondary")

                    save_button = gr.Button("ğŸ’¾ ê²°ê³¼ ì €ì¥", elem_classes="button-primary")
                    save_output = gr.Textbox(label="ì €ì¥ ê²°ê³¼", lines=2, interactive=False, elem_classes="result-text")

            # --- ë‹¨ì¼ ì²˜ë¦¬ ê°€ì´ë“œ ---
            with gr.Row(elem_classes="instruction-box"):
                 gr.Markdown( # ê°€ì´ë“œ ë‚´ìš© ì—…ë°ì´íŠ¸
                      """
                      <h3>ğŸ“ ë¹ ë¥¸ ì‚¬ìš© ê°€ì´ë“œ (ë‹¨ì¼ ì´ë¯¸ì§€)</h3>
                      <p><span class="priority-high">1. ì´ë¯¸ì§€ ì—…ë¡œë“œ:</span> ë¶„ì„í•  ì½œë¡œë‹ˆ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.</p>
                      <p><span class="priority-medium">2. (ì„ íƒ) ì „ì²˜ë¦¬:</span> í•„ìš”ì‹œ 'ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì„¤ì •'ì—ì„œ ì˜µì…˜ì„ ì„ íƒí•˜ê³  'ì „ì²˜ë¦¬ ì ìš©'ì„ ëˆ„ë¥´ì„¸ìš”. 'ì›ë³¸ ë³µì›' ë˜ëŠ” 'ì‹¤í–‰ ì·¨ì†Œ'ë¡œ ë˜ëŒë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
                      <p><span class="priority-medium">3. (ì„ íƒ) ë¶„ì„ ì„¤ì •:</span> 'ë¶„ì„ íŒŒë¼ë¯¸í„°'ì—ì„œ AI íƒì§€ ê´€ë ¨ ì„¤ì •ì„ ì¡°ì •í•˜ì„¸ìš”.</p>
                      <p><span class="priority-high">4. ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰:</span> 'ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.</p>
                      <p><span class="priority-medium">5. ìˆ˜ë™ ìˆ˜ì •:</span></p>
                      <ul>
                          <li>ê²°ê³¼ ì´ë¯¸ì§€ ìœ„ì—ì„œ í´ë¦­í•˜ì—¬ í¬ì¸íŠ¸ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì œê±°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
                          <li>'í¸ì§‘ ëª¨ë“œ' ë²„íŠ¼ìœ¼ë¡œ ì¶”ê°€(ğŸŸ¢ ADD)/ì œê±°(ğŸ”´ REMOVE) ëª¨ë“œë¥¼ ì „í™˜í•˜ì„¸ìš”.</li>
                          <li>'ë§ˆì§€ë§‰ ìˆ˜ë™ í¬ì¸íŠ¸ ì·¨ì†Œ' ë²„íŠ¼ìœ¼ë¡œ ê°€ì¥ ìµœê·¼ì— **ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€**í•œ í¬ì¸íŠ¸ë¥¼ ì œê±°í•©ë‹ˆë‹¤.</li>
                      </ul>
                       <p><span class="priority-low">6. ê²°ê³¼ ì €ì¥:</span> 'ê²°ê³¼ ì €ì¥' ë²„íŠ¼ì„ ëˆŒëŸ¬ ì›ë³¸, ê²°ê³¼ ì´ë¯¸ì§€, ì¹´ìš´íŠ¸ ì •ë³´ë¥¼ ì €ì¥í•˜ì„¸ìš”.</p>
                      """
                 )

            # --- ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²° ---

            # ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹œ ì›ë³¸ ì´ë¯¸ì§€ ìƒíƒœ ì €ì¥
            input_image.upload(
                 lambda img: (img, img), # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ input_imageì™€ ìƒíƒœ ë³€ìˆ˜ ëª¨ë‘ì— ì„¤ì •
                 inputs=[input_image],
                 outputs=[input_image, original_input_image_state]
            ).then(
                 lambda: counter.reset(), # ìƒˆ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹œ counter ë¦¬ì…‹
                 inputs=None,
                 outputs=None
            ).then(
                 lambda img: image_history.set_original(img), # ì´ë¯¸ì§€ íˆìŠ¤í† ë¦¬ì—ë„ ì„¤ì •
                 inputs=[input_image],
                 outputs=[input_image] # íˆìŠ¤í† ë¦¬ ì„¤ì • í›„ input_image ì—…ë°ì´íŠ¸ (í¬ê¸° ì¡°ì • ë“± ë°˜ì˜)
            ).then(
                 lambda: "ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ë¶„ì„ì„ ì§„í–‰í•˜ì„¸ìš”.", # ì´ˆê¸° ë©”ì‹œì§€
                 outputs=[colony_count_text]
            )

            # ì „ì²˜ë¦¬ ë²„íŠ¼
            preprocess_button.click(
                lambda img, gs, b, bt, edge, sh, sa: image_history.add_state(preprocess_image(img, to_grayscale=gs, binary=b, binary_threshold=bt, edge_detection=edge, sharpen=sh, sharpen_amount=sa)),
                inputs=[input_image, to_grayscale, binary, binary_threshold, edge_detection, sharpen, sharpen_amount],
                outputs=[input_image] # ì „ì²˜ë¦¬ í›„ input_image ì—…ë°ì´íŠ¸
            )
            reset_button.click(
                lambda: image_history.reset(), # ì›ë³¸ìœ¼ë¡œ ë¦¬ì…‹
                inputs=[],
                outputs=[input_image]
            )
            undo_button.click(
                lambda: image_history.undo(), # ì´ì „ ë‹¨ê³„ë¡œ
                inputs=[],
                outputs=[input_image]
            )

            # ë¶„ì„ ë²„íŠ¼
            segment_button.click(
                segment_and_count_colonies,
                inputs=[
                    input_image, # í˜„ì¬ í‘œì‹œëœ (ì „ì²˜ë¦¬ëœ) ì´ë¯¸ì§€ ì‚¬ìš©
                    input_size_slider,
                    iou_threshold_slider,
                    conf_threshold_slider,
                    better_quality_checkbox,
                    withContours_checkbox,
                    # --- SyntaxError ìˆ˜ì •: í•´ë‹¹ ë¼ì¸ ì œê±° ---
                    # mask_random_color=gr.Checkbox(value=True, visible=False),
                    # --------------------------------------
                    # min_area_percentile_slider, # ê¸°ì¡´ ìŠ¬ë¼ì´ë” ì œê±°
                    # max_area_percentile_slider, # ê¸°ì¡´ ìŠ¬ë¼ì´ë” ì œê±°
                    circularity_threshold_slider,
                    # --- ë©´ì  í•„í„°ë§ UI ì…ë ¥ ì¶”ê°€ ---
                    enable_area_filter_checkbox,
                    min_area_percentile_slider,
                    max_area_percentile_slider,
                    # -------------------------------
                ],
                outputs=[output_image, colony_count_text]
            )

            # ìˆ˜ë™ í¬ì¸íŠ¸ ì¶”ê°€/ì œê±° ì´ë²¤íŠ¸
            output_image.select(
                counter.add_or_remove_point,
                inputs=[output_image], # í˜„ì¬ ì¶œë ¥ ì´ë¯¸ì§€ ì „ë‹¬ (ì¢Œí‘œê³„ ê¸°ì¤€)
                outputs=[output_image, colony_count_text] # ì—…ë°ì´íŠ¸ëœ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ë°˜í™˜
            )

            # ë§ˆì§€ë§‰ ìˆ˜ë™ í¬ì¸íŠ¸ ì œê±° ë²„íŠ¼
            remove_point_button.click(
                counter.remove_last_point,
                inputs=[output_image],
                outputs=[output_image, colony_count_text]
            )

            # í¸ì§‘ ëª¨ë“œ ì „í™˜ ë²„íŠ¼
            remove_mode_button.click(
                counter.toggle_remove_mode,
                inputs=[], # ì…ë ¥ í•„ìš” ì—†ìŒ
                outputs=[output_image, remove_mode_indicator] # ì´ë¯¸ì§€ì™€ ëª¨ë“œ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            )

            # ê²°ê³¼ ì €ì¥ ë²„íŠ¼
            save_button.click(
                save_results,
                inputs=[original_input_image_state, output_image], # ì›ë³¸(State)ê³¼ ê²°ê³¼(Image) ì „ë‹¬
                outputs=[save_output]
            )

        # --- ë°°ì¹˜ ì²˜ë¦¬ íƒ­ ---
        with gr.Tab("ë°°ì¹˜ ì²˜ë¦¬"):
            with gr.Row():
                # --- ë°°ì¹˜ ì„¤ì • ì»¬ëŸ¼ ---
                with gr.Column(scale=1):
                    gr.Markdown("<div class='section-title'>ğŸ“ ë°°ì¹˜ ì´ë¯¸ì§€ ì—…ë¡œë“œ & ì„¤ì •</div>")
                    batch_files = gr.File(
                        label="ì´ë¯¸ì§€ íŒŒì¼ ì„ íƒ (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)",
                        file_count="multiple",
                        file_types=["image"],
                        elem_classes=["card"]
                    )

                    with gr.Accordion("âš™ï¸ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •", open=True, elem_classes="accordion-header"):
                        batch_input_size = gr.Slider(512, 2048, 1024, step=64, label="ì…ë ¥ í¬ê¸°")
                        batch_iou_threshold = gr.Slider(0.1, 0.9, 0.7, step=0.1, label="IOU ì„ê³„ê°’")
                        batch_conf_threshold = gr.Slider(0.1, 0.9, 0.25, step=0.05, label="ì‹ ë¢°ë„ ì„ê³„ê°’")
                        batch_circularity = gr.Slider(0.0, 1.0, 0.8, step=0.01, label="ì›í˜•ë„ ì„ê³„ê°’")
                        batch_withContours = gr.Checkbox(label="ìœ¤ê³½ì„  í‘œì‹œ", value=True)
                        batch_better_quality = gr.Checkbox(label="í–¥ìƒëœ í’ˆì§ˆ (ë¯¸ì‚¬ìš©)", value=True, visible=False)
                        # --- ë°°ì¹˜ ë©´ì  í•„í„°ë§ UI ì¶”ê°€ ---
                        batch_enable_area_filter = gr.Checkbox(label="ë©´ì  í•„í„°ë§ ì‚¬ìš©", value=False)
                        batch_min_area = gr.Slider(0, 10, 1, step=1, label="ìµœì†Œ ë©´ì  (ë°±ë¶„ìœ„ %)", visible=True) # visible=Trueë¡œ ë³€ê²½
                        batch_max_area = gr.Slider(90, 100, 99, step=1, label="ìµœëŒ€ ë©´ì  (ë°±ë¶„ìœ„ %)", visible=True) # visible=Trueë¡œ ë³€ê²½

                    batch_process_button = gr.Button(
                        "ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘",
                        variant="primary",
                        elem_classes="button-primary"
                    )

                # --- ë°°ì¹˜ ê²°ê³¼ ì»¬ëŸ¼ ---
                with gr.Column(scale=1):
                    gr.Markdown("<div class='section-title'>ğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ & ê°¤ëŸ¬ë¦¬</div>")
                    batch_summary = gr.Textbox(
                        label="ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½",
                        lines=8, # ì¤„ ìˆ˜ ì¡°ì •
                        elem_classes="result-text",
                        interactive=False
                    )
                    gr.Textbox(label="ê²°ê³¼ ì €ì¥ ê¸°ë³¸ í´ë”", value=OUTPUT_BASE_DIR, interactive=False)
                    open_output_button = gr.Button("ğŸ“‚ ê¸°ë³¸ ê²°ê³¼ í´ë” ì—´ê¸°", elem_classes="button-secondary")
                    batch_gallery = gr.Gallery(
                         label="ì²˜ë¦¬ ê²°ê³¼ ì´ë¯¸ì§€", show_label=False, elem_classes=["batch-gallery"], columns=4, height=400
                    )

            # --- ë°°ì¹˜ ì²˜ë¦¬ ê°€ì´ë“œ ---
            with gr.Row(elem_classes="instruction-box"):
                 gr.Markdown( # ê°€ì´ë“œ ë‚´ìš© ì—…ë°ì´íŠ¸
                      """
                      <h3>ğŸ“ ë°°ì¹˜ ì²˜ë¦¬ ê°€ì´ë“œ</h3>
                      <p><span class="priority-high">1. ì´ë¯¸ì§€ íŒŒì¼ ì„ íƒ:</span> ë¶„ì„í•  ì—¬ëŸ¬ ì´ë¯¸ì§€ íŒŒì¼ì„ í•œ ë²ˆì— ì„ íƒí•˜ì„¸ìš”.</p>
                      <p><span class="priority-medium">2. (ì„ íƒ) ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •:</span> í•„ìš”ì— ë”°ë¼ ë¶„ì„ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì„¸ìš”.</p>
                      <p><span class="priority-high">3. ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘:</span> 'ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.</p>
                      <p><span class="priority-medium">4. ê²°ê³¼ í™•ì¸:</span></p>
                      <ul>
                          <li>ì²˜ë¦¬ ì§„í–‰ ìƒí™©ê³¼ ìµœì¢… ìš”ì•½ ë©”ì‹œì§€ê°€ 'ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½' ì°½ì— í‘œì‹œë©ë‹ˆë‹¤.</li>
                          <li>ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°ê°€ ì•„ë˜ ê°¤ëŸ¬ë¦¬ì— ë‚˜íƒ€ë‚©ë‹ˆë‹¤.</li>
                          <li>ëª¨ë“  ê²°ê³¼(ê°œë³„ ì´ë¯¸ì§€ í´ë”, ìš”ì•½ CSV/JSON)ëŠ” 'ê²°ê³¼ ì €ì¥ ê¸°ë³¸ í´ë”' ì•„ë˜ì˜ `batch_[íƒ€ì„ìŠ¤íƒ¬í”„]` í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.</li>
                          <li>'ê¸°ë³¸ ê²°ê³¼ í´ë” ì—´ê¸°' ë²„íŠ¼ìœ¼ë¡œ í•´ë‹¹ í´ë”ë¥¼ ë°”ë¡œ ì—´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
                      </ul>
                      """
                 )

            # --- ë°°ì¹˜ ì²˜ë¦¬ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ---
            batch_process_button.click(
                handle_batch_upload,
                inputs=[
                    batch_files,
                    batch_input_size,
                    batch_iou_threshold,
                    batch_conf_threshold,
                    batch_better_quality,
                    batch_withContours,
                    # batch_min_area, # ê¸°ì¡´ ìŠ¬ë¼ì´ë” ì œê±°
                    # batch_max_area, # ê¸°ì¡´ ìŠ¬ë¼ì´ë” ì œê±°
                    batch_circularity,
                    # --- ë°°ì¹˜ ë©´ì  í•„í„°ë§ UI ì…ë ¥ ì¶”ê°€ ---
                    batch_enable_area_filter,
                    batch_min_area,
                    batch_max_area,
                    # -------------------------------
                ],
                outputs=[batch_summary, batch_gallery] # ìš”ì•½ í…ìŠ¤íŠ¸ì™€ ê°¤ëŸ¬ë¦¬ ë°ì´í„° ë°˜í™˜
            )

            # ê²°ê³¼ í´ë” ì—´ê¸° ë¡œì§
            def open_folder(folder_path):
                try:
                    abs_folder_path = os.path.abspath(folder_path)
                    if not os.path.isdir(abs_folder_path):
                         return f"ì˜¤ë¥˜: í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {abs_folder_path}"

                    if sys.platform == "win32":
                        os.startfile(abs_folder_path)
                    elif sys.platform == "darwin": # macOS
                        webbrowser.open(f"file://{abs_folder_path}")
                    else: # Linux ë“±
                        webbrowser.open(f"file://{abs_folder_path}")
                    return f"í´ë” ì—´ê¸° ì‹œë„: {abs_folder_path}"
                except Exception as e:
                    return f"í´ë” ì—´ê¸° ì˜¤ë¥˜: {str(e)}"

            open_output_button.click(
                 lambda: open_folder(OUTPUT_BASE_DIR), # ê¸°ë³¸ ê²°ê³¼ í´ë” ì—´ê¸°
                 inputs=[],
                 outputs=[batch_summary] # ìƒíƒœ ë©”ì‹œì§€ë¥¼ ìš”ì•½ ì°½ì— í‘œì‹œ
            )

if __name__ == "__main__":
    # ê³µìœ  ì˜µì…˜ ë“± ì¶”ê°€ ê°€ëŠ¥
    demo.launch(share=False)

