from ultralytics import YOLO
import gradio as gr
import torch
from PIL import Image, ImageDraw, ImageFont
import numpy as np
import cv2
import os
import json
from datetime import datetime
from pathlib import Path
import shutil
import time
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('colony_counter.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('ColonyCounter')

# FastSAM ëª¨ë¸ ë¡œë“œ
model = YOLO('./weights/FastSAM-x.pt')

# ì¥ì¹˜ ì„¤ì •
device = torch.device(
    "cuda" if torch.cuda.is_available() else
    "mps" if torch.backends.mps.is_available() else "cpu"
)

class ImageManager:
    def __init__(self, base_path="./data"):
        self.base_path = Path(base_path)
        self._create_directories()
        
    def _create_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        directories = [
            self.base_path / "images" / "original",
            self.base_path / "images" / "analyzed",
            self.base_path / "images" / "overlay",
            self.base_path / "metadata"
        ]
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            
    def generate_filename(self, suffix):
        """íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ íŒŒì¼ëª… ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"{timestamp}_{suffix}"
        
    def save_images(self, original_image, analyzed_image, overlay_image=None):
        """ì´ë¯¸ì§€ ì„¸íŠ¸ ì €ì¥"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥
            original_path = self.base_path / "images" / "original" / f"{timestamp}_original.jpg"
            Image.fromarray(original_image).save(original_path)
            
            # ë¶„ì„ëœ ì´ë¯¸ì§€ ì €ì¥
            analyzed_path = self.base_path / "images" / "analyzed" / f"{timestamp}_analyzed.jpg"
            Image.fromarray(analyzed_image).save(analyzed_path)
            
            # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ì €ì¥
            if overlay_image is not None:
                overlay_path = self.base_path / "images" / "overlay" / f"{timestamp}_overlay.jpg"
                Image.fromarray(overlay_image).save(overlay_path)
                
            logger.info(f"Images saved successfully with timestamp: {timestamp}")
            return timestamp
        except Exception as e:
            logger.error(f"Error saving images: {str(e)}")
            raise
            
    def save_metadata(self, timestamp, metadata):
        """ë©”íƒ€ë°ì´í„° ì €ì¥"""
        try:
            metadata_path = self.base_path / "metadata" / f"{timestamp}_metadata.json"
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=4, ensure_ascii=False)
            logger.info(f"Metadata saved successfully: {timestamp}")
        except Exception as e:
            logger.error(f"Error saving metadata: {str(e)}")
            raise

def fast_process(colony_annotations, dish_annotation, image, device, scale, better_quality, mask_random_color, bbox, use_retina, withContours):
    """
    ë§ˆìŠ¤í¬ ì£¼ì„ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ê³ , í˜íŠ¸ë¦¬ ì ‘ì‹œëŠ” ì™¸ê³½ì„ ë§Œ ê·¸ë¦¬ë©° ì½œë¡œë‹ˆëŠ” ì±„ìš°ê³  ì™¸ê³½ì„ ì„ ê·¸ë¦½ë‹ˆë‹¤.
    """
    try:
        image_np = np.array(image).copy()

        # ì½œë¡œë‹ˆ ë§ˆìŠ¤í¬ ì²˜ë¦¬
        for ann in colony_annotations:
            mask = ann.cpu().numpy()
            if mask.ndim == 2:
                mask = mask > 0
                if mask_random_color:
                    color = np.random.randint(0, 255, (3,)).tolist()
                    image_np[mask] = color
                else:
                    image_np[mask] = (0, 255, 0)  # ê¸°ë³¸ ì´ˆë¡ìƒ‰

            if withContours:
                contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(image_np, contours, -1, (255, 0, 0), 2)  # íŒŒë€ìƒ‰ ê²½ê³„ì„ 

        # í˜íŠ¸ë¦¬ ì ‘ì‹œ ë§ˆìŠ¤í¬ ì²˜ë¦¬ (ì™¸ê³½ì„ ë§Œ)
        if dish_annotation is not None:
            dish_mask = dish_annotation.cpu().numpy()
            if dish_mask.ndim == 2:
                dish_mask = dish_mask > 0
                if withContours:
                    contours, _ = cv2.findContours(dish_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    cv2.drawContours(image_np, contours, -1, (0, 0, 255), 3)  # ë¹¨ê°„ìƒ‰ ì™¸ê³½ì„ 

        processed_image = Image.fromarray(image_np)
        return processed_image
    except Exception as e:
        logger.error(f"Error in fast_process: {str(e)}")
        raise

class ColonyCounter:
    def __init__(self):
        self.manual_points = []
        self.auto_points = []
        self.current_image = None
        self.auto_detected_count = 0
        self.remove_mode = False
        self.original_image = None
        self.last_method = None
        self.image_manager = ImageManager()
        
    def reset(self):
        self.manual_points = []
        self.auto_points = []
        self.current_image = None
        self.auto_detected_count = 0
        self.remove_mode = False
        self.original_image = None
        self.last_method = None

    def set_original_image(self, image):
        self.original_image = np.array(image)

    def save_analysis_results(self, original_image, analyzed_image, analysis_params):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        try:
            # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„±
            overlay_image = self.create_overlay(original_image, analyzed_image)
            
            # ì´ë¯¸ì§€ ì €ì¥ ë° íƒ€ì„ìŠ¤íƒ¬í”„ ë°›ê¸°
            timestamp = self.image_manager.save_images(
                original_image,
                analyzed_image,
                overlay_image
            )
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            metadata = {
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "counts": {
                    "total": self.auto_detected_count + len(self.manual_points),
                    "auto_detected": self.auto_detected_count,
                    "manually_added": len(self.manual_points)
                },
                "analysis_params": analysis_params,
                "processing_time": time.time() - self._start_time if hasattr(self, '_start_time') else None
            }
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            self.image_manager.save_metadata(timestamp, metadata)
            logger.info(f"Analysis results saved successfully: {timestamp}")
        except Exception as e:
            logger.error(f"Error saving analysis results: {str(e)}")
            raise
            
    def create_overlay(self, original_image, analyzed_image):
        """ì›ë³¸ê³¼ ë¶„ì„ ê²°ê³¼ë¥¼ í•©ì¹œ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # ì´ë¯¸ì§€ê°€ numpy arrayê°€ ì•„ë‹ˆë©´ ë³€í™˜
            if isinstance(original_image, Image.Image):
                original_image = np.array(original_image)
            if isinstance(analyzed_image, Image.Image):
                analyzed_image = np.array(analyzed_image)
                
            # ì˜¤ë²„ë ˆì´ ìƒì„±
            overlay = cv2.addWeighted(original_image, 0.7, analyzed_image, 0.3, 0)
            return overlay
        except Exception as e:
            logger.error(f"Error creating overlay: {str(e)}")
            raise

    def toggle_remove_mode(self):
        self.remove_mode = not self.remove_mode
        img_with_points = self.draw_points()
        mode_text = "ğŸ”´ Remove Mode" if self.remove_mode else "ğŸŸ¢ Add Mode"
        return img_with_points, mode_text

    def add_or_remove_point(self, image, evt: gr.SelectData):
        try:
            if self.current_image is None and image is not None:
                self.current_image = np.array(image)

            x, y = evt.index

            if self.remove_mode:
                # ì œê±° ëª¨ë“œ: ê°€ì¥ ê°€ê¹Œìš´ ì  ì°¾ì•„ì„œ ì œê±°
                if self.manual_points:
                    closest_idx = self.find_closest_point(x, y)
                    if closest_idx is not None:
                        self.manual_points.pop(closest_idx)
            else:
                # ì¶”ê°€ ëª¨ë“œ: ìƒˆë¡œìš´ ì  ì¶”ê°€
                self.manual_points.append((x, y))

            img_with_points = self.draw_points()
            return img_with_points, self.get_count_text()
        except Exception as e:
            logger.error(f"Error in add_or_remove_point: {str(e)}")
            return image, self.get_count_text()

    def find_closest_point(self, x, y, threshold=20):
        if not self.manual_points:
            return None

        distances = []
        for idx, (px, py) in enumerate(self.manual_points):
            dist = np.sqrt((x - px) ** 2 + (y - py) ** 2)
            distances.append((dist, idx))

        closest_dist, closest_idx = min(distances, key=lambda item: item[0])
        return closest_idx if closest_dist < threshold else None

    def remove_last_point(self, image):
        try:
            if self.manual_points:
                self.manual_points.pop()
                img_with_points = self.draw_points()
                return img_with_points, self.get_count_text()
            return image, self.get_count_text()
        except Exception as e:
            logger.error(f"Error in remove_last_point: {str(e)}")
            return image, self.get_count_text()

    def get_count_text(self):
        try:
            method_text = f"Method: {self.last_method}\n" if self.last_method else ""
            return (f"{method_text}Total Colony Count: {self.auto_detected_count + len(self.manual_points)}\n"
                    f"ğŸ¤– Auto detected: {self.auto_detected_count}\n"
                    f"ğŸ‘† Manually added: {len(self.manual_points)}")
        except Exception as e:
            logger.error(f"Error in get_count_text: {str(e)}")
            return "Error calculating count"

    def draw_points(self):
        try:
            if self.current_image is None:
                return None

            img_with_points = self.current_image.copy()  # í•œ ë²ˆë§Œ ë³µì‚¬
            overlay = np.zeros_like(img_with_points)  # ì˜¤ë²„ë ˆì´ ë ˆì´ì–´ ìƒì„±
            square_size = 25  # ìˆ˜ë™ í¬ì¸íŠ¸ì˜ í¬ê¸° ì„¤ì •

            # Font settings
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.7
            font_thickness = 1        # í°ìƒ‰ ê¸€ì”¨ë¥¼ ì–‡ê²Œ
            outline_thickness = 3     # ê²€ì€ìƒ‰ ì™¸ê³½ì„ ì„ ë‘ê»ê²Œ

            # ìë™ ê°ì§€ëœ colonyì— ë²ˆí˜¸ í‘œì‹œ
            for idx, (x, y) in enumerate(self.auto_points, 1):
                text = str(idx)
                (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)

                text_x = int(x - text_width / 2)
                text_y = int(y - 10)

                # ê²€ì€ìƒ‰ ì™¸ê³½ì„  (4ë°©í–¥)
                for dx, dy in [(-1, -1), (-1, 1), (1, -1), (1, 1)]:
                    cv2.putText(img_with_points, text,
                                (text_x + dx, text_y + dy),
                                font, font_scale, (0, 0, 0), outline_thickness)

                # í°ìƒ‰ í…ìŠ¤íŠ¸
                cv2.putText(img_with_points, text,
                            (text_x, text_y),
                            font, font_scale, (255, 255, 255), font_thickness)

            # ìˆ˜ë™ í¬ì¸íŠ¸ ëª¨ë‘ í•œë²ˆì— ê·¸ë¦¬ê¸°
            for x, y in self.manual_points:
                pt1 = (int(x - square_size / 2), int(y - square_size / 2))
                pt2 = (int(x + square_size / 2), int(y + square_size / 2))
                cv2.rectangle(overlay, pt1, pt2, (255, 0, 0), -1)

            # í•œ ë²ˆì˜ addWeighted ì—°ì‚°ìœ¼ë¡œ ì²˜ë¦¬
            cv2.addWeighted(overlay, 0.4, img_with_points, 1.0, 0, img_with_points)

            # ìˆ˜ë™ í¬ì¸íŠ¸ì— ë²ˆí˜¸ í‘œì‹œ (í…ìŠ¤íŠ¸ ìƒ‰ìƒì„ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ ë³€ê²½)
            for idx, (x, y) in enumerate(self.manual_points, len(self.auto_points) + 1):
                text = str(idx)
                (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)
                text_x = int(x - text_width / 2)
                text_y = int(y - 10)

                # ê²€ì€ìƒ‰ ì™¸ê³½ì„  (4ë°©í–¥)
                for dx, dy in [(-1, -1), (-1, 1), (1, -1), (1, 1)]:
                    cv2.putText(img_with_points, text,
                                (text_x + dx, text_y + dy),
                                font, font_scale, (0, 0, 0), outline_thickness)

                # ë¹¨ê°„ìƒ‰ í…ìŠ¤íŠ¸
                cv2.putText(img_with_points, text,
                            (text_x, text_y),
                            font, font_scale, (0, 0, 255), font_thickness)  # (B, G, R) í˜•ì‹ìœ¼ë¡œ ë¹¨ê°„ìƒ‰

            # ì œê±° ëª¨ë“œ í‘œì‹œ
            if self.remove_mode:
                overlay = img_with_points.copy()
                cv2.rectangle(overlay, (0, 0), (img_with_points.shape[1], 40), (255, 0, 0), -1)
                cv2.addWeighted(overlay, 0.3, img_with_points, 0.7, 0, img_with_points)
                cv2.putText(img_with_points, "REMOVE MODE", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

            return img_with_points
        except Exception as e:
            logger.error(f"Error in draw_points: {str(e)}")
            return self.current_image

counter = ColonyCounter()

def segment_and_count_colonies(
    input_image,
    method='fastsam',
    input_size=1024,
    iou_threshold=0.7,
    conf_threshold=0.25,
    better_quality=False,
    withContours=True,
    mask_random_color=True,
    min_area_percentile=1,
    max_area_percentile=99,
    circularity_threshold=0.8
):
    try:
        if input_image is None:
            return None, "No input image provided."

        counter.reset()
        counter._start_time = time.time()  # ì²˜ë¦¬ ì‹œê°„ ì¸¡ì • ì‹œì‘
        counter.set_original_image(input_image)
        counter.last_method = method.upper()

        # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
        input_size = int(input_size)
        w, h = input_image.size
        scale = input_size / max(w, h)
        new_w, new_h = int(w * scale), int(h * scale)
        input_resized = input_image.resize((new_w, new_h))

        # FastSAM ëª¨ë¸ ì‹¤í–‰
        results = model.predict(
            input_resized,
            device=device,
            conf=conf_threshold,
            iou=iou_threshold,
            imgsz=input_size,
            retina_masks=True
        )

        # ë§ˆìŠ¤í¬ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
        if not hasattr(results[0], 'masks') or results[0].masks is None:
            counter.current_image = np.array(input_resized)
            return np.array(input_resized), "No colonies detected"

        annotations = results[0].masks.data

        if len(annotations) == 0:
            counter.current_image = np.array(input_resized)
            return np.array(input_resized), "No colonies detected"

        # ëª¨ë“  ë§ˆìŠ¤í¬ì˜ ë©´ì  ê³„ì‚°
        areas = [np.sum(ann.cpu().numpy() > 0) for ann in annotations]

        # í˜íŠ¸ë¦¬ ì ‘ì‹œ ë§ˆìŠ¤í¬ ì°¾ê¸° (ê°€ì¥ í° ë§ˆìŠ¤í¬)
        dish_idx = np.argmax(areas)
        dish_annotation = annotations[dish_idx]
        colony_annotations = [ann for idx, ann in enumerate(annotations) if idx != dish_idx]

        # ë©´ì  í•„í„°ë§ ë° ì›í˜•ë„ ê³„ì‚°
        valid_colony_annotations = []
        counter.auto_points = []  # ì¤‘ì‹¬ì  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”

        for ann in colony_annotations:
            mask = ann.cpu().numpy()
            area = np.sum(mask > 0)

            # ì›í˜•ë„ ê³„ì‚°
            contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if len(contours) > 0:
                perimeter = cv2.arcLength(contours[0], True)
                circularity = 4 * np.pi * (area / (perimeter ** 2)) if perimeter > 0 else 0
                if circularity >= circularity_threshold:
                    valid_colony_annotations.append(ann)
                    # ë§ˆìŠ¤í¬ì˜ ì¤‘ì‹¬ì  ê³„ì‚°
                    y_indices, x_indices = np.where(mask > 0)
                    center_x = int(np.mean(x_indices))
                    center_y = int(np.mean(y_indices))
                    counter.auto_points.append((center_x, center_y))

        # ì´ë¯¸ì§€ ì²˜ë¦¬
        if valid_colony_annotations:
            fig = fast_process(
                colony_annotations=valid_colony_annotations,
                dish_annotation=dish_annotation,
                image=input_resized,
                device=device,
                scale=(1024 // input_size),
                better_quality=better_quality,
                mask_random_color=mask_random_color,
                bbox=None,
                use_retina=False,
                withContours=withContours
            )
        else:
            fig = input_resized

        # numpy ë°°ì—´ë¡œ ë³€í™˜ ë° auto_detected_count ì„¤ì •
        if isinstance(fig, Image.Image):
            counter.current_image = np.array(fig)
        else:
            counter.current_image = fig

        counter.auto_detected_count = len(counter.auto_points)

        # draw_pointsë¥¼ í˜¸ì¶œí•˜ì—¬ ìˆ«ì í‘œì‹œ
        counter.current_image = counter.draw_points()

        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        analysis_params = {
            "method": method,
            "input_size": input_size,
            "iou_threshold": iou_threshold,
            "conf_threshold": conf_threshold,
            "better_quality": better_quality,
            "withContours": withContours,
            "mask_random_color": mask_random_color,
            "min_area_percentile": min_area_percentile,
            "max_area_percentile": max_area_percentile,
            "circularity_threshold": circularity_threshold
        }
        
        counter.save_analysis_results(
            np.array(input_image),
            counter.current_image,
            analysis_params
        )
        
        return counter.current_image, counter.get_count_text()
        
    except Exception as e:
        logger.error(f"Error in segment_and_count_colonies: {str(e)}")
        if input_image is not None:
            return np.array(input_image), f"Error processing image: {str(e)}"
        return None, f"Error processing image: {str(e)}"

counter = ColonyCounter()

# CSS ìŠ¤íƒ€ì¼ ì •ì˜
css = """
.container {max-width: 1100px; margin: auto; padding: 20px;}
.header {text-align: center; margin-bottom: 30px;}
.result-text {font-size: 1.2em; font-weight: bold;}
.instruction-box {
    background-color: #000000;
    color: #ffffff;
    border-radius: 10px;
    padding: 20px;
    margin: 20px 0;
}
.input-image {border: 2px solid #ddd;}
.output-image {border: 2px solid #ddd;}
"""

# Gradio ì¸í„°í˜ì´ìŠ¤ ì„¤ì •
with gr.Blocks(theme=gr.themes.Soft(), css=css) as demo:
    gr.Markdown(
        """
        <div class="header">
            <h1>ğŸ”¬ ê³ ê¸‰ ì½œë¡œë‹ˆ ì¹´ìš´í„°</h1>
            <h3>ìë™ ì½œë¡œë‹ˆ ê°ì§€ ë° ìˆ˜ë™ ìˆ˜ì • ê¸°ëŠ¥</h3>
        </div>
        """
    )

    with gr.Tab("ì½œë¡œë‹ˆ ì¹´ìš´í„°"):
        with gr.Row():
            with gr.Column(scale=1):
                input_image = gr.Image(
                    label="ì´ë¯¸ì§€ ì—…ë¡œë“œ",
                    type="pil",
                    elem_classes="input-image"
                )
                with gr.Row():
                    method_select = gr.Radio(
                        choices=['FastSAM'],
                        value='FastSAM',
                        label="íƒì§€ ë°©ë²•",
                        info="AI ê¸°ë°˜ íƒì§€ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”"
                    )
                    segment_button = gr.Button(
                        "ğŸ” ì´ë¯¸ì§€ ë¶„ì„",
                        variant="primary",
                        scale=2
                    )

                with gr.Accordion("âš™ï¸ ë¶„ì„ ì„¤ì •", open=False):
                    with gr.Tab("ì¼ë°˜"):
                        input_size_slider = gr.Slider(
                            512, 1024, 1024,
                            step=64,
                            label="ì…ë ¥ í¬ê¸°",
                            info="í¬ë©´ ì •í™•ë„ê°€ ë†’ì•„ì§€ì§€ë§Œ ì²˜ë¦¬ ì†ë„ê°€ ëŠë ¤ì§‘ë‹ˆë‹¤"
                        )
                        better_quality_checkbox = gr.Checkbox(
                            label="í–¥ìƒëœ í’ˆì§ˆ",
                            value=True,
                            info="ì†ë„ë¥¼ í¬ìƒí•˜ê³  ì¶œë ¥ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤"
                        )
                        withContours_checkbox = gr.Checkbox(
                            label="ì™¸ê³½ì„  í‘œì‹œ",
                            value=True,
                            info="ì½œë¡œë‹ˆì˜ ê²½ê³„ì„ ì„ í‘œì‹œí•©ë‹ˆë‹¤"
                        )

                    with gr.Tab("FastSAM"):
                        iou_threshold_slider = gr.Slider(
                            0.1, 0.9, 0.7,
                            label="IOU ì„ê³„ê°’",
                            info="ë†’ì„ìˆ˜ë¡ ê²¹ì¹¨ ê°ì§€ê°€ ì—„ê²©í•´ì§‘ë‹ˆë‹¤"
                        )
                        conf_threshold_slider = gr.Slider(
                            0.1, 0.9, 0.25,
                            label="ì‹ ë¢°ë„ ì„ê³„ê°’",
                            info="ë†’ì„ìˆ˜ë¡ ì‹ ë¢°ë„ê°€ ë†’ì€ íƒì§€ë§Œ í‘œì‹œë©ë‹ˆë‹¤"
                        )

                    with gr.Tab("í¬ê¸° í•„í„°"):
                        min_area_percentile_slider = gr.Slider(
                            0, 10, 1,
                            label="ìµœì†Œ í¬ê¸° ë°±ë¶„ìœ„ìˆ˜",
                            info="ì‘ì€ ì½œë¡œë‹ˆë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤ (1ì€ ê°€ì¥ ì‘ì€ 1% í•„í„°ë§)"
                        )
                        max_area_percentile_slider = gr.Slider(
                            90, 100, 99,
                            label="ìµœëŒ€ í¬ê¸° ë°±ë¶„ìœ„ìˆ˜",
                            info="í° ê°ì²´ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤ (99ëŠ” ê°€ì¥ í° 1% í•„í„°ë§)"
                        )

                    with gr.Tab("í˜•íƒœ í•„í„°"):
                        circularity_threshold_slider = gr.Slider(
                            0.0, 1.0, 0.8,
                            label="ì›í˜•ë„ ì„ê³„ê°’",
                            info="ì›í˜•ì— ê°€ê¹Œìš´ ì½œë¡œë‹ˆë§Œ ê°ì§€í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤ (1 = ì™„ë²½í•œ ì›)"
                        )

            with gr.Column(scale=1):
                output_image = gr.Image(
                    label="ë¶„ì„ ê²°ê³¼",
                    type="numpy",
                    interactive=True,
                    elem_classes="output-image"
                )
                colony_count_text = gr.Textbox(
                    label="ì¹´ìš´íŠ¸ ê²°ê³¼",
                    lines=3,
                    elem_classes="result-text"
                )
                save_path_text = gr.Textbox(
                    label="ì €ì¥ ìœ„ì¹˜",
                    value=f"ê²°ê³¼ê°€ ì €ì¥ëœ ìœ„ì¹˜: {counter.image_manager.base_path}",
                    lines=1,
                    interactive=False
                )

                with gr.Row():
                    with gr.Column(scale=1):
                        remove_mode_button = gr.Button(
                            "ğŸ”„ í¸ì§‘ ëª¨ë“œ ì „í™˜",
                            variant="secondary"
                        )
                        remove_mode_text = gr.Textbox(
                            label="í˜„ì¬ ëª¨ë“œ",
                            value="ğŸŸ¢ ì¶”ê°€ ëª¨ë“œ",
                            lines=1
                        )
                    with gr.Column(scale=1):
                        remove_point_button = gr.Button(
                            "â†©ï¸ ìµœê·¼ í¬ì¸íŠ¸ ì œê±°",
                            variant="secondary"
                        )

        with gr.Row(elem_classes="instruction-box"):
            gr.Markdown(
                """
                ### ğŸ“ ë¹ ë¥¸ ê°€ì´ë“œ
                1. **ì´ë¯¸ì§€ ì—…ë¡œë“œ**: ë¶„ì„í•  ì½œë¡œë‹ˆ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.
                2. **íƒì§€ ë°©ë²• ì„ íƒ**: FastSAM - AI ê¸°ë°˜ íƒì§€ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
                3. **ì´ë¯¸ì§€ ë¶„ì„**: "ğŸ” ì´ë¯¸ì§€ ë¶„ì„" ë²„íŠ¼ì„ ëˆŒëŸ¬ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì„¸ìš”.
                4. **ìˆ˜ë™ ìˆ˜ì •**: 
                   - ğŸ‘† ì´ë¯¸ì§€ë¥¼ í´ë¦­í•˜ì—¬ ëˆ„ë½ëœ ì½œë¡œë‹ˆë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
                   - ğŸ”„ "í¸ì§‘ ëª¨ë“œ ì „í™˜" ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ê°€/ì œê±° ëª¨ë“œë¥¼ ì „í™˜í•˜ì„¸ìš”.
                   - â†©ï¸ "ìµœê·¼ í¬ì¸íŠ¸ ì œê±°" ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ìµœê·¼ ì¶”ê°€ëœ í¬ì¸íŠ¸ë¥¼ ì œê±°í•˜ì„¸ìš”.
                5. **ë¶„ì„ ì„¤ì • ì¡°ì •**:
                   - **ì…ë ¥ í¬ê¸°**: ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì„¤ì •í•˜ì„¸ìš” (í¬ë©´ ì •í™•ë„ ì¦ê°€, ì†ë„ ê°ì†Œ).
                   - **IOU ì„ê³„ê°’**: ê²¹ì¹¨ì— ëŒ€í•œ ë¯¼ê°ë„ë¥¼ ì„¤ì •í•˜ì„¸ìš” (ë†’ì„ìˆ˜ë¡ ê²¹ì¹¨ì´ ì—„ê²©í•˜ê²Œ íŒë‹¨ë¨).
                   - **ì‹ ë¢°ë„ ì„ê³„ê°’**: íƒì§€ ì‹ ë¢°ë„ë¥¼ ì„¤ì •í•˜ì„¸ìš” (ë†’ì„ìˆ˜ë¡ ì‹ ë¢°ë„ê°€ ë†’ì€ íƒì§€ë§Œ í‘œì‹œë¨).
                   - **ìµœì†Œ/ìµœëŒ€ í¬ê¸° ë°±ë¶„ìœ„ìˆ˜**: í¬ê¸° í•„í„°ë¥¼ ì„¤ì •í•˜ì—¬ ë„ˆë¬´ ì‘ê±°ë‚˜ í° ì½œë¡œë‹ˆë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤.
                   - **ì›í˜•ë„ ì„ê³„ê°’**: ì›í˜•ë„ í•„í„°ë¥¼ ì„¤ì •í•˜ì—¬ ì›í˜•ì— ê°€ê¹Œìš´ ì½œë¡œë‹ˆë§Œ íƒì§€í•©ë‹ˆë‹¤.
                """
            )

    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
    segment_button.click(
        segment_and_count_colonies,
        inputs=[
            input_image,
            method_select,
            input_size_slider,
            iou_threshold_slider,
            conf_threshold_slider,
            better_quality_checkbox,
            withContours_checkbox,
            min_area_percentile_slider,
            max_area_percentile_slider,
            circularity_threshold_slider
        ],
        outputs=[output_image, colony_count_text]
    )

    # ìˆ˜ë™ í¬ì¸íŠ¸ ì¶”ê°€/ì œê±° ì´ë²¤íŠ¸
    output_image.select(
        counter.add_or_remove_point,
        inputs=[output_image],
        outputs=[output_image, colony_count_text]
    )

    remove_point_button.click(
        counter.remove_last_point,
        inputs=[output_image],
        outputs=[output_image, colony_count_text]
    )

    remove_mode_button.click(
        counter.toggle_remove_mode,
        inputs=[],
        outputs=[output_image, remove_mode_text]
    )

# ì•± ì‹¤í–‰
if __name__ == "__main__":
    demo.launch()
