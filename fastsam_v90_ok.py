from ultralytics import YOLO
import gradio as gr
import torch
from PIL import Image
import numpy as np
import cv2
import os
from datetime import datetime
import pandas as pd
from pathlib import Path
import json
import sys
import warnings

# FutureWarning ë¬´ì‹œ (ì˜µì…˜, ê¶Œì¥í•˜ì§€ ì•ŠìŒ)
warnings.filterwarnings("ignore", category=FutureWarning)

# ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
DEFAULT_OUTPUT_DIR = os.path.join(str(Path.home()), 'colony_counter_results')
os.makedirs(DEFAULT_OUTPUT_DIR, exist_ok=True)

# FastSAM ëª¨ë¸ ë¡œë“œ
try:
    model = YOLO('./weights/FastSAM-x.pt')
except Exception as e:
    print(f"Error loading YOLO model: {str(e)}")
    sys.exit(1)

# ì¥ì¹˜ ì„¤ì •
device = torch.device(
    "cuda" if torch.cuda.is_available() else
    "mps" if torch.backends.mps.is_available() else "cpu"
)

def fast_process(colony_annotations, dish_annotation, image, mask_random_color, withContours):
    """
    ë§ˆìŠ¤í¬ ì£¼ì„ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ê³ , í˜íŠ¸ë¦¬ ì ‘ì‹œëŠ” ì™¸ê³½ì„ ë§Œ ê·¸ë¦¬ë©° ì½œë¡œë‹ˆëŠ” ì±„ìš°ê³  ì™¸ê³½ì„ ì„ ê·¸ë¦½ë‹ˆë‹¤.
    """
    try:
        image_np = np.array(image).copy()

        # ì½œë¡œë‹ˆ ë§ˆìŠ¤í¬ ì²˜ë¦¬
        for ann in colony_annotations:
            ann_cpu = ann.cpu().numpy()
            if ann_cpu.ndim == 3 and ann_cpu.shape[0] == 1:
                ann_cpu = ann_cpu[0]  # (1, H, W) -> (H, W)
            
            mask = ann_cpu > 0
            if mask.ndim == 2:
                if mask_random_color:
                    color = np.random.randint(0, 255, (3,)).tolist()
                    image_np[mask] = color
                else:
                    image_np[mask] = (0, 255, 0)  # ê¸°ë³¸ ì´ˆë¡ìƒ‰

            if withContours:
                contours = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                contours = contours[0] if len(contours) == 2 else contours[1]
                cv2.drawContours(image_np, contours, -1, (255, 0, 0), 2)  # íŒŒë€ìƒ‰ ê²½ê³„ì„ 

        # í˜íŠ¸ë¦¬ ì ‘ì‹œ ë§ˆìŠ¤í¬ ì²˜ë¦¬ (ì™¸ê³½ì„ ë§Œ)
        if dish_annotation is not None:
            dish_mask = dish_annotation.cpu().numpy()
            if dish_mask.ndim == 3 and dish_mask.shape[0] == 1:
                dish_mask = dish_mask[0]
            if dish_mask.ndim == 2:
                dish_mask = dish_mask > 0
                if withContours:
                    contours = cv2.findContours(dish_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    contours = contours[0] if len(contours) == 2 else contours[1]
                    cv2.drawContours(image_np, contours, -1, (0, 0, 255), 3)  # ë¹¨ê°„ìƒ‰ ì™¸ê³½ì„ 

        processed_image = Image.fromarray(image_np)
        return processed_image
    except Exception as e:
        print(f"Error in fast_process: {str(e)}")
        return image

class ColonyCounter:
    """
    ì½œë¡œë‹ˆ ì¹´ìš´í„° í´ë˜ìŠ¤
    ìë™/ìˆ˜ë™ ì½œë¡œë‹ˆ ê°ì§€ ë° ì¹´ìš´íŒ…ì„ ìœ„í•œ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    def __init__(self):
        """
        ì½œë¡œë‹ˆ ì¹´ìš´í„° ì´ˆê¸°í™”
        - manual_points: ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€ëœ í¬ì¸íŠ¸ ëª©ë¡
        - auto_points: AIê°€ ìë™ ê°ì§€í•œ colony ì¤‘ì‹¬ì  ëª©ë¡
        - current_image: í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì´ë¯¸ì§€
        - auto_detected_count: ìë™ ê°ì§€ëœ ì½œë¡œë‹ˆ ìˆ˜
        - remove_mode: í¬ì¸íŠ¸ ì œê±° ëª¨ë“œ ì—¬ë¶€
        - last_method: ë§ˆì§€ë§‰ìœ¼ë¡œ ì‚¬ìš©ëœ ê°ì§€ ë°©ë²•
        - scale_factor: ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§• ë¹„ìœ¨ ì €ì¥ ë³€ìˆ˜ ì¶”ê°€
        """
        self.manual_points = []
        self.auto_points = []
        self.current_image = None
        self.auto_detected_count = 0
        self.remove_mode = False
        self.original_image = None
        self.last_method = "NONE"
        self.scale_factor = 1.0  # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§• ë¹„ìœ¨ ì €ì¥ ë³€ìˆ˜ ì¶”ê°€

    def reset(self):
        self.manual_points = []
        self.auto_points = []
        self.current_image = None
        self.auto_detected_count = 0
        self.remove_mode = False
        self.original_image = None
        self.last_method = "NONE"
        self.scale_factor = 1.0  # ë¦¬ì…‹ ì‹œ scale_factorë„ ì´ˆê¸°í™”

    def set_original_image(self, image):
        self.original_image = np.array(image)

    def toggle_remove_mode(self):
        self.remove_mode = not self.remove_mode
        img_with_points = self.draw_points()
        mode_text = "ğŸ”´ Remove Mode" if self.remove_mode else "ğŸŸ¢ Add Mode"
        return img_with_points, mode_text

    def find_closest_point(self, x, y, threshold=50):
        # ìë™ í¬ì¸íŠ¸ì™€ ìˆ˜ë™ í¬ì¸íŠ¸ ëª¨ë‘ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ì  ì°¾ê¸°
        all_points = self.auto_points + self.manual_points
        if not all_points:
            return None, None
        
        # í´ë¦­ ì¢Œí‘œëŠ” UI ì¢Œí‘œê³„, ì €ì¥ëœ í¬ì¸íŠ¸ëŠ” ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ ì¢Œí‘œê³„
        # ë”°ë¼ì„œ í´ë¦­ ì¢Œí‘œë¥¼ ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ ì¢Œí‘œê³„ë¡œ ë³€í™˜
        scaled_x = x / self.scale_factor
        scaled_y = y / self.scale_factor

        distances = []
        for idx, (px, py) in enumerate(all_points):
            dist = np.sqrt((scaled_x - px) ** 2 + (scaled_y - py) ** 2)
            distances.append((dist, idx))

        if not distances:
            return None, None

        closest_dist, closest_idx = min(distances, key=lambda item: item[0])
        if closest_dist < threshold:
            # auto_points ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìë™/ìˆ˜ë™ì„ êµ¬ë¶„
            is_auto = (closest_idx < len(self.auto_points))
            return closest_idx, is_auto
        return None, None

    def debug_find_closest(self, x, y, threshold=50):
        """ë””ë²„ê¹…ìš© í•¨ìˆ˜: ê°€ì¥ ê°€ê¹Œìš´ í¬ì¸íŠ¸ ì°¾ê¸° ê³¼ì •ì„ ìì„¸íˆ ì¶œë ¥"""
        all_points = self.auto_points + self.manual_points
        if not all_points:
            print("í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None, None
        
        # í´ë¦­ ì¢Œí‘œëŠ” UI ì¢Œí‘œê³„, ì €ì¥ëœ í¬ì¸íŠ¸ëŠ” ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ ì¢Œí‘œê³„
        # ë”°ë¼ì„œ í´ë¦­ ì¢Œí‘œë¥¼ ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ ì¢Œí‘œê³„ë¡œ ë³€í™˜
        scaled_x = x / self.scale_factor
        scaled_y = y / self.scale_factor
        print(f"í´ë¦­ ì¢Œí‘œ: ({x}, {y}) -> ë³€í™˜ ì¢Œí‘œ: ({scaled_x}, {scaled_y})")
        print(f"ìŠ¤ì¼€ì¼ íŒ©í„°: {self.scale_factor}")
        
        if len(self.auto_points) > 0:
            print(f"ìë™ í¬ì¸íŠ¸ ê°œìˆ˜: {len(self.auto_points)}")
            for i, (px, py) in enumerate(self.auto_points[:5]):
                dist = np.sqrt((scaled_x - px) ** 2 + (scaled_y - py) ** 2)
                print(f"  ìë™ í¬ì¸íŠ¸ {i}: ({px}, {py}), ê±°ë¦¬: {dist}")
            if len(self.auto_points) > 5:
                print(f"  ... ì™¸ {len(self.auto_points)-5}ê°œ")
        
        if len(self.manual_points) > 0:
            print(f"ìˆ˜ë™ í¬ì¸íŠ¸ ê°œìˆ˜: {len(self.manual_points)}")
            for i, (px, py) in enumerate(self.manual_points[:5]):
                dist = np.sqrt((scaled_x - px) ** 2 + (scaled_y - py) ** 2)
                print(f"  ìˆ˜ë™ í¬ì¸íŠ¸ {i}: ({px}, {py}), ê±°ë¦¬: {dist}")
            if len(self.manual_points) > 5:
                print(f"  ... ì™¸ {len(self.manual_points)-5}ê°œ")

        distances = []
        for idx, (px, py) in enumerate(all_points):
            dist = np.sqrt((scaled_x - px) ** 2 + (scaled_y - py) ** 2)
            distances.append((dist, idx))

        if not distances:
            print("ê±°ë¦¬ ê³„ì‚° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None, None

        closest_dist, closest_idx = min(distances, key=lambda item: item[0])
        print(f"ê°€ì¥ ê°€ê¹Œìš´ í¬ì¸íŠ¸ ì¸ë±ìŠ¤: {closest_idx}, ê±°ë¦¬: {closest_dist}")
        print(f"ì„ê³„ê°’: {threshold}")
        
        if closest_dist < threshold:
            is_auto = (closest_idx < len(self.auto_points))
            type_str = "ìë™" if is_auto else "ìˆ˜ë™"
            print(f"ì„ íƒëœ í¬ì¸íŠ¸: {type_str} í¬ì¸íŠ¸ {closest_idx}, ì„ê³„ê°’ ë²”ìœ„ ë‚´ì— ìˆìŒ")
            return closest_idx, is_auto
        else:
            print(f"ê°€ì¥ ê°€ê¹Œìš´ í¬ì¸íŠ¸ë„ ì„ê³„ê°’ë³´ë‹¤ ë©€ë¦¬ ìˆìŠµë‹ˆë‹¤.")
        return None, None

    def add_or_remove_point(self, image, evt: gr.SelectData):
        try:
            if self.current_image is None and image is not None:
                self.current_image = np.array(image)

            x, y = evt.index
            print(f"í´ë¦­ ì¢Œí‘œ: ({x}, {y}), ìŠ¤ì¼€ì¼ íŒ©í„°: {self.scale_factor}")

            if self.remove_mode:
                # ì¼ë°˜ find_closest_point ëŒ€ì‹  debug ë²„ì „ì„ ì‚¬ìš© (ë¬¸ì œ ì§„ë‹¨ ì‹œ)
                # closest_idx, is_auto = self.debug_find_closest(x, y)
                
                closest_idx, is_auto = self.find_closest_point(x, y)
                if closest_idx is not None:
                    if is_auto:
                        point = self.auto_points[closest_idx]
                        print(f"ì œê±°í•  ìë™ í¬ì¸íŠ¸ {closest_idx}: ({point[0]}, {point[1]})")
                        self.auto_points.pop(closest_idx)
                        self.auto_detected_count -= 1
                    else:
                        manual_idx = closest_idx - len(self.auto_points)
                        point = self.manual_points[manual_idx]
                        print(f"ì œê±°í•  ìˆ˜ë™ í¬ì¸íŠ¸ {manual_idx}: ({point[0]}, {point[1]})")
                        self.manual_points.pop(manual_idx)
                else:
                    print(f"ê°€ê¹Œìš´ í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„ê³„ê°’ ë²”ìœ„ ë‚´ì— ì—†ìŒ.")
            else:
                # ìˆ˜ë™ í¬ì¸íŠ¸ ì¶”ê°€ ì‹œì—ë„ ì¢Œí‘œê³„ ë³€í™˜ í•„ìš”
                # UI ì¢Œí‘œë¥¼ ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                scaled_x = x / self.scale_factor
                scaled_y = y / self.scale_factor
                self.manual_points.append((scaled_x, scaled_y))
                print(f"ìˆ˜ë™ í¬ì¸íŠ¸ ì¶”ê°€: UI ì¢Œí‘œ({x}, {y}) -> ë³€í™˜ ì¢Œí‘œ({scaled_x}, {scaled_y})")

            img_with_points = self.draw_points()
            return img_with_points, self.get_count_text()
        except Exception as e:
            print(f"Error in add_or_remove_point: {str(e)}")
            return image, self.get_count_text()

    def remove_last_point(self, image):
        try:
            if self.manual_points:
                self.manual_points.pop()
                img_with_points = self.draw_points()
                return img_with_points, self.get_count_text()
            return image, self.get_count_text()
        except Exception as e:
            print(f"Error in remove_last_point: {str(e)}")
            return image, self.get_count_text()

    def get_count_text(self):
        try:
            method_text = f"Method: {self.last_method}\n" if self.last_method != "NONE" else ""
            total = self.auto_detected_count + len(self.manual_points)
            return (f"{method_text}Total Colony Count: {total}\n"
                    f"ğŸ¤– Auto detected: {self.auto_detected_count}\n"
                    f"ğŸ‘† Manually added: {len(self.manual_points)}")
        except Exception as e:
            print(f"Error in get_count_text: {str(e)}")
            return "Error calculating count"

    def draw_points(self):
        """
        ì´ë¯¸ì§€ì— ì½œë¡œë‹ˆ í¬ì¸íŠ¸ì™€ ë²ˆí˜¸ë¥¼ ê·¸ë¦¬ëŠ” ë©”ì„œë“œ
        
        ê¸°ëŠ¥:
        1. ìë™ ê°ì§€ëœ ì½œë¡œë‹ˆì— ë²ˆí˜¸ í‘œì‹œ (í°ìƒ‰ í…ìŠ¤íŠ¸ + ê²€ì€ìƒ‰ ì™¸ê³½ì„ )
        2. ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€ëœ í¬ì¸íŠ¸ì— ì‚¬ê°í˜•ê³¼ ë²ˆí˜¸ í‘œì‹œ (ë¹¨ê°„ìƒ‰)
        3. ì œê±° ëª¨ë“œì¼ ë•Œ ìƒë‹¨ì— í‘œì‹œ
        
        [ì‚¬ìš©ì ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥í•œ ë¶€ë¶„]
        1. ë§ˆì»¤ í¬ê¸°:
           - square_size: ìˆ˜ë™ í¬ì¸íŠ¸ì˜ ì‚¬ê°í˜• í¬ê¸° (ê¸°ë³¸ê°’: 25)
           - font: í°íŠ¸ ì¢…ë¥˜ (ê¸°ë³¸ê°’: cv2.FONT_HERSHEY_SIMPLEX)
           - font_scale: í…ìŠ¤íŠ¸ í¬ê¸° (ê¸°ë³¸ê°’: 0.77)
           - font_thickness: ë‚´ë¶€ í…ìŠ¤íŠ¸ ë‘ê»˜ (ê¸°ë³¸ê°’: 1)
           - outline_thickness: ì™¸ê³½ì„  ë‘ê»˜ (ê¸°ë³¸ê°’: 4)

        2. ìƒ‰ìƒ ì„¤ì •:
           - ìë™ ê°ì§€ ì½œë¡œë‹ˆ:
             * í…ìŠ¤íŠ¸ ìƒ‰ìƒ: (255, 255, 255) # í°ìƒ‰
             * ì™¸ê³½ì„  ìƒ‰ìƒ: (0, 0, 0) # ê²€ì€ìƒ‰
           - ìˆ˜ë™ ì¶”ê°€ ì½œë¡œë‹ˆ:
             * ì‚¬ê°í˜• ìƒ‰ìƒ: (255, 0, 0) # ë¹¨ê°„ìƒ‰
             * í…Œë‘ë¦¬ ìƒ‰ìƒ: (0, 0, 0) # ê²€ì€ìƒ‰
             * í…ìŠ¤íŠ¸ ìƒ‰ìƒ: (255, 0, 0) # ë¹¨ê°„ìƒ‰

        3. íˆ¬ëª…ë„ ì„¤ì •:
           - overlay_opacity: ì˜¤ë²„ë ˆì´ íˆ¬ëª…ë„ (ê¸°ë³¸ê°’: 0.4)
           - remove_mode_opacity: ì œê±° ëª¨ë“œ ë°°ë„ˆ íˆ¬ëª…ë„ (ê¸°ë³¸ê°’: 0.3)
        
        ë°˜í™˜ê°’:
        - í¬ì¸íŠ¸ì™€ ë²ˆí˜¸ê°€ í‘œì‹œëœ ì´ë¯¸ì§€
        - ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
        """
        try:
            if self.current_image is None:
                return None

            # ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬ ë° ì˜¤ë²„ë ˆì´ ìƒì„±
            img_with_points = self.current_image.copy()
            overlay = np.zeros_like(img_with_points)

            ###########################################
            # [ì‚¬ìš©ì ì„¤ì • ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤]
            ###########################################
            # 1. ë§ˆì»¤ í¬ê¸° ë° í°íŠ¸ ì„¤ì •
            square_size = 25  # ìˆ˜ë™ í¬ì¸íŠ¸ì˜ ì‚¬ê°í˜• í¬ê¸°
            font = cv2.FONT_HERSHEY_SIMPLEX  # í°íŠ¸ ì¢…ë¥˜
            font_scale = 0.77  # í…ìŠ¤íŠ¸ í¬ê¸°
            font_thickness = 1  # ë‚´ë¶€ í…ìŠ¤íŠ¸ ë‘ê»˜
            outline_thickness = 4  # ì™¸ê³½ì„  ë‘ê»˜

            # 2. ìƒ‰ìƒ ì„¤ì • (B, G, R í˜•ì‹)
            AUTO_TEXT_COLOR = (255, 255, 255)  # ìë™ ê°ì§€ í…ìŠ¤íŠ¸ ìƒ‰ìƒ (í°ìƒ‰)
            AUTO_OUTLINE_COLOR = (0, 0, 0)     # ìë™ ê°ì§€ ì™¸ê³½ì„  ìƒ‰ìƒ (ê²€ì€ìƒ‰)
            MANUAL_RECT_COLOR = (255, 0, 0)    # ìˆ˜ë™ ì¶”ê°€ ì‚¬ê°í˜• ìƒ‰ìƒ (ë¹¨ê°„ìƒ‰)
            MANUAL_BORDER_COLOR = (0, 0, 0)    # ìˆ˜ë™ ì¶”ê°€ í…Œë‘ë¦¬ ìƒ‰ìƒ (ê²€ì€ìƒ‰)
            MANUAL_TEXT_COLOR = (255, 0, 0)    # ìˆ˜ë™ ì¶”ê°€ í…ìŠ¤íŠ¸ ìƒ‰ìƒ (ë¹¨ê°„ìƒ‰)

            # 3. íˆ¬ëª…ë„ ì„¤ì •
            OVERLAY_OPACITY = 0.4  # ì˜¤ë²„ë ˆì´ íˆ¬ëª…ë„
            REMOVE_MODE_OPACITY = 0.3  # ì œê±° ëª¨ë“œ ë°°ë„ˆ íˆ¬ëª…ë„

            ###########################################
            # 1. ìë™ ê°ì§€ëœ ì½œë¡œë‹ˆ ë²ˆí˜¸ í‘œì‹œ
            ###########################################
            for idx, (x, y) in enumerate(self.auto_points, 1):
                # ì €ì¥ëœ ì¢Œí‘œ(ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ ê¸°ì¤€)ë¥¼ UI ì¢Œí‘œë¡œ ë³€í™˜
                ui_x = int(x * self.scale_factor)
                ui_y = int(y * self.scale_factor)
                
                text = str(idx)
                # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°í•˜ì—¬ ì¤‘ì•™ ì •ë ¬
                (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)
                text_x = int(ui_x - text_width / 2)
                text_y = int(ui_y - 10)

                # [ì¤‘ìš”] 8ë°©í–¥ ê²€ì€ìƒ‰ ì™¸ê³½ì„ ìœ¼ë¡œ í…ìŠ¤íŠ¸ ê°€ì‹œì„± í–¥ìƒ
                # dx, dyë¡œ 8ë°©í–¥ì˜ ì˜¤í”„ì…‹ì„ ì§€ì •í•˜ì—¬ ì™¸ê³½ì„  ìƒì„±
                for dx, dy in [(-1,-1), (-1,0), (-1,1), (0,-1), (0,1), (1,-1), (1,0), (1,1)]:
                    cv2.putText(img_with_points, text,
                              (text_x + dx, text_y + dy),
                              font, font_scale, AUTO_OUTLINE_COLOR, outline_thickness)

                # í°ìƒ‰ í…ìŠ¤íŠ¸ë¥¼ ì™¸ê³½ì„  ìœ„ì— ê·¸ë¦¬ê¸°
                cv2.putText(img_with_points, text,
                          (text_x, text_y),
                          font, font_scale, AUTO_TEXT_COLOR, font_thickness)

            ###########################################
            # 2. ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€ëœ í¬ì¸íŠ¸ í‘œì‹œ
            ###########################################
            for idx, (x, y) in enumerate(self.manual_points, len(self.auto_points) + 1):
                # ì €ì¥ëœ ì¢Œí‘œ(ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ ê¸°ì¤€)ë¥¼ UI ì¢Œí‘œë¡œ ë³€í™˜
                ui_x = int(x * self.scale_factor)
                ui_y = int(y * self.scale_factor)
                
                # ì‚¬ê°í˜• ì¢Œí‘œ ê³„ì‚°
                pt1 = (int(ui_x - square_size / 2), int(ui_y - square_size / 2))
                pt2 = (int(ui_x + square_size / 2), int(ui_y + square_size / 2))
                
                # [ì¤‘ìš”] ë°˜íˆ¬ëª… ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
                cv2.rectangle(overlay, pt1, pt2, MANUAL_RECT_COLOR, -1)  # ìƒ‰ìƒ ì±„ìš°ê¸°
                cv2.rectangle(overlay, pt1, pt2, MANUAL_BORDER_COLOR, 2)  # í…Œë‘ë¦¬

                # ë²ˆí˜¸ í…ìŠ¤íŠ¸ ì¶”ê°€
                text = str(idx)
                (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)
                text_x = int(ui_x - text_width / 2)
                text_y = int(ui_y - 10)

                # 8ë°©í–¥ ê²€ì€ìƒ‰ ì™¸ê³½ì„ 
                for dx, dy in [(-1,-1), (-1,0), (-1,1), (0,-1), (0,1), (1,-1), (1,0), (1,1)]:
                    cv2.putText(overlay, text,
                              (text_x + dx, text_y + dy),
                              font, font_scale, AUTO_OUTLINE_COLOR, outline_thickness)

                # ë¹¨ê°„ìƒ‰ í…ìŠ¤íŠ¸
                cv2.putText(img_with_points, text,
                          (text_x, text_y),
                          font, font_scale, MANUAL_TEXT_COLOR, font_thickness)

            # [ì¤‘ìš”] ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ë¥¼ ì›ë³¸ê³¼ ë¸”ë Œë”©
            cv2.addWeighted(overlay, OVERLAY_OPACITY, img_with_points, 1.0, 0, img_with_points)

            ###########################################
            # 3. ì œê±° ëª¨ë“œ í‘œì‹œ
            ###########################################
            if self.remove_mode:
                # ìƒë‹¨ì— ë¹¨ê°„ìƒ‰ ë°°ë„ˆ ì¶”ê°€
                overlay = img_with_points.copy()
                cv2.rectangle(overlay, (0, 0), (img_with_points.shape[1], 40), MANUAL_RECT_COLOR, -1)
                cv2.addWeighted(overlay, REMOVE_MODE_OPACITY, img_with_points, 0.7, 0, img_with_points)
                # "REMOVE MODE" í…ìŠ¤íŠ¸ í‘œì‹œ
                cv2.putText(img_with_points, "REMOVE MODE", (10, 30),
                          font, 1, AUTO_TEXT_COLOR, 2)

            return img_with_points
        except Exception as e:
            print(f"Error in draw_points: {str(e)}")
            return self.current_image

    def save_results(self, output_dir, img_filename):
        """ê²°ê³¼ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì €ì¥"""
        try:
            image_name = os.path.splitext(img_filename)[0]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            save_dir = os.path.join(output_dir, f"{image_name}_{timestamp}")
            os.makedirs(save_dir, exist_ok=True)
            
            if self.original_image is not None:
                original_path = os.path.join(save_dir, "original.png")
                cv2.imwrite(original_path, cv2.cvtColor(self.original_image, cv2.COLOR_RGB2BGR))
            
            if self.current_image is not None:
                result_path = os.path.join(save_dir, "result.png")
                cv2.imwrite(result_path, cv2.cvtColor(self.current_image, cv2.COLOR_RGB2BGR))
            
            result_txt = os.path.join(save_dir, "count_results.txt")
            with open(result_txt, 'w') as f:
                f.write(self.get_count_text())
                
            return f"Results saved to {save_dir}"
        except Exception as e:
            return f"Error saving results: {str(e)}"

class ImagePreprocessHistory:
    def __init__(self):
        self.original_image = None
        self.current_image = None
        self.history = []
        self.current_index = -1

    def set_original(self, image):
        """ì›ë³¸ ì´ë¯¸ì§€ ì„¤ì •"""
        if image is None:
            return None
            
        # PIL Imageë¡œ ë³€í™˜
        if not isinstance(image, Image.Image):
            try:
                image = Image.fromarray(image)
            except Exception as e:
                print(f"Error converting image: {str(e)}")
                return None
        
        self.original_image = image
        self.current_image = image
        self.history = [image]
        self.current_index = 0
        return image

    def add_state(self, image):
        """ìƒˆë¡œìš´ ì´ë¯¸ì§€ ìƒíƒœ ì¶”ê°€"""
        if image is None:
            return None
            
        # PIL Imageë¡œ ë³€í™˜
        if not isinstance(image, Image.Image):
            try:
                image = Image.fromarray(image)
            except Exception as e:
                print(f"Error converting image: {str(e)}")
                return None
        
        # í˜„ì¬ ì¸ë±ìŠ¤ ì´í›„ì˜ íˆìŠ¤í† ë¦¬ëŠ” ì‚­ì œ
        self.history = self.history[:self.current_index + 1]
        self.history.append(image)
        self.current_index = len(self.history) - 1
        self.current_image = image
        return image

    def reset(self):
        """ì›ë³¸ ì´ë¯¸ì§€ë¡œ ë³µì›"""
        if self.original_image is not None:
            self.current_image = self.original_image
            self.current_index = 0
            return self.original_image
        return None

    def redo(self):
        """ì´ì „ ìƒíƒœë¡œ ë³µì›"""
        if self.current_index > 0:
            self.current_index -= 1
            self.current_image = self.history[self.current_index]
            return self.current_image
        return self.current_image

# ì „ì—­ ì´ë¯¸ì§€ íˆìŠ¤í† ë¦¬ ê°ì²´
image_history = ImagePreprocessHistory()

def segment_and_count_colonies(
    input_image,
    method='fastsam',
    input_size=1024,
    iou_threshold=0.7,
    conf_threshold=0.25,
    better_quality=False,
    withContours=True,
    mask_random_color=True,
    min_area_percentile=1,
    max_area_percentile=99,
    circularity_threshold=0.8
):
    try:
        if input_image is None:
            return None, "No input image provided.", None

        # ìƒˆë¡œìš´ counter ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        new_counter = ColonyCounter()
        new_counter.reset()
        new_counter.set_original_image(input_image)
        new_counter.last_method = method.upper()

        # ì…ë ¥ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
        input_size = int(input_size)
        w, h = input_image.size
        scale = input_size / max(w, h)
        new_w, new_h = int(w * scale), int(h * scale)
        input_resized = input_image.resize((new_w, new_h))
        
        # ìŠ¤ì¼€ì¼ ë¹„ìœ¨ ì €ì¥
        new_counter.scale_factor = scale

        # FastSAM ëª¨ë¸ ì˜ˆì¸¡
        input_array = np.array(input_resized)
        results = model.predict(
            source=input_array,
            device=device,
            conf=conf_threshold,
            iou=iou_threshold,
            imgsz=input_size,
            retina_masks=True  # FastSAM ë§ˆìŠ¤í¬ë¥¼ ìœ„í•´ í•„ìš”
        )

        annotations = getattr(results[0].masks, 'data', None)
        if annotations is None or len(annotations) == 0:
            new_counter.current_image = np.array(input_resized)
            return np.array(input_resized), "No colonies detected", new_counter

        # ê° ë§ˆìŠ¤í¬ ë©´ì 
        areas = [np.sum(ann.cpu().numpy() > 0) for ann in annotations]

        # ê°€ì¥ í° ë§ˆìŠ¤í¬ = í˜íŠ¸ë¦¬ ì ‘ì‹œ(dish)
        dish_idx = np.argmax(areas)
        dish_annotation = annotations[dish_idx]
        colony_annotations = [ann for idx, ann in enumerate(annotations) if idx != dish_idx]

        # í•„í„°ë§ + ì›í˜•ë„ ê³„ì‚°
        valid_colony_annotations = []
        new_counter.auto_points = []  # ìë™ ê°ì§€ëœ ì  ì´ˆê¸°í™”

        for ann in colony_annotations:
            ann_cpu = ann.cpu().numpy()
            if ann_cpu.ndim == 3 and ann_cpu.shape[0] == 1:
                ann_cpu = ann_cpu[0]
            mask = ann_cpu > 0
            area = np.sum(mask)

            contours = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            contours = contours[0] if len(contours) == 2 else contours[1]
            if contours and len(contours) > 0:
                perimeter = cv2.arcLength(contours[0], True)
                circularity = 4 * np.pi * (area / (perimeter ** 2)) if perimeter > 0 else 0
                if circularity >= circularity_threshold:
                    valid_colony_annotations.append(ann)
                    # ë§ˆìŠ¤í¬ ì¤‘ì‹¬ì 
                    y_indices, x_indices = np.where(mask)
                    center_x = int(np.mean(x_indices))
                    center_y = int(np.mean(y_indices))
                    new_counter.auto_points.append((center_x, center_y))

        if valid_colony_annotations:
            processed_image = fast_process(
                colony_annotations=valid_colony_annotations,
                dish_annotation=dish_annotation,
                image=input_resized,
                mask_random_color=mask_random_color,
                withContours=withContours
            )
        else:
            processed_image = input_resized

        # counter ê°ì²´ì— ê²°ê³¼ ë°˜ì˜
        if isinstance(processed_image, Image.Image):
            new_counter.current_image = np.array(processed_image)
        else:
            new_counter.current_image = processed_image

        new_counter.auto_detected_count = len(new_counter.auto_points)
        new_counter.current_image = new_counter.draw_points()

        return new_counter.current_image, new_counter.get_count_text(), new_counter
    except Exception as e:
        print(f"Error in segment_and_count_colonies: {str(e)}")
        if input_image is not None:
            return np.array(input_image), f"Error processing image: {str(e)}", None
        return None, f"Error processing image: {str(e)}", None

def batch_process(
    input_dir,
    output_dir='',
    method='fastsam',
    input_size=1024,
    iou_threshold=0.7,
    conf_threshold=0.25,
    better_quality=False,
    withContours=True,
    mask_random_color=True,
    min_area_percentile=1,
    max_area_percentile=99,
    circularity_threshold=0.8
):
    """ì—¬ëŸ¬ ì´ë¯¸ì§€ ì¼ê´„ ì²˜ë¦¬"""
    try:
        if not isinstance(input_dir, str) or not os.path.isdir(input_dir):
            return "Invalid input directory.", []

        if not output_dir or output_dir.strip() == "":
            output_dir = DEFAULT_OUTPUT_DIR

        try:
            os.makedirs(output_dir, exist_ok=True)
        except Exception as e:
            return f"Error creating output directory: {str(e)}", []

        valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')
        image_files = [f for f in os.listdir(input_dir) 
                       if f.lower().endswith(valid_extensions)]
        
        if not image_files:
            return "No valid image files found in the input directory.", []

        results = []
        progress_text = (f"Processing images from: {input_dir}\n"
                         f"Saving results to: {output_dir}\n\n")
        gallery_items = []
        
        for idx, img_file in enumerate(image_files, 1):
            try:
                progress_text += f"Processing image {idx}/{len(image_files)}: {img_file}\n"
                img_path = os.path.join(input_dir, img_file)

                try:
                    input_image = Image.open(img_path).convert('RGB')
                except Exception as e:
                    raise Exception(f"Error loading image: {str(e)}")
                
                # ì´ë¯¸ì§€ ë¶„ì„
                result_image, count_text, counter = segment_and_count_colonies(
                    input_image=input_image,
                    method=method,
                    input_size=input_size,
                    iou_threshold=iou_threshold,
                    conf_threshold=conf_threshold,
                    better_quality=better_quality,
                    withContours=withContours,
                    mask_random_color=mask_random_color,
                    min_area_percentile=min_area_percentile,
                    max_area_percentile=max_area_percentile,
                    circularity_threshold=circularity_threshold
                )
                
                if counter is not None:
                    save_result = counter.save_results(output_dir, img_file)
                else:
                    save_result = "Failed to process image."

                results.append({
                    'filename': img_file,
                    'count_text': count_text,
                    'save_result': save_result
                })
                
                if result_image is not None:
                    gallery_items.append({
                        'image': result_image,
                        'caption': f"{img_file}\n{count_text}"
                    })
                else:
                    gallery_items.append({
                        'image': None,
                        'caption': f"{img_file}\n{count_text}"
                    })
                
                progress_text += f"Processed {img_file}: {count_text}\n{save_result}\n\n"
            except Exception as e:
                error_msg = f"Error processing {img_file}: {str(e)}\n"
                print(error_msg)
                results.append({
                    'filename': img_file,
                    'count_text': f"Error: {str(e)}",
                    'save_result': "Failed to save results"
                })
                gallery_items.append({
                    'image': None,
                    'caption': f"{img_file}\nError: {str(e)}"
                })
                progress_text += error_msg

        summary_path = os.path.join(output_dir, "batch_summary.csv")
        try:
            pd.DataFrame(results).to_csv(summary_path, index=False)
        except Exception as e:
            progress_text += f"Error saving summary CSV: {str(e)}\n"

        # summary.json ìƒì„±
        try:
            create_summary(results, output_dir)
            progress_text += f"\nBatch processing complete. Summary saved to {summary_path} and summary.json"
        except Exception as e:
            progress_text += f"\nError creating summary: {str(e)}"

        return progress_text, gallery_items

    except Exception as e:
        return f"Error in batch processing: {str(e)}", []

def get_output_subdir(output_dir):
    date_str = datetime.now().strftime("%Y-%m-%d")
    time_str = datetime.now().strftime("%H-%M-%S")
    return os.path.join(output_dir, date_str, time_str)

def create_summary(results, output_dir):
    summary = {
        'date': datetime.now().strftime("%Y-%m-%d"),
        'time': datetime.now().strftime("%H:%M:%S"),
        'total_images': len(results),
        'successful': sum(1 for r in results if 'Error' not in r['count_text']),
        'failed': sum(1 for r in results if 'Error' in r['count_text']),
        'results': results
    }
    
    summary_json_path = os.path.join(output_dir, "summary.json")
    with open(summary_json_path, 'w') as f:
        json.dump(summary, f, indent=4)
        
    df = pd.DataFrame(results)
    csv_path = os.path.join(output_dir, "results.csv")
    df.to_csv(csv_path, index=False)

def preprocess_image(image, method='none'):
    """
    ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
    Args:
        image: PIL Image ë˜ëŠ” numpy array
        method: ì „ì²˜ë¦¬ ë°©ë²• ('grayscale', 'binary', 'edge', 'sharpen', 'none')
    Returns:
        ì²˜ë¦¬ëœ PIL Image
    """
    try:
        # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
        if isinstance(image, Image.Image):
            image_np = np.array(image)
        else:
            image_np = image.copy()

        if method == 'none':
            return Image.fromarray(image_np)

        if method == 'grayscale':
            if len(image_np.shape) == 3:
                gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
                return Image.fromarray(cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB))
            return Image.fromarray(image_np)

        elif method == 'binary':
            if len(image_np.shape) == 3:
                gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
            else:
                gray = image_np
            _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
            return Image.fromarray(cv2.cvtColor(binary, cv2.COLOR_GRAY2RGB))

        elif method == 'edge':
            if len(image_np.shape) == 3:
                gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
            else:
                gray = image_np
            edges = cv2.Canny(gray, 100, 200)
            return Image.fromarray(cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB))

        elif method == 'sharpen':
            kernel = np.array([[-1,-1,-1],
                             [-1, 9,-1],
                             [-1,-1,-1]])
            sharpened = cv2.filter2D(image_np, -1, kernel)
            return Image.fromarray(sharpened)

        return Image.fromarray(image_np)
    except Exception as e:
        print(f"Error in preprocess_image: {str(e)}")
        return image

# CSS ìŠ¤íƒ€ì¼ ìˆ˜ì •
css = """
.container {max-width: 1100px; margin: auto; padding: 20px;}
.header {text-align: center; margin-bottom: 30px;}
.result-text {font-size: 1.2em; font-weight: bold;}
.instruction-box {
    background-color: #000000;
    color: #ffffff;
    border-radius: 10px;
    padding: 20px;
    margin: 20px 0;
}
.input-image {
    border: 2px solid #ddd;
    margin-top: 10px;
    border-radius: 8px;
    background-color: #f8f9fa;
    max-height: 600px;
}
.output-image {
    border: 2px solid #ddd;
    margin-top: 10px;
    border-radius: 8px;
    background-color: #f8f9fa;
    min-height: 600px;
}
.image-label {
    font-size: 1.1em;
    font-weight: bold;
    margin-bottom: 5px;
    color: #444;
}
.footer {
    text-align: center;
    padding: 20px;
    margin-top: 30px;
    color: #666;
    font-size: 0.9em;
}
"""

# ì „ì—­ counter ê°ì²´
counter = ColonyCounter()

with gr.Blocks(theme=gr.themes.Soft(), css=css) as demo:
    gr.Markdown(
        """
        <div class="header">
            <h1>ğŸ”¬ Advanced Colony Counter</h1>
            <h3>AI-Powered Colony Detection & Analysis</h3>
        </div>
        """
    )

    with gr.Tabs():
        with gr.Tab("Colony Counter"):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown(
                        """<p class="image-label">Upload Image</p>""",
                        elem_classes="image-label"
                    )
                    input_image = gr.Image(
                        label="",
                        type="pil",
                        elem_classes="input-image",
                        show_label=False,
                        show_download_button=False
                    )
                    
                    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì˜µì…˜
                    with gr.Row():
                        preprocess_method = gr.Radio(
                            choices=['none', 'grayscale', 'binary', 'edge', 'sharpen'],
                            value='none',
                            label="Image Preprocessing",
                            info="Select preprocessing method"
                        )
                    
                    with gr.Row():
                        preprocess_button = gr.Button(
                            "ğŸ¨ Apply Preprocessing",
                            variant="secondary",
                            scale=1
                        )
                        reset_button = gr.Button(
                            "â†º Reset to Original",
                            variant="secondary",
                            scale=1
                        )
                        redo_button = gr.Button(
                            "â†¶ Undo Preprocessing",
                            variant="secondary",
                            scale=1
                        )

                    with gr.Row():
                        method_select = gr.Radio(
                            choices=['AI Detection'],
                            value='AI Detection',
                            label="Detection Method",
                            info="Advanced AI-based colony detection"
                        )
                        segment_button = gr.Button(
                            "ğŸ” Analyze Image",
                            variant="primary",
                            scale=2
                        )

                    # ë¶„ì„ ì„¤ì • ì¶”ê°€
                    with gr.Accordion("âš™ï¸ Analysis Settings", open=False):
                        with gr.Row():
                            input_size_slider = gr.Slider(
                                512, 1024, 1024,
                                step=64,
                                label='Input Size',
                                info='Larger size = better accuracy but slower'
                            )
                            better_quality_checkbox = gr.Checkbox(
                                label="Enhanced Quality",
                                value=True,
                                info="Improve output quality"
                            )
                        
                        with gr.Row():
                            withContours_checkbox = gr.Checkbox(
                                label="Show Contours",
                                value=True,
                                info="Display colony boundaries"
                            )
                            iou_threshold_slider = gr.Slider(
                                0.1, 0.9, 0.7,
                                label="IOU Threshold",
                                info="Higher = stricter detection"
                            )
                        
                        with gr.Row():
                            conf_threshold_slider = gr.Slider(
                                0.1, 0.9, 0.25,
                                label="Confidence Threshold",
                                info="Higher = more confident detection"
                            )
                            circularity_threshold_slider = gr.Slider(
                                0.0, 1.0, 0.8,
                                label="Circularity",
                                info="Higher = more circular colonies"
                            )
                        
                        with gr.Row():
                            min_area_percentile_slider = gr.Slider(
                                0, 10, 1,
                                label="Min Size %",
                                info="Filter smaller colonies"
                            )
                            max_area_percentile_slider = gr.Slider(
                                90, 100, 99,
                                label="Max Size %",
                                info="Filter larger objects"
                            )

                with gr.Column(scale=1):
                    gr.Markdown(
                        """<p class="image-label">Analysis Result</p>""",
                        elem_classes="image-label"
                    )
                    output_image = gr.Image(
                        label="",
                        type="numpy",
                        interactive=True,
                        elem_classes="output-image",
                        show_label=False,
                        show_download_button=True
                    )
                    colony_count_text = gr.Textbox(
                        label="Count Result",
                        lines=3,
                        elem_classes="result-text"
                    )

                    with gr.Row():
                        with gr.Column(scale=1):
                            remove_mode_button = gr.Button(
                                "ğŸ”„ Toggle Edit Mode",
                                variant="secondary"
                            )
                            remove_mode_text = gr.Textbox(
                                label="Current Mode",
                                value="ğŸŸ¢ Add Mode",
                                lines=1
                            )
                        with gr.Column(scale=1):
                            remove_point_button = gr.Button(
                                "â†©ï¸ Undo Last Point",
                                variant="secondary"
                            )

        with gr.Tab("Batch Processing"):
            with gr.Row():
                input_dir = gr.Textbox(
                    label="Input Directory",
                    placeholder="Enter the full path to the input directory",
                    lines=1
                )
                output_dir = gr.Textbox(
                    label="Output Directory",
                    value=DEFAULT_OUTPUT_DIR,
                    info="Results will be saved here",
                    placeholder="Enter path or use default",
                    lines=1
                )
            
            with gr.Row():
                batch_process_btn = gr.Button("ğŸ” Process All Images", scale=2)
                open_folder_btn = gr.Button("ğŸ“‚ Open Output Folder", scale=1)

            with gr.Row():
                batch_progress = gr.Textbox(
                    label="Progress",
                    lines=10,
                    max_lines=15
                )
            
            with gr.Row():
                batch_gallery = gr.Gallery(
                    label="Batch Processing Results",
                    show_label=True,
                    elem_id="gallery",
                    columns=3
                )

            with gr.Row():
                with gr.Accordion("ğŸ“‹ Batch Processing Instructions", open=False):
                    gr.Markdown("""
                    ### How to use batch processing:
                    1. Enter the full path to the input directory containing your images.
                    2. Enter the output directory path or use the default.
                    3. Click 'Process All Images' to start.
                    4. Progress will be shown in the text box below.
                    5. Results for each image will be saved in separate folders and displayed in the gallery.
                    6. A summary CSV and JSON file will be created in the output directory.
                    """)

    # Footer ì¶”ê°€
    gr.Markdown(
        """
        <div class="footer">
            Produced By BDK&copy;
        </div>
        """
    )

    # ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜
    def handle_image_upload(image):
        """ì´ë¯¸ì§€ ì—…ë¡œë“œ ì²˜ë¦¬ ìµœì í™”"""
        if image is None:
            return None, None
        
        try:
            # PIL Imageë¡œ ë³€í™˜
            if not isinstance(image, Image.Image):
                image = Image.fromarray(image)
            
            # ì´ë¯¸ì§€ í¬ê¸° ì œí•œ
            max_size = 1024
            w, h = image.size
            if max(w, h) > max_size:
                scale = max_size / max(w, h)
                new_w, new_h = int(w * scale), int(h * scale)
                image = image.resize((new_w, new_h), Image.LANCZOS)
            
            # ì´ë¯¸ì§€ íˆìŠ¤í† ë¦¬ì— ì €ì¥
            processed_image = image_history.set_original(image)
            return processed_image, "Image uploaded successfully"
        except Exception as e:
            print(f"Error in handle_image_upload: {str(e)}")
            return None, f"Error uploading image: {str(e)}"

    # ì „ì²˜ë¦¬ í•¨ìˆ˜ ìˆ˜ì •
    def apply_preprocessing(image, method):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì ìš©"""
        if image is None:
            return None
        
        try:
            processed = preprocess_image(image, method)
            if processed is not None:
                return image_history.add_state(processed)
            return image
        except Exception as e:
            print(f"Error in apply_preprocessing: {str(e)}")
            return image

    # Reset í•¨ìˆ˜
    def reset_image():
        """ì´ë¯¸ì§€ ì´ˆê¸°í™”"""
        try:
            return image_history.reset()
        except Exception as e:
            print(f"Error in reset_image: {str(e)}")
            return None

    # Redo í•¨ìˆ˜
    def redo_image():
        """ì´ì „ ìƒíƒœë¡œ ë³µì›"""
        try:
            return image_history.redo()
        except Exception as e:
            print(f"Error in redo_image: {str(e)}")
            return None

    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²°
    input_image.upload(
        handle_image_upload,
        inputs=[input_image],
        outputs=[input_image, colony_count_text]
    )

    preprocess_button.click(
        apply_preprocessing,
        inputs=[input_image, preprocess_method],
        outputs=[input_image]
    )

    reset_button.click(
        reset_image,
        inputs=[],
        outputs=[input_image]
    )

    redo_button.click(
        redo_image,
        inputs=[],
        outputs=[input_image]
    )

    # analyze_image í•¨ìˆ˜ ìˆ˜ì •
    def analyze_image(
        input_image, method, input_size=1024, iou_threshold=0.7,
        conf_threshold=0.25, better_quality=True, withContours=True,
        min_area_percentile=1, max_area_percentile=99,
        circularity_threshold=0.8
    ):
        """ì´ë¯¸ì§€ ë¶„ì„ í•¨ìˆ˜ ìµœì í™”"""
        if input_image is None:
            return None, "No input image provided."

        try:
            # ì´ë¯¸ì§€ í¬ê¸° ìµœì í™”
            if isinstance(input_image, Image.Image):
                w, h = input_image.size
                if max(w, h) > input_size:
                    scale = input_size / max(w, h)
                    new_w, new_h = int(w * scale), int(h * scale)
                    input_image = input_image.resize((new_w, new_h), Image.LANCZOS)

            # FastSAMì„ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©
            method = 'fastsam'
            processed_image, count_text, new_counter = segment_and_count_colonies(
                input_image=input_image,
                method=method,
                input_size=input_size,
                iou_threshold=iou_threshold,
                conf_threshold=conf_threshold,
                better_quality=better_quality,
                withContours=withContours,
                mask_random_color=True,
                min_area_percentile=min_area_percentile,
                max_area_percentile=max_area_percentile,
                circularity_threshold=circularity_threshold
            )

            if new_counter is not None:
                counter.auto_points = new_counter.auto_points
                counter.auto_detected_count = new_counter.auto_detected_count
                counter.current_image = new_counter.current_image
                counter.original_image = new_counter.original_image
                counter.last_method = new_counter.last_method
                counter.scale_factor = new_counter.scale_factor

            return processed_image, count_text
        except Exception as e:
            print(f"Error in analyze_image: {str(e)}")
            return None, f"Error analyzing image: {str(e)}"

    segment_button.click(
        analyze_image,
        inputs=[
            input_image,
            method_select,
            input_size_slider,
            iou_threshold_slider,
            conf_threshold_slider,
            better_quality_checkbox,
            withContours_checkbox,
            min_area_percentile_slider,
            max_area_percentile_slider,
            circularity_threshold_slider
        ],
        outputs=[output_image, colony_count_text]
    )

    # ìˆ˜ë™ í¬ì¸íŠ¸ ì¶”ê°€/ì œê±° ì´ë²¤íŠ¸
    output_image.select(
        counter.add_or_remove_point,
        inputs=[output_image],
        outputs=[output_image, colony_count_text]
    )

    remove_point_button.click(
        counter.remove_last_point,
        inputs=[output_image],
        outputs=[output_image, colony_count_text]
    )

    remove_mode_button.click(
        counter.toggle_remove_mode,
        inputs=[],
        outputs=[output_image, remove_mode_text]
    )

    # ë°°ì¹˜ ì²˜ë¦¬ ì´ë²¤íŠ¸
    def handle_batch_process(
        input_dir, output_dir, method, input_size, iou_threshold,
        conf_threshold, better_quality, withContours,
        min_area_percentile, max_area_percentile, circularity_threshold
    ):
        # batch_process ë‚´ë¶€ì—ì„œ mask_random_color=Trueë¡œ í•˜ë“œì½”ë”©ë˜ì–´ ìˆìœ¼ë¯€ë¡œ
        # ì›í•˜ë©´ inputsì—ì„œ mask_random_colorë¥¼ ì¸ìë¡œ ë°›ì•„ ì—°ë™ ê°€ëŠ¥
        progress, gallery = batch_process(
            input_dir=input_dir,
            output_dir=output_dir,
            method=method,
            input_size=input_size,
            iou_threshold=iou_threshold,
            conf_threshold=conf_threshold,
            better_quality=better_quality,
            withContours=withContours,
            mask_random_color=True,
            min_area_percentile=min_area_percentile,
            max_area_percentile=max_area_percentile,
            circularity_threshold=circularity_threshold
        )
        return progress, gallery

    batch_process_btn.click(
        handle_batch_process,
        inputs=[
            input_dir,
            output_dir,
            method_select,
            input_size_slider,
            iou_threshold_slider,
            conf_threshold_slider,
            better_quality_checkbox,
            withContours_checkbox,
            min_area_percentile_slider,
            max_area_percentile_slider,
            circularity_threshold_slider
        ],
        outputs=[batch_progress, batch_gallery]
    )

    def open_output_folder(folder_to_open):
        try:
            if os.path.exists(folder_to_open):
                if os.name == 'nt':  # Windows
                    os.startfile(folder_to_open)
                elif os.name == 'posix':  # macOS, Linux
                    if sys.platform == 'darwin':
                        os.system(f'open "{folder_to_open}"')
                    else:
                        os.system(f'xdg-open "{folder_to_open}"')
                return f"Opened output folder: {folder_to_open}"
            else:
                return f"Output folder does not exist: {folder_to_open}"
        except Exception as e:
            return f"Error opening folder: {str(e)}"

    open_folder_btn.click(
        open_output_folder,
        inputs=[output_dir],
        outputs=[batch_progress]
    )

if __name__ == "__main__":
    demo.launch()